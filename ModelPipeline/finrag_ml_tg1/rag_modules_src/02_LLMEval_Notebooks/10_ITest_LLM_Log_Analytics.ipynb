{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdfeccd",
   "metadata": {},
   "source": [
    "### Post-Success, Log Analytics:\n",
    "- Sync latest logs from S3\n",
    "- Do some analytics on logs.parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bda68510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úì ModelPipeline root: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "‚úì Notebook location: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\02_LLMEval_Notebooks\n",
      "\n",
      "================================================================================\n",
      "SYNCING LOGS FROM S3\n",
      "================================================================================\n",
      "[DEBUG] ‚úì Found ModelPipeline via file path: D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "[DEBUG] ‚úì AWS credentials loaded from aws_credentials.env\n",
      "‚úì Downloaded latest query_logs.parquet from S3\n",
      "\n",
      "================================================================================\n",
      "READY FOR TESTING & ANALYTICS\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Setup - Path Resolution, Imports & Sync Latest Logs\n",
    "# ============================================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Suppress noisy logs for clean notebook output\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.getLogger(\"finrag_ml_tg1\").setLevel(logging.INFO)\n",
    "\n",
    "# Find ModelPipeline root and add to sys.path\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root in path tree\")\n",
    "\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"‚úì ModelPipeline root: {model_root}\")\n",
    "print(f\"‚úì Notebook location: {Path.cwd()}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# Sync latest logs from S3\n",
    "# ============================================================================\n",
    "from finrag_ml_tg1.rag_modules_src.synthesis_pipeline.query_logger import QueryLogger\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNCING LOGS FROM S3\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "logger = QueryLogger()\n",
    "downloaded, skipped = logger.sync_to_local()\n",
    "\n",
    "if downloaded > 0:\n",
    "    print(f\"‚úì Downloaded latest query_logs.parquet from S3\")\n",
    "elif skipped > 0:\n",
    "    print(f\"‚úì Local query_logs.parquet is already up-to-date\")\n",
    "else:\n",
    "    print(f\"‚ö† No log file found in S3 yet\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"READY FOR TESTING & ANALYTICS\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Configure Polars display settings\n",
    "pl.Config.set_tbl_rows(-1)  # Show all rows\n",
    "pl.Config.set_tbl_cols(-1)  # Show all columns\n",
    "pl.Config.set_tbl_width_chars(150)  # Wider tables\n",
    "pl.Config.set_fmt_str_lengths(100)  # Show longer strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3772c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LIVE PIPELINE TEST\n",
      "================================================================================\n",
      "\n",
      "Running test query:\n",
      "   'What was Apple's total revenue in 2020?'\n",
      "\n",
      "Processing...\n",
      "\n",
      "[DEBUG] ‚úì Found ModelPipeline via file path: D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "[DEBUG] ‚úì AWS credentials loaded from aws_credentials.env\n",
      "[DEBUG] ‚úì Found ModelPipeline via file path: D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "[DEBUG] ‚úì AWS credentials loaded from aws_credentials.env\n",
      "[DEBUG] ‚úì Found ModelPipeline via file path: D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "[DEBUG] ‚úì AWS credentials loaded from aws_credentials.env\n",
      "================================================================================\n",
      "‚úÖ SUCCESS\n",
      "\n",
      "üìù Answer Preview:\n",
      "   # Apple's Total Revenue in 2020\n",
      "\n",
      "According to Apple's FY 2020 10-K filing, total net sales increased 6% or $14.3 billion during 2020 compared to 2019, primarily driven by higher net sales of Services ...\n",
      "\n",
      "! Query Metrics:\n",
      "   Model: claude-haiku-4-5-20251001-v1:0\n",
      "   Cost: $0.0104\n",
      "   Tokens: 8,900 in + 294 out = 9,194\n",
      "   Time: 9,377.1 ms\n",
      "\n",
      "üìÅ Logged to: s3://sentence-data-ingestion/DATA_MERGE_ASSETS/LOGS/FINRAG/logs/query_logs.parquet\n",
      "================================================================================\n",
      "\n",
      "üîÑ Re-syncing logs to include fresh query...\n",
      "‚úì Logs updated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Live Test Query - Verify Pipeline Works\n",
    "# ============================================================================\n",
    "\n",
    "from finrag_ml_tg1.rag_modules_src.synthesis_pipeline.orchestrator import answer_query\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LIVE PIPELINE TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test query (lightweight but meaningful)\n",
    "test_query = \"What was Apple's, Microsoft's, Alphabet's total revenue, cogs and eps related information in 2018?\"\n",
    "\n",
    "print(f\"\\nRunning test query:\")\n",
    "print(f\"   '{test_query}'\")\n",
    "print(f\"\\nProcessing...\\n\")\n",
    "\n",
    "# Run query through full pipeline\n",
    "result = answer_query(\n",
    "    query=test_query,\n",
    "    model_root=model_root,\n",
    "    include_kpi=True,\n",
    "    include_rag=True,\n",
    "    model_key=None,  # Use default model\n",
    "    export_context=True,  # Skip context export for test\n",
    "    export_response=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 80)\n",
    "if result.get('error'):\n",
    "    print(f\"‚ùå ERROR: {result['error']}\")\n",
    "    print(f\"   Stage: {result.get('stage')}\")\n",
    "else:\n",
    "    print(f\"‚úÖ SUCCESS\")\n",
    "    \n",
    "    # Show answer preview\n",
    "    answer = result['answer']\n",
    "    answer_preview = answer[:200] + \"...\" if len(answer) > 200 else answer\n",
    "    print(f\"\\nüìù Answer Preview:\")\n",
    "    print(f\"   {answer_preview}\")\n",
    "    \n",
    "    # Show metrics\n",
    "    llm_meta = result['metadata']['llm']\n",
    "    print(f\"\\n! Query Metrics:\")\n",
    "    print(f\"   Model: {llm_meta['model_id'].split('.')[-1]}\")\n",
    "    print(f\"   Cost: ${llm_meta['cost']:.4f}\")\n",
    "    print(f\"   Tokens: {llm_meta['input_tokens']:,} in + {llm_meta['output_tokens']:,} out = {llm_meta['total_tokens']:,}\")\n",
    "    print(f\"   Time: {result['metadata']['processing_time_ms']:,.1f} ms\")\n",
    "    \n",
    "    # Show log location\n",
    "    print(f\"\\nüìÅ Logged to: {result['exports']['log_file']}\")\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Re-sync to get the fresh query we just logged\n",
    "print(\"üîÑ Re-syncing logs to include fresh query...\")\n",
    "logger.sync_to_local()\n",
    "print(\"‚úì Logs updated\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "508f307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total log entries: 45\n",
      "Columns: ['timestamp', 'query', 'model_id', 'input_tokens', 'output_tokens', 'total_tokens', 'cost', 'context_length', 'processing_time_ms', 'error', 'error_type', 'stage', 'context_file', 'response_file']\n",
      "\n",
      "Schema:\n",
      "Schema({'timestamp': String, 'query': String, 'model_id': String, 'input_tokens': Int64, 'output_tokens': Int64, 'total_tokens': Int64, 'cost': Float64, 'context_length': Int64, 'processing_time_ms': Float64, 'error': String, 'error_type': String, 'stage': String, 'context_file': String, 'response_file': String})\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Column stats:\n",
      "  timestamp: String (nulls: 0)\n",
      "  query: String (nulls: 0)\n",
      "  model_id: String (nulls: 0)\n",
      "  input_tokens: Int64 (nulls: 0)\n",
      "  output_tokens: Int64 (nulls: 0)\n",
      "  total_tokens: Int64 (nulls: 0)\n",
      "  cost: Float64 (nulls: 0)\n",
      "  context_length: Int64 (nulls: 0)\n",
      "  processing_time_ms: Float64 (nulls: 0)\n",
      "  error: String (nulls: 45)\n",
      "  error_type: String (nulls: 45)\n",
      "  stage: String (nulls: 45)\n",
      "  context_file: String (nulls: 19)\n",
      "  response_file: String (nulls: 19)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSTIC: Inspect Query Logs Schema\n",
    "# ============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to logs\n",
    "log_path = model_root / \"finrag_ml_tg1\" / \"rag_modules_src\" / \"exports\" / \"logs\" / \"query_logs.parquet\"\n",
    "\n",
    "if not log_path.exists():\n",
    "    print(f\"ERROR: Log file not found at {log_path}\")\n",
    "else:\n",
    "    # Load logs\n",
    "    df_logs = pl.read_parquet(log_path)\n",
    "    \n",
    "    print(f\"Total log entries: {df_logs.height}\")\n",
    "    print(f\"Columns: {df_logs.columns}\\n\")\n",
    "    \n",
    "    # Show schema\n",
    "    print(\"Schema:\")\n",
    "    print(df_logs.schema)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Show data types and null counts\n",
    "    print(\"Column stats:\")\n",
    "    for col in df_logs.columns:\n",
    "        dtype = df_logs[col].dtype\n",
    "        null_count = df_logs[col].null_count()\n",
    "        print(f\"  {col}: {dtype} (nulls: {null_count})\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a765908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUERY LOGS LOADED\n",
      "================================================================================\n",
      "Total log entries: 45\n",
      "Columns: ['timestamp', 'query', 'model_id', 'input_tokens', 'output_tokens', 'total_tokens', 'cost', 'context_length', 'processing_time_ms', 'error', 'error_type', 'stage', 'context_file', 'response_file']\n",
      "\n",
      "Schema:\n",
      "  timestamp..................... String......... (nulls: 0)\n",
      "  query......................... String......... (nulls: 0)\n",
      "  model_id...................... String......... (nulls: 0)\n",
      "  input_tokens.................. Int64.......... (nulls: 0)\n",
      "  output_tokens................. Int64.......... (nulls: 0)\n",
      "  total_tokens.................. Int64.......... (nulls: 0)\n",
      "  cost.......................... Float64........ (nulls: 0)\n",
      "  context_length................ Int64.......... (nulls: 0)\n",
      "  processing_time_ms............ Float64........ (nulls: 0)\n",
      "  error......................... String......... (nulls: 45)\n",
      "  error_type.................... String......... (nulls: 45)\n",
      "  stage......................... String......... (nulls: 45)\n",
      "  context_file.................. String......... (nulls: 19)\n",
      "  response_file................. String......... (nulls: 19)\n",
      "\n",
      "================================================================================\n",
      "MOST RECENT QUERY (Should be! test from Cell 2!)\n",
      "================================================================================\n",
      "  timestamp: 2025-11-25T05:28:12.715283Z\n",
      "  query: What was Apple's total revenue in 2020?\n",
      "  model_id: us.anthropic.claude-haiku-4-5-20251001-v1:0\n",
      "  cost: 0.01037\n",
      "  total_tokens: 9194\n",
      "  processing_time_ms: 9377.122402191162\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Load Logs for Analytics\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# Path to local logs\n",
    "log_path = model_root / \"finrag_ml_tg1\" / \"rag_modules_src\" / \"exports\" / \"logs\" / \"query_logs.parquet\"\n",
    "\n",
    "if not log_path.exists():\n",
    "    print(f\"‚ùå ERROR: Log file not found at {log_path}\")\n",
    "    print(f\"   Run Cell 1 to sync from S3\")\n",
    "else:\n",
    "    # Load logs\n",
    "    df_logs = pl.read_parquet(log_path)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"QUERY LOGS LOADED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total log entries: {df_logs.height}\")\n",
    "    print(f\"Columns: {df_logs.columns}\\n\")\n",
    "    \n",
    "    # Show schema\n",
    "    print(\"Schema:\")\n",
    "    for col, dtype in df_logs.schema.items():\n",
    "        null_count = df_logs[col].null_count()\n",
    "        print(f\"  {col:.<30} {str(dtype):.<15} (nulls: {null_count})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MOST RECENT QUERY (Should be! test from Cell 2!)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show most recent entry\n",
    "    most_recent = df_logs.sort(\"timestamp\", descending=True).head(1)\n",
    "    \n",
    "    for col in ['timestamp', 'query', 'model_id', 'cost', 'total_tokens', 'processing_time_ms']:\n",
    "        if col in most_recent.columns:\n",
    "            val = most_recent[col][0]\n",
    "            print(f\"  {col}: {val}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad3478d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUERY LOGS LOADED\n",
      "================================================================================\n",
      "Total log entries: 45\n",
      "Columns: ['timestamp', 'query', 'model_id', 'input_tokens', 'output_tokens', 'total_tokens', 'cost', 'context_length', 'processing_time_ms', 'error', 'error_type', 'stage', 'context_file', 'response_file']\n",
      "\n",
      "Schema:\n",
      "  timestamp..................... String......... (nulls: 0)\n",
      "  query......................... String......... (nulls: 0)\n",
      "  model_id...................... String......... (nulls: 0)\n",
      "  input_tokens.................. Int64.......... (nulls: 0)\n",
      "  output_tokens................. Int64.......... (nulls: 0)\n",
      "  total_tokens.................. Int64.......... (nulls: 0)\n",
      "  cost.......................... Float64........ (nulls: 0)\n",
      "  context_length................ Int64.......... (nulls: 0)\n",
      "  processing_time_ms............ Float64........ (nulls: 0)\n",
      "  error......................... String......... (nulls: 45)\n",
      "  error_type.................... String......... (nulls: 45)\n",
      "  stage......................... String......... (nulls: 45)\n",
      "  context_file.................. String......... (nulls: 19)\n",
      "  response_file................. String......... (nulls: 19)\n",
      "\n",
      "================================================================================\n",
      "MOST RECENT QUERY (Should be your test from Cell 2!)\n",
      "================================================================================\n",
      "  timestamp: 2025-11-25T05:28:12.715283Z\n",
      "  query: What was Apple's total revenue in 2020?\n",
      "  model_id: us.anthropic.claude-haiku-4-5-20251001-v1:0\n",
      "  cost: 0.01037\n",
      "  total_tokens: 9194\n",
      "  processing_time_ms: 9377.122402191162\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Load Logs for Analytics\n",
    "# ============================================================================\n",
    "\n",
    "pl.Config.set_tbl_formatting(\"ASCII_FULL_CONDENSED\")  # Denser formatting\n",
    "pl.Config.set_tbl_rows(-1)  # Show all rows\n",
    "pl.Config.set_tbl_width_chars(1000)  # Allow wide tables\n",
    "\n",
    "\n",
    "# Path to local logs\n",
    "log_path = model_root / \"finrag_ml_tg1\" / \"rag_modules_src\" / \"exports\" / \"logs\" / \"query_logs.parquet\"\n",
    "\n",
    "if not log_path.exists():\n",
    "    print(f\"‚ùå ERROR: Log file not found at {log_path}\")\n",
    "    print(f\"   Run Cell 1 to sync from S3\")\n",
    "else:\n",
    "    # Load logs\n",
    "    df_logs = pl.read_parquet(log_path)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"QUERY LOGS LOADED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total log entries: {df_logs.height}\")\n",
    "    print(f\"Columns: {df_logs.columns}\\n\")\n",
    "    \n",
    "    # Show schema\n",
    "    print(\"Schema:\")\n",
    "    for col, dtype in df_logs.schema.items():\n",
    "        null_count = df_logs[col].null_count()\n",
    "        print(f\"  {col:.<30} {str(dtype):.<15} (nulls: {null_count})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MOST RECENT QUERY (Should be your test from Cell 2!)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show most recent entry\n",
    "    most_recent = df_logs.sort(\"timestamp\", descending=True).head(1)\n",
    "    \n",
    "    for col in ['timestamp', 'query', 'model_id', 'cost', 'total_tokens', 'processing_time_ms']:\n",
    "        if col in most_recent.columns:\n",
    "            val = most_recent[col][0]\n",
    "            print(f\"  {col}: {val}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "360ed41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä OVERALL QUERY HISTORY SUMMARY\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Metric</th><th>Value</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Total Queries&quot;</td><td>&quot;45&quot;</td></tr><tr><td>&quot;Successful Queries&quot;</td><td>&quot;45&quot;</td></tr><tr><td>&quot;Failed Queries&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;Date Range&quot;</td><td>&quot;2025-11-19 to 2025-11-25&quot;</td></tr><tr><td>&quot;Unique Questions&quot;</td><td>&quot;14&quot;</td></tr><tr><td>&quot;Total Cost&quot;</td><td>&quot;$0.7208&quot;</td></tr><tr><td>&quot;Total Tokens&quot;</td><td>&quot;345,280 (315,747 in + 29,533 out)&quot;</td></tr><tr><td>&quot;Avg Cost per Query&quot;</td><td>&quot;$0.0160&quot;</td></tr><tr><td>&quot;Avg Tokens per Query&quot;</td><td>&quot;7,673&quot;</td></tr><tr><td>&quot;Avg Processing Time (ms)&quot;</td><td>&quot;17,001.0&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "+--------------------------+-----------------------------------+\n",
       "| Metric                   | Value                             |\n",
       "| ---                      | ---                               |\n",
       "| str                      | str                               |\n",
       "+==============================================================+\n",
       "| Total Queries            | 45                                |\n",
       "| Successful Queries       | 45                                |\n",
       "| Failed Queries           | 0                                 |\n",
       "| Date Range               | 2025-11-19 to 2025-11-25          |\n",
       "| Unique Questions         | 14                                |\n",
       "| Total Cost               | $0.7208                           |\n",
       "| Total Tokens             | 345,280 (315,747 in + 29,533 out) |\n",
       "| Avg Cost per Query       | $0.0160                           |\n",
       "| Avg Tokens per Query     | 7,673                             |\n",
       "| Avg Processing Time (ms) | 17,001.0                          |\n",
       "+--------------------------+-----------------------------------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Overall Query History Summary\n",
    "# ============================================================================\n",
    "\n",
    "# Parse date from timestamp\n",
    "df_logs = df_logs.with_columns([\n",
    "    pl.col(\"timestamp\").str.slice(0, 10).alias(\"date\")\n",
    "])\n",
    "\n",
    "# Filter out null costs (failed queries)\n",
    "df_success = df_logs.filter(pl.col(\"cost\").is_not_null())\n",
    "\n",
    "# Calculate summary stats\n",
    "summary = pl.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Total Queries\",\n",
    "        \"Successful Queries\",\n",
    "        \"Failed Queries\",\n",
    "        \"Date Range\",\n",
    "        \"Unique Questions\",\n",
    "        \"Total Cost\",\n",
    "        \"Total Tokens\",\n",
    "        \"Avg Cost per Query\",\n",
    "        \"Avg Tokens per Query\",\n",
    "        \"Avg Processing Time (ms)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(df_logs.height),\n",
    "        str(len(df_success)),\n",
    "        str(df_logs.height - len(df_success)),\n",
    "        f\"{df_logs['date'].min()} to {df_logs['date'].max()}\",\n",
    "        str(df_logs[\"query\"].n_unique()),\n",
    "        f\"${df_success['cost'].sum():.4f}\",\n",
    "        f\"{df_success['total_tokens'].sum():,} ({df_success['input_tokens'].sum():,} in + {df_success['output_tokens'].sum():,} out)\",\n",
    "        f\"${df_success['cost'].mean():.4f}\",\n",
    "        f\"{df_success['total_tokens'].mean():,.0f}\",\n",
    "        f\"{df_success['processing_time_ms'].mean():,.1f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä OVERALL QUERY HISTORY SUMMARY\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7343ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üí∞ COST & TOKEN ANALYSIS BY QUERY\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>query_short</th><th>runs</th><th>avg_input_tokens</th><th>avg_output_tokens</th><th>avg_total_tokens</th><th>total_cost</th><th>avg_cost</th><th>avg_processing_ms</th></tr><tr><td>str</td><td>u32</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Across its fiscal 2018-2020 10-K filings, how does Walmart Inc. explain the main...&quot;</td><td>14</td><td>5431</td><td>790</td><td>6222</td><td>0.206779</td><td>0.01477</td><td>18606.5</td></tr><tr><td>&quot;How does MICROSOFT CORP describe the change in its Intelligent Cloud revenue in ...&quot;</td><td>6</td><td>6940</td><td>381</td><td>7320</td><td>0.106381</td><td>0.01773</td><td>13496.8</td></tr><tr><td>&quot;Over time, how does Meta Platforms describe the regulatory and policy risks that...&quot;</td><td>2</td><td>10469</td><td>1476</td><td>11945</td><td>0.072236</td><td>0.036118</td><td>29148.2</td></tr><tr><td>&quot;In their 2009 Form 10-K risk-factor disclosures, how do Radian Group, Netflix an...&quot;</td><td>3</td><td>5263</td><td>637</td><td>5900</td><td>0.061326</td><td>0.020442</td><td>16422.9</td></tr><tr><td>&quot;What was Apple&#x27;s total revenue and operating income in fiscal year 2017?&quot;</td><td>5</td><td>8049</td><td>354</td><td>8402</td><td>0.049084</td><td>0.0098168</td><td>11214.5</td></tr><tr><td>&quot;What does EXXON MOBIL CORP report as its total revenue in 2008, and how is this ...&quot;</td><td>2</td><td>5743</td><td>262</td><td>6005</td><td>0.042318</td><td>0.021159</td><td>10846.5</td></tr><tr><td>&quot;What was Apple&#x27;s total revenue in 2020?&quot;</td><td>3</td><td>8900</td><td>288</td><td>9188</td><td>0.031015</td><td>0.010338</td><td>9568.6</td></tr><tr><td>&quot;What was Apple&#x27;s revenue in 2017?&quot;</td><td>3</td><td>8549</td><td>324</td><td>8873</td><td>0.030508</td><td>0.010169</td><td>12661.8</td></tr><tr><td>&quot;Where does Tesla define Adjusted EBITDA in its 2022 Form 10-K, and how does the ...&quot;</td><td>2</td><td>5961</td><td>300</td><td>6260</td><td>0.029849</td><td>0.0149245</td><td>10426.8</td></tr><tr><td>&quot;In their 2020 Form 10-K risk-factor disclosures, how do Radian Group, Netflix an...&quot;</td><td>2</td><td>9190</td><td>1010</td><td>10200</td><td>0.028484</td><td>0.014242</td><td>29258.4</td></tr><tr><td>&quot;Show me Apple, Microsoft, Amazon, Alphabet, Google, and Tesla&#x27;s financial perfor...&quot;</td><td>1</td><td>12096</td><td>2863</td><td>14959</td><td>0.026411</td><td>0.026411</td><td>50156.8</td></tr><tr><td>&quot;What operational or supply chain risks does Walmart Inc. highlight in its 2011 R...&quot;</td><td>1</td><td>4264</td><td>446</td><td>4710</td><td>0.019482</td><td>0.019482</td><td>21033.7</td></tr><tr><td>&quot;For NVIDIA and Microsoft, what were revenue, operating income, and total assets ...&quot;</td><td>1</td><td>10607</td><td>1264</td><td>11871</td><td>0.016927</td><td>0.016927</td><td>20991.3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 8)\n",
       "+-------------------------------------------------------------------------------------+------+------------------+-------------------+------------------+------------+-----------+-------------------+\n",
       "| query_short                                                                         | runs | avg_input_tokens | avg_output_tokens | avg_total_tokens | total_cost | avg_cost  | avg_processing_ms |\n",
       "| ---                                                                                 | ---  | ---              | ---               | ---              | ---        | ---       | ---               |\n",
       "| str                                                                                 | u32  | i64              | i64               | i64              | f64        | f64       | f64               |\n",
       "+===================================================================================================================================================================================================+\n",
       "| Across its fiscal 2018-2020 10-K filings, how does Walmart Inc. explain the main... | 14   | 5431             | 790               | 6222             | 0.206779   | 0.01477   | 18606.5           |\n",
       "| How does MICROSOFT CORP describe the change in its Intelligent Cloud revenue in ... | 6    | 6940             | 381               | 7320             | 0.106381   | 0.01773   | 13496.8           |\n",
       "| Over time, how does Meta Platforms describe the regulatory and policy risks that... | 2    | 10469            | 1476              | 11945            | 0.072236   | 0.036118  | 29148.2           |\n",
       "| In their 2009 Form 10-K risk-factor disclosures, how do Radian Group, Netflix an... | 3    | 5263             | 637               | 5900             | 0.061326   | 0.020442  | 16422.9           |\n",
       "| What was Apple's total revenue and operating income in fiscal year 2017?            | 5    | 8049             | 354               | 8402             | 0.049084   | 0.0098168 | 11214.5           |\n",
       "| What does EXXON MOBIL CORP report as its total revenue in 2008, and how is this ... | 2    | 5743             | 262               | 6005             | 0.042318   | 0.021159  | 10846.5           |\n",
       "| What was Apple's total revenue in 2020?                                             | 3    | 8900             | 288               | 9188             | 0.031015   | 0.010338  | 9568.6            |\n",
       "| What was Apple's revenue in 2017?                                                   | 3    | 8549             | 324               | 8873             | 0.030508   | 0.010169  | 12661.8           |\n",
       "| Where does Tesla define Adjusted EBITDA in its 2022 Form 10-K, and how does the ... | 2    | 5961             | 300               | 6260             | 0.029849   | 0.0149245 | 10426.8           |\n",
       "| In their 2020 Form 10-K risk-factor disclosures, how do Radian Group, Netflix an... | 2    | 9190             | 1010              | 10200            | 0.028484   | 0.014242  | 29258.4           |\n",
       "| Show me Apple, Microsoft, Amazon, Alphabet, Google, and Tesla's financial perfor... | 1    | 12096            | 2863              | 14959            | 0.026411   | 0.026411  | 50156.8           |\n",
       "| What operational or supply chain risks does Walmart Inc. highlight in its 2011 R... | 1    | 4264             | 446               | 4710             | 0.019482   | 0.019482  | 21033.7           |\n",
       "| For NVIDIA and Microsoft, what were revenue, operating income, and total assets ... | 1    | 10607            | 1264              | 11871            | 0.016927   | 0.016927  | 20991.3           |\n",
       "+-------------------------------------------------------------------------------------+------+------------------+-------------------+------------------+------------+-----------+-------------------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Cost & Token Analysis by Query\n",
    "# ============================================================================\n",
    "\n",
    "# Truncate query text for readability\n",
    "df_analysis = df_success.with_columns([\n",
    "    pl.when(pl.col(\"query\").str.len_chars() > 80)\n",
    "    .then(pl.col(\"query\").str.slice(0, 80) + \"...\")\n",
    "    .otherwise(pl.col(\"query\"))\n",
    "    .alias(\"query_short\")\n",
    "])\n",
    "\n",
    "# Group by query\n",
    "df_by_query = (\n",
    "    df_analysis\n",
    "    .group_by(\"query_short\")\n",
    "    .agg([\n",
    "        pl.len().alias(\"runs\"),\n",
    "        pl.col(\"input_tokens\").mean().round(0).cast(pl.Int64).alias(\"avg_input_tokens\"),\n",
    "        pl.col(\"output_tokens\").mean().round(0).cast(pl.Int64).alias(\"avg_output_tokens\"),\n",
    "        pl.col(\"total_tokens\").mean().round(0).cast(pl.Int64).alias(\"avg_total_tokens\"),\n",
    "        pl.col(\"cost\").sum().alias(\"total_cost\"),\n",
    "        pl.col(\"cost\").mean().alias(\"avg_cost\"),\n",
    "        pl.col(\"processing_time_ms\").mean().round(1).alias(\"avg_processing_ms\"),\n",
    "    ])\n",
    "    .sort(\"total_cost\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üí∞ COST & TOKEN ANALYSIS BY QUERY\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "df_by_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c44b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ü§ñ MODEL USAGE DISTRIBUTION\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>query_count</th><th>total_tokens</th><th>total_input_tokens</th><th>total_output_tokens</th><th>total_cost</th><th>avg_cost_per_query</th><th>avg_processing_ms</th></tr><tr><td>str</td><td>u32</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>31</td><td>252006</td><td>231328</td><td>20678</td><td>0.334718</td><td>0.010797</td><td>16592.7</td></tr><tr><td>&quot;claude-sonnet-4-5-20250929-v1:0&quot;</td><td>14</td><td>93274</td><td>84419</td><td>8855</td><td>0.386082</td><td>0.027577</td><td>17905.2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 8)\n",
       "+---------------------------------+-------------+--------------+--------------------+---------------------+------------+--------------------+-------------------+\n",
       "| model_name                      | query_count | total_tokens | total_input_tokens | total_output_tokens | total_cost | avg_cost_per_query | avg_processing_ms |\n",
       "| ---                             | ---         | ---          | ---                | ---                 | ---        | ---                | ---               |\n",
       "| str                             | u32         | i64          | i64                | i64                 | f64        | f64                | f64               |\n",
       "+===============================================================================================================================================================+\n",
       "| claude-haiku-4-5-20251001-v1:0  | 31          | 252006       | 231328             | 20678               | 0.334718   | 0.010797           | 16592.7           |\n",
       "| claude-sonnet-4-5-20250929-v1:0 | 14          | 93274        | 84419              | 8855                | 0.386082   | 0.027577           | 17905.2           |\n",
       "+---------------------------------+-------------+--------------+--------------------+---------------------+------------+--------------------+-------------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Model Usage Distribution\n",
    "# ============================================================================\n",
    "\n",
    "# Extract short model name\n",
    "df_model_analysis = df_success.with_columns([\n",
    "    pl.col(\"model_id\").str.split(\".\").list.last().alias(\"model_name\")\n",
    "])\n",
    "\n",
    "# Group by model\n",
    "df_by_model = (\n",
    "    df_model_analysis\n",
    "    .group_by(\"model_name\")\n",
    "    .agg([\n",
    "        pl.len().alias(\"query_count\"),\n",
    "        pl.col(\"total_tokens\").sum().alias(\"total_tokens\"),\n",
    "        pl.col(\"input_tokens\").sum().alias(\"total_input_tokens\"),\n",
    "        pl.col(\"output_tokens\").sum().alias(\"total_output_tokens\"),\n",
    "        pl.col(\"cost\").sum().alias(\"total_cost\"),\n",
    "        pl.col(\"cost\").mean().alias(\"avg_cost_per_query\"),\n",
    "        pl.col(\"processing_time_ms\").mean().round(1).alias(\"avg_processing_ms\"),\n",
    "    ])\n",
    "    .sort(\"query_count\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ MODEL USAGE DISTRIBUTION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "df_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66592205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìÖ RECENT QUERY TIMELINE (Last 10)\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>query_preview</th><th>model</th><th>cost_$</th><th>tokens</th><th>status</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;05:28:12&quot;</td><td>&quot;What was Apple&#x27;s total revenue in 2020?&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0104</td><td>9194</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;05:23:29&quot;</td><td>&quot;What was Apple&#x27;s total revenue in 2020?&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0102</td><td>9169</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;05:21:08&quot;</td><td>&quot;What was Apple&#x27;s total revenue in 2020?&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0104</td><td>9200</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;02:52:48&quot;</td><td>&quot;Across its fiscal 2018-2020 10-K filings, how does...&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0099</td><td>6458</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;02:02:58&quot;</td><td>&quot;Across its fiscal 2018-2020 10-K filings, how does...&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0101</td><td>6489</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;01:49:24&quot;</td><td>&quot;Across its fiscal 2018-2020 10-K filings, how does...&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0101</td><td>6498</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;13:59:22&quot;</td><td>&quot;In their 2020 Form 10-K risk-factor disclosures, h...&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0146</td><td>10200</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;03:05:49&quot;</td><td>&quot;Show me Apple, Microsoft, Amazon, Alphabet, Google...&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0264</td><td>14959</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;22:39:32&quot;</td><td>&quot;How does MICROSOFT CORP describe the change in its...&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0088</td><td>7195</td><td>&quot;‚úÖ&quot;</td></tr><tr><td>&quot;20:24:22&quot;</td><td>&quot;Across its fiscal 2018-2020 10-K filings, how does...&quot;</td><td>&quot;claude-haiku-4-5-20251001-v1:0&quot;</td><td>0.0092</td><td>6143</td><td>&quot;‚úÖ&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "+----------+-------------------------------------------------------+--------------------------------+--------+--------+--------+\n",
       "| time     | query_preview                                         | model                          | cost_$ | tokens | status |\n",
       "| ---      | ---                                                   | ---                            | ---    | ---    | ---    |\n",
       "| str      | str                                                   | str                            | f64    | i64    | str    |\n",
       "+==============================================================================================================================+\n",
       "| 05:28:12 | What was Apple's total revenue in 2020?               | claude-haiku-4-5-20251001-v1:0 | 0.0104 | 9194   | ‚úÖ     |\n",
       "| 05:23:29 | What was Apple's total revenue in 2020?               | claude-haiku-4-5-20251001-v1:0 | 0.0102 | 9169   | ‚úÖ     |\n",
       "| 05:21:08 | What was Apple's total revenue in 2020?               | claude-haiku-4-5-20251001-v1:0 | 0.0104 | 9200   | ‚úÖ     |\n",
       "| 02:52:48 | Across its fiscal 2018-2020 10-K filings, how does... | claude-haiku-4-5-20251001-v1:0 | 0.0099 | 6458   | ‚úÖ     |\n",
       "| 02:02:58 | Across its fiscal 2018-2020 10-K filings, how does... | claude-haiku-4-5-20251001-v1:0 | 0.0101 | 6489   | ‚úÖ     |\n",
       "| 01:49:24 | Across its fiscal 2018-2020 10-K filings, how does... | claude-haiku-4-5-20251001-v1:0 | 0.0101 | 6498   | ‚úÖ     |\n",
       "| 13:59:22 | In their 2020 Form 10-K risk-factor disclosures, h... | claude-haiku-4-5-20251001-v1:0 | 0.0146 | 10200  | ‚úÖ     |\n",
       "| 03:05:49 | Show me Apple, Microsoft, Amazon, Alphabet, Google... | claude-haiku-4-5-20251001-v1:0 | 0.0264 | 14959  | ‚úÖ     |\n",
       "| 22:39:32 | How does MICROSOFT CORP describe the change in its... | claude-haiku-4-5-20251001-v1:0 | 0.0088 | 7195   | ‚úÖ     |\n",
       "| 20:24:22 | Across its fiscal 2018-2020 10-K filings, how does... | claude-haiku-4-5-20251001-v1:0 | 0.0092 | 6143   | ‚úÖ     |\n",
       "+----------+-------------------------------------------------------+--------------------------------+--------+--------+--------+"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Recent Query Timeline (Last 10 Queries)\n",
    "# ============================================================================\n",
    "\n",
    "# Get last 10 queries\n",
    "df_recent = df_logs.sort(\"timestamp\", descending=True).head(10)\n",
    "\n",
    "# Create display dataframe\n",
    "df_timeline = df_recent.select([\n",
    "    pl.col(\"timestamp\").str.slice(11, 8).alias(\"time\"),  # HH:MM:SS\n",
    "    pl.when(pl.col(\"query\").str.len_chars() > 50)\n",
    "      .then(pl.col(\"query\").str.slice(0, 50) + \"...\")\n",
    "      .otherwise(pl.col(\"query\"))\n",
    "      .alias(\"query_preview\"),\n",
    "    pl.col(\"model_id\").str.split(\".\").list.last().alias(\"model\"),\n",
    "    pl.col(\"cost\").round(4).alias(\"cost_$\"),\n",
    "    pl.col(\"total_tokens\").alias(\"tokens\"),\n",
    "    pl.when(pl.col(\"error\").is_null())\n",
    "      .then(pl.lit(\"‚úÖ\"))\n",
    "      .otherwise(pl.lit(\"‚ùå\"))\n",
    "      .alias(\"status\")\n",
    "])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìÖ RECENT QUERY TIMELINE (Last 10)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "df_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6b7b444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "‚úÖ NO ERRORS - All queries successful!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Error Analysis (If Any Failures)\n",
    "# ============================================================================\n",
    "\n",
    "df_errors = df_logs.filter(pl.col(\"error\").is_not_null())\n",
    "\n",
    "if len(df_errors) > 0:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚ö†Ô∏è  ERROR ANALYSIS ({len(df_errors)} failed queries)\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Group by error type\n",
    "    error_summary = (\n",
    "        df_errors\n",
    "        .group_by(\"error_type\")\n",
    "        .agg([\n",
    "            pl.len().alias(\"count\"),\n",
    "            pl.col(\"stage\").first().alias(\"typical_stage\")\n",
    "        ])\n",
    "        .sort(\"count\", descending=True)\n",
    "    )\n",
    "    \n",
    "    print(\"Errors by type:\")\n",
    "    display(error_summary)\n",
    "    \n",
    "    print(\"\\nMost recent error details:\")\n",
    "    recent_error = df_errors.sort(\"timestamp\", descending=True).head(1)\n",
    "    print(f\"  Timestamp: {recent_error['timestamp'][0]}\")\n",
    "    print(f\"  Query: {recent_error['query'][0][:100]}...\")\n",
    "    print(f\"  Error: {recent_error['error'][0]}\")\n",
    "    print(f\"  Stage: {recent_error['stage'][0]}\")\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"‚úÖ NO ERRORS - All queries successful!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb657e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42970b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32469984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea657ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935c613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae661dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
