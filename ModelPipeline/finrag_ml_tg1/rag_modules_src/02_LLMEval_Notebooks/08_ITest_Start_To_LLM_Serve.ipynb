{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ce927d",
   "metadata": {},
   "source": [
    "### Final Integration / Chain tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed858f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ca2d744",
   "metadata": {},
   "source": [
    "#### Skeleton -- Now, slightly enhanced, Study Synthesis Pipeline main.py and models, models_contract !!\n",
    "\n",
    "- Complexity is hidden inside:\n",
    "  - init_rag_components() → 6 components initialized\n",
    "  - build_combined_context() → Supply line 1 (KPI) + Supply line 2 (RAG) + assembly\n",
    "  - loader.load_system_prompt() → YAML prompt loading\n",
    "    \n",
    "```python\n",
    "# Init\n",
    "config = MLConfig()\n",
    "rag = init_rag_components(model_root)\n",
    "loader = PromptLoader()\n",
    "\n",
    "# Context\n",
    "query = \"Your question...\"\n",
    "combined_context, _ = build_combined_context(query, rag, True, True)\n",
    "\n",
    "# Prompts\n",
    "system_prompt = loader.load_system_prompt()\n",
    "user_prompt = loader.format_query_template(combined_context)\n",
    "\n",
    "# LLM\n",
    "serving_model = config.get_default_serving_model()\n",
    "llm = BedrockClient(\n",
    "    region=config.region,\n",
    "    model_id=serving_model['model_id'],\n",
    "    max_tokens=loader.get_recommended_llm_params()['max_tokens'],\n",
    "    temperature=loader.get_recommended_llm_params()['temperature']\n",
    ")\n",
    "\n",
    "# Call\n",
    "response = llm.invoke(system=system_prompt, user=user_prompt)\n",
    "answer = response['content']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c58dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPipeline root: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "Notebook location: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\01_Isolation_Test_NBS\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Setup - Path Resolution & Imports\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Suppress noisy logs for clean notebook output\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.getLogger(\"finrag_ml_tg1\").setLevel(logging.INFO)\n",
    "\n",
    "# Find ModelPipeline root and add to sys.path\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root in path tree\")\n",
    "\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"ModelPipeline root: {model_root}\")\n",
    "print(f\"Notebook location: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96857009",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e0f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPipeline root: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "\n",
      "Processing query...\n",
      "  Model: default (development_CH45 - Claude 4.5 Haiku)\n",
      "\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ KPI-JSON: Loaded 527 metric records\n",
      "✓ KPI-JSON: Unique tickers: 2\n",
      "✓ KPI-JSON: Year range: 2010-2025\n",
      "======================================================================\n",
      "FINRAG QUERY RESULT\n",
      "======================================================================\n",
      "\n",
      "Query: For NVIDIA and Microsoft, what were revenue, operating income, and total assets in each year from 20...\n",
      "\n",
      "Answer Preview:\n",
      "----------------------------------------------------------------------\n",
      "# Financial Performance and Strategic Context: NVIDIA vs. Microsoft (2018-2020)\n",
      "\n",
      "## Direct Answer\n",
      "\n",
      "Microsoft demonstrated consistent growth across all three metrics from 2018-2020, while NVIDIA experienced significant volatility. Microsoft's total assets grew from $258.8B to $301.3B, net income fluctuated between $8.9B-$13.2B, while NVIDIA's smaller scale ($11.2B-$17.3B in assets) masked dramatic operational swings, with net income declining from $1.1B (2018) to $567M (2019) before recovering to...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Metrics:\n",
      "  Model: claude-haiku-4-5-20251001-v1:0\n",
      "  Tokens: 10,607 in / 1,264 out\n",
      "  Cost: $0.0169\n",
      "  Context: 42,812 chars\n",
      "\n",
      "Exports:\n",
      "  Context: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\exports\\contexts\\context_20251119T002411.txt\n",
      "  Response: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\exports\\responses\\response_20251119T002411.json\n",
      "  Logs: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\exports\\logs\\query_logs.parquet\n",
      "======================================================================\n",
      "\n",
      "Tip: Full answer saved in exports. Context and logs available above.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Run main.py directly (with default query and model !!! )\n",
    "# ============================================================================\n",
    "\n",
    "%run ../synthesis_pipeline/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064d240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8161a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ddd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0364b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb492e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
