{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da89df5a",
   "metadata": {},
   "source": [
    "## Isolation Tests and Skeletons - Part 1.\n",
    "\n",
    "#### Supply Lines and Formatting, Connecting lines across Step 1-4 etc. towards end.\n",
    "\n",
    "```\n",
    "1. Supply Line 1 skeleton\n",
    "2. user_query → EntityAdapter → QueryEmbedderV2 → MetricPipeline → compact KPI text\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a43796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d478ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model root on sys.path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "\n",
      "[IMPORT CHECKS]\n",
      "  ✓ All module imports succeeded\n",
      "\n",
      "[PATH RESOLUTION]\n",
      "  ✓ Company dimension: finrag_dim_companies_21.parquet\n",
      "  ✓ Section dimension: finrag_dim_sec_sections.parquet\n",
      "  ✓ Metric data JSON: downloaded_data.json\n",
      "\n",
      "[CONSTRUCTION CHECKS]\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "  ✓ MLConfig()\n",
      "  ✓ EmbeddingRuntimeConfig.from_ml_config()\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "  ✓ EntityAdapter(company_dim_path, section_dim_path)\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ Loaded 527 metric records\n",
      "✓ Unique tickers: 2\n",
      "✓ Year range: 2010-2025\n",
      "  ✓ MetricPipeline(data_path, company_dim_path)\n",
      "  ✓ config.get_bedrock_client()\n",
      "  ✓ QueryEmbedderV2(runtime_cfg, boto_client)\n",
      "  ✓ BedrockClient (synthesis LLM)\n",
      "\n",
      "[SUMMARY]\n",
      "  ✓ All imports validated\n",
      "  ✓ All dimension files located\n",
      "  ✓ All core objects constructed successfully\n",
      "  ✓ No AWS/Bedrock calls were made in this cell\n",
      "\n",
      "Ready for functional tests in subsequent cells.\n"
     ]
    }
   ],
   "source": [
    "# CELL 1 — Global wiring + import/construct smoke tests\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Put ModelPipeline on sys.path\n",
    "# -------------------------------------------------------------------\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root in path tree\")\n",
    "\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"✓ Model root on sys.path: {model_root}\")\n",
    "\n",
    "# Small helper for structured checks\n",
    "def check(label, fn):\n",
    "    try:\n",
    "        obj = fn()\n",
    "        print(f\"  ✓ {label}\")\n",
    "        return obj\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {label} -> {type(e).__name__}: {e}\")\n",
    "        raise\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Core imports via finrag_ml_tg1 package\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[IMPORT CHECKS]\")\n",
    "\n",
    "# 2.1 Loaders / config\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "\n",
    "# 2.2 Entity adapter package - ALL modules\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.company_extractor import CompanyExtractor\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.company_universe import CompanyUniverse\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.section_extractor import SectionExtractor\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.section_universe import SectionUniverse\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.year_extractor import YearExtractor\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.metric_adapter import MetricAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.models import (\n",
    "    CompanyInfo,\n",
    "    CompanyMatches,\n",
    "    YearMatches,\n",
    "    MetricMatches,\n",
    "    SectionMatches,\n",
    "    RiskMatches,\n",
    ")\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.string_utils import simple_fuzzy_match\n",
    "\n",
    "# 2.3 Metric pipeline - ALL modules\n",
    "from finrag_ml_tg1.rag_modules_src.metric_pipeline.src.filter_extractor import FilterExtractor\n",
    "from finrag_ml_tg1.rag_modules_src.metric_pipeline.src.metric_lookup import MetricLookup\n",
    "from finrag_ml_tg1.rag_modules_src.metric_pipeline.src.pipeline import MetricPipeline\n",
    "from finrag_ml_tg1.rag_modules_src.metric_pipeline.config.metric_mappings import (\n",
    "    METRIC_MAPPINGS,\n",
    "    METRIC_KEYWORDS,\n",
    "    QUANTITATIVE_INDICATORS,\n",
    ")\n",
    "\n",
    "# 2.4 Constants (used by entity_adapter and metric_pipeline)\n",
    "from finrag_ml_tg1.rag_modules_src.constants.metric_mapping_v2 import (\n",
    "    METRIC_MAPPINGS as METRIC_MAPPINGS_V2,\n",
    "    SECTION_KEYWORDS,\n",
    "    SECTION_ITEM_PATTERNS,\n",
    "    RISK_TOPIC_KEYWORDS,\n",
    ")\n",
    "\n",
    "# 2.5 Utilities\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    EmbeddingRuntimeConfig,\n",
    "    QueryEmbedderV2,\n",
    "    QueryTooLongError,\n",
    "    QueryTooShortError,\n",
    "    QueryOutOfScopeError,\n",
    ")\n",
    "\n",
    "# 2.6 Synthesis / orchestration\n",
    "from finrag_ml_tg1.rag_modules_src.synthesis_pipeline.bedrock_client import BedrockClient\n",
    "from finrag_ml_tg1.rag_modules_src.synthesis_pipeline import orchestrator as synth_orchestrator\n",
    "\n",
    "print(\"  ✓ All module imports succeeded\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Compute all data paths from model_root (once, at top level)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[PATH RESOLUTION]\")\n",
    "\n",
    "# Dimension files\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "\n",
    "# Metric pipeline data\n",
    "METRIC_DATA_JSON = model_root / \"finrag_ml_tg1/rag_modules_src/metric_pipeline/data/downloaded_data.json\"\n",
    "\n",
    "# Verify critical files exist\n",
    "assert DIM_COMPANIES.exists(), f\"Missing: {DIM_COMPANIES}\"\n",
    "assert DIM_SECTIONS.exists(), f\"Missing: {DIM_SECTIONS}\"\n",
    "assert METRIC_DATA_JSON.exists(), f\"Missing: {METRIC_DATA_JSON}\"\n",
    "\n",
    "print(f\"  ✓ Company dimension: {DIM_COMPANIES.name}\")\n",
    "print(f\"  ✓ Section dimension: {DIM_SECTIONS.name}\")\n",
    "print(f\"  ✓ Metric data JSON: {METRIC_DATA_JSON.name}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Object construction smoke tests (no external calls)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[CONSTRUCTION CHECKS]\")\n",
    "\n",
    "# 4.1 MLConfig (loads YAML + env)\n",
    "config = check(\"MLConfig()\", lambda: MLConfig())\n",
    "\n",
    "# 4.2 EmbeddingRuntimeConfig from MLConfig\n",
    "def _make_runtime_cfg():\n",
    "    embedding_cfg_dict = config.cfg[\"embedding\"]\n",
    "    cfg = EmbeddingRuntimeConfig.from_ml_config(embedding_cfg_dict)\n",
    "    cfg.max_query_chars = 1500\n",
    "    return cfg\n",
    "\n",
    "runtime_cfg = check(\"EmbeddingRuntimeConfig.from_ml_config()\", _make_runtime_cfg)\n",
    "\n",
    "# 4.3 EntityAdapter (with explicit paths)\n",
    "adapter = check(\n",
    "    \"EntityAdapter(company_dim_path, section_dim_path)\",\n",
    "    lambda: EntityAdapter(\n",
    "        company_dim_path=DIM_COMPANIES,\n",
    "        section_dim_path=DIM_SECTIONS,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 4.4 MetricPipeline (with explicit paths)\n",
    "metric_pipeline = check(\n",
    "    \"MetricPipeline(data_path, company_dim_path)\",\n",
    "    lambda: MetricPipeline(\n",
    "        data_path=str(METRIC_DATA_JSON),\n",
    "        company_dim_path=str(DIM_COMPANIES),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 4.5 Bedrock runtime client from MLConfig\n",
    "bedrock_runtime_client = check(\n",
    "    \"config.get_bedrock_client()\",\n",
    "    lambda: config.get_bedrock_client(),\n",
    ")\n",
    "\n",
    "# 4.6 QueryEmbedderV2 (using shared Bedrock client)\n",
    "embedder = check(\n",
    "    \"QueryEmbedderV2(runtime_cfg, boto_client)\",\n",
    "    lambda: QueryEmbedderV2(runtime_cfg, boto_client=bedrock_runtime_client),\n",
    ")\n",
    "\n",
    "# 4.7 BedrockClient (LLM client for synthesis)\n",
    "def _make_llm_client():\n",
    "    llm_cfg = config.cfg.get(\"rag_orchestrator\", {}).get(\"llm\", {})\n",
    "    return BedrockClient(\n",
    "        region=llm_cfg.get(\"region\", config.region),\n",
    "        model_id=llm_cfg.get(\"model_id\", \"anthropic.claude-3-sonnet-20240229-v1:0\"),\n",
    "        max_tokens=llm_cfg.get(\"max_tokens\", 4096),\n",
    "        temperature=llm_cfg.get(\"temperature\", 0.7),\n",
    "    )\n",
    "\n",
    "llm_client = check(\"BedrockClient (synthesis LLM)\", _make_llm_client)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Summary\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[SUMMARY]\")\n",
    "print(\"  ✓ All imports validated\")\n",
    "print(\"  ✓ All dimension files located\")\n",
    "print(\"  ✓ All core objects constructed successfully\")\n",
    "print(\"  ✓ No AWS/Bedrock calls were made in this cell\")\n",
    "print(\"\\nReady for functional tests in subsequent cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074b60c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7606099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FUNCTIONAL TESTS]\n",
      "Testing core business logic of each pipeline component...\n",
      "\n",
      "1. EntityAdapter.extract()\n",
      "   ✓ Extracted: ['AAPL'], [2023], ['income_stmt_Revenue']\n",
      "\n",
      "2. MetricPipeline.needs_metric_layer()\n",
      "   ✓ Correctly routes quantitative vs narrative queries\n",
      "\n",
      "3. MetricPipeline.process()\n",
      "   ✓ Success! Filters: ['NVDA'], [2023], ['income_stmt_Revenue']\n",
      "   ✓ Data points returned: 1 records\n",
      "   ✓ Stats: 1/1 combinations found\n",
      "\n",
      "4. QueryEmbedderV2 validation\n",
      "   ✓ Correctly rejects too-long queries (>1500 chars)\n",
      "   ✓ Accepts valid query length\n",
      "   ✓ Correctly rejects too-long queries\n",
      "   ✓ Accepts valid query length\n",
      "\n",
      "5. CompanyUniverse lookups\n",
      "   ✓ AAPL lookup: Apple Inc. (CIK: 320193)\n",
      "   ✓ NVDA lookup: NVIDIA CORP (CIK: 1045810)\n",
      "   ✓ CIK 320193 lookup: AAPL\n",
      "   ✓ Universe contains 21 companies\n",
      "\n",
      "6. SectionUniverse validation\n",
      "   ✓ Core sections (ITEM_1, ITEM_1A, ITEM_7) validated\n",
      "   ✓ Rejects invalid section codes\n",
      "   ✓ filter_existing() works: 2/4 sections kept\n",
      "   ✓ Section universe loaded: 21 valid sections\n",
      "\n",
      "============================================================\n",
      "[FUNCTIONAL TEST SUMMARY]\n",
      "  ✓ EntityAdapter: Full NL→entity extraction working\n",
      "  ✓ MetricPipeline: Query routing + data lookup working\n",
      "  ✓ QueryEmbedderV2: Validation logic working\n",
      "  ✓ CompanyUniverse: Ticker/CIK lookups working\n",
      "  ✓ SectionUniverse: Section validation working\n",
      "============================================================\n",
      "\n",
      "All functional smoke tests passed!\n",
      "Safe to proceed with AWS-dependent tests (embeddings, vector search, LLM calls).\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 — Functional smoke tests (no AWS calls)\n",
    "\n",
    "print(\"[FUNCTIONAL TESTS]\")\n",
    "print(\"Testing core business logic of each pipeline component...\\n\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Test 1: EntityAdapter - Full extraction pipeline\n",
    "# -------------------------------------------------------------------\n",
    "print(\"1. EntityAdapter.extract()\")\n",
    "test_query = \"What was Apple's revenue in 2023?\"\n",
    "result = adapter.extract(test_query)\n",
    "\n",
    "assert len(result.companies.tickers) > 0, \"Should extract Apple ticker\"\n",
    "assert 2023 in result.years.years, \"Should extract year 2023\"\n",
    "assert len(result.metrics.metrics) > 0, \"Should extract revenue metric\"\n",
    "print(f\"   ✓ Extracted: {result.companies.tickers}, {result.years.years}, {result.metrics.metrics[:2]}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Test 2: MetricPipeline - needs_metric_layer decision logic\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n2. MetricPipeline.needs_metric_layer()\")\n",
    "quantitative_query = \"What is NVDA's revenue in 2023?\"\n",
    "narrative_query = \"Tell me about AI trends\"\n",
    "\n",
    "assert metric_pipeline.needs_metric_layer(quantitative_query) == True, \"Should activate for quantitative query\"\n",
    "assert metric_pipeline.needs_metric_layer(narrative_query) == False, \"Should skip for narrative query\"\n",
    "print(f\"   ✓ Correctly routes quantitative vs narrative queries\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Test 3: MetricPipeline - Full process() flow (with actual data lookup)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n3. MetricPipeline.process()\")\n",
    "metric_query = \"What was NVDA revenue in 2023?\"\n",
    "metric_result = metric_pipeline.process(metric_query)\n",
    "\n",
    "# Check the actual return structure\n",
    "assert 'success' in metric_result, \"Should have 'success' key\"\n",
    "assert 'query' in metric_result, \"Should have 'query' key\"\n",
    "\n",
    "if metric_result['success']:\n",
    "    assert 'filters' in metric_result, \"Should have 'filters' on success\"\n",
    "    assert 'data' in metric_result, \"Should have 'data' on success\"\n",
    "    assert 'count' in metric_result, \"Should have 'count' on success\"\n",
    "    \n",
    "    print(f\"   ✓ Success! Filters: {metric_result['filters']['tickers']}, {metric_result['filters']['years']}, {metric_result['filters']['metrics'][:2]}\")\n",
    "    print(f\"   ✓ Data points returned: {metric_result['count']} records\")\n",
    "    print(f\"   ✓ Stats: {metric_result['stats']['found_with_values']}/{metric_result['stats']['total_combinations']} combinations found\")\n",
    "else:\n",
    "    print(f\"   ⚠ Metric layer not activated: {metric_result.get('reason', 'Unknown reason')}\")\n",
    "    if 'extracted_filters' in metric_result:\n",
    "        print(f\"   Extracted: {metric_result['extracted_filters']}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Test 4: QueryEmbedderV2 - Validation logic (no Bedrock call)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n4. QueryEmbedderV2 validation\")\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    QueryTooLongError,\n",
    ")\n",
    "\n",
    "# Test too-long query (this is what validate_query actually checks)\n",
    "try:\n",
    "    long_query = \"a\" * 2000  # Exceeds max_query_chars (1500)\n",
    "    embedder.validate_query(long_query)\n",
    "    assert False, \"Should reject too-long query\"\n",
    "except QueryTooLongError:\n",
    "    print(\"   ✓ Correctly rejects too-long queries (>1500 chars)\")\n",
    "\n",
    "# Test valid query length\n",
    "valid_query = \"What was Apple's revenue in 2023?\"\n",
    "embedder.validate_query(valid_query)  # Should not raise\n",
    "print(\"   ✓ Accepts valid query length\")\n",
    "\n",
    "# Note: QueryEmbedderV2.validate_query() only checks LENGTH\n",
    "# Entity/scope validation happens in validate_scope() which needs EntityExtractionResult\n",
    "# We skip testing validate_scope() in this smoke test since it requires entity extraction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test too-long query\n",
    "try:\n",
    "    long_query = \"a\" * 2000  # Exceeds max_query_chars (1500)\n",
    "    embedder.validate_query(long_query)\n",
    "    assert False, \"Should reject too-long query\"\n",
    "except QueryTooLongError:\n",
    "    print(\"   ✓ Correctly rejects too-long queries\")\n",
    "\n",
    "# Test valid query length\n",
    "valid_query = \"What was Apple's revenue in 2023?\"\n",
    "embedder.validate_query(valid_query)  # Should not raise\n",
    "print(\"   ✓ Accepts valid query length\")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Test 5: CompanyUniverse - Lookup operations\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n5. CompanyUniverse lookups\")\n",
    "\n",
    "# Test ticker lookups (just verify they exist, don't check exact names)\n",
    "aapl = adapter.company_universe.get_by_ticker(\"AAPL\")\n",
    "assert aapl is not None, \"Should find Apple by ticker\"\n",
    "assert aapl.cik_int == 320193, f\"Expected CIK 320193 for AAPL, got {aapl.cik_int}\"\n",
    "print(f\"   ✓ AAPL lookup: {aapl.name} (CIK: {aapl.cik_int})\")\n",
    "\n",
    "nvda = adapter.company_universe.get_by_ticker(\"NVDA\")\n",
    "assert nvda is not None, \"Should find NVIDIA by ticker\"\n",
    "assert nvda.cik_int == 1045810, f\"Expected CIK 1045810 for NVDA, got {nvda.cik_int}\"\n",
    "print(f\"   ✓ NVDA lookup: {nvda.name} (CIK: {nvda.cik_int})\")\n",
    "\n",
    "# Test CIK lookup\n",
    "apple_by_cik = adapter.company_universe.get_by_cik_int(320193)\n",
    "assert apple_by_cik is not None, \"Should find Apple by CIK\"\n",
    "assert apple_by_cik.ticker == \"AAPL\", f\"Expected ticker AAPL, got {apple_by_cik.ticker}\"\n",
    "print(f\"   ✓ CIK 320193 lookup: {apple_by_cik.ticker}\")\n",
    "\n",
    "# Test that universe has expected number of companies (21 based on your JSON)\n",
    "total_companies = len(adapter.company_universe.ciks_int)\n",
    "assert total_companies == 21, f\"Expected 21 companies, got {total_companies}\"\n",
    "print(f\"   ✓ Universe contains {total_companies} companies\")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Test 6: SectionUniverse - Canonical section validation\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n6. SectionUniverse validation\")\n",
    "\n",
    "# Check some core sections exist\n",
    "assert adapter.section_universe.has(\"ITEM_7\"), \"Should have ITEM_7\"\n",
    "assert adapter.section_universe.has(\"ITEM_1A\"), \"Should have ITEM_1A\"\n",
    "assert adapter.section_universe.has(\"ITEM_1\"), \"Should have ITEM_1\"\n",
    "print(f\"   ✓ Core sections (ITEM_1, ITEM_1A, ITEM_7) validated\")\n",
    "\n",
    "# Check rejection of invalid section\n",
    "assert not adapter.section_universe.has(\"INVALID_SECTION\"), \"Should reject invalid section\"\n",
    "print(f\"   ✓ Rejects invalid section codes\")\n",
    "\n",
    "# Test filtering\n",
    "test_sections = [\"ITEM_7\", \"INVALID\", \"ITEM_1A\", \"FAKE_ITEM\"]\n",
    "valid_sections = adapter.section_universe.filter_existing(test_sections)\n",
    "assert \"ITEM_7\" in valid_sections, \"Should keep ITEM_7\"\n",
    "assert \"ITEM_1A\" in valid_sections, \"Should keep ITEM_1A\"\n",
    "assert \"INVALID\" not in valid_sections, \"Should remove INVALID\"\n",
    "assert \"FAKE_ITEM\" not in valid_sections, \"Should remove FAKE_ITEM\"\n",
    "print(f\"   ✓ filter_existing() works: {len(valid_sections)}/4 sections kept\")\n",
    "\n",
    "# Check total section count (informational, not strict assertion)\n",
    "total_sections = len(adapter.section_universe.all_canonical)\n",
    "print(f\"   ✓ Section universe loaded: {total_sections} valid sections\")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Summary\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[FUNCTIONAL TEST SUMMARY]\")\n",
    "print(\"  ✓ EntityAdapter: Full NL→entity extraction working\")\n",
    "print(\"  ✓ MetricPipeline: Query routing + data lookup working\")\n",
    "print(\"  ✓ QueryEmbedderV2: Validation logic working\")\n",
    "print(\"  ✓ CompanyUniverse: Ticker/CIK lookups working\")\n",
    "print(\"  ✓ SectionUniverse: Section validation working\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAll functional smoke tests passed!\")\n",
    "print(\"Safe to proceed with AWS-dependent tests (embeddings, vector search, LLM calls).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc2067",
   "metadata": {},
   "source": [
    "```\n",
    "Query → Extract Entities → Validate/Embed → Get KPI Data → Format → Display\n",
    "  ↓           ↓                 ↓              ↓           ↓        ↓\n",
    "adapter    entities       (optional)      pipeline    formatter  notebook\n",
    "```\n",
    "\n",
    "#### CELL 3 — Supply Line 1: Query → Entities → KPI Data → Formatted Output\n",
    "#### CELL 3 SUPPLY LINE 1: v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972c5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUPPLY LINE 1 - KPI FACT TABLE PIPELINE]\n",
      "Testing: user_query → EntityAdapter → MetricPipeline → formatted text\n",
      "\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ Loaded 527 metric records\n",
      "✓ Unique tickers: 2\n",
      "✓ Year range: 2010-2025\n",
      "✓ MetricPipeline initialized\n",
      "\n",
      "Query: What were Microsoft's and NVIDIA's total assets and revenue from 2021 to 2023?\n",
      "\n",
      "[Step 1: Entity Extraction]\n",
      "  Companies: ['MSFT', 'NVDA']\n",
      "  Years: [2021, 2022, 2023]\n",
      "  Metrics: ['balance_sheet_Total Assets', 'income_stmt_Revenue']...\n",
      "\n",
      "[Step 2: KPI Fact Table Lookup]\n",
      "  ✓ Success: 8 data points\n",
      "  Coverage: 8/12\n",
      "\n",
      "[Step 3: Format Output]\n",
      "Compact KPI Data:\n",
      "----------------------------------------------------------------------\n",
      "MSFT 2021: Total Assets=$333.8B\n",
      "MSFT 2022: Total Assets=$364.8B\n",
      "MSFT 2023: Total Assets=$412.0B\n",
      "NVDA 2021: Total Assets=$28.8B\n",
      "NVDA 2022: Total Assets=$44.2B, Revenue=$26.9B\n",
      "NVDA 2023: Total Assets=$41.2B, Revenue=$27.0B\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Token estimate: ~55 tokens\n",
      "\n",
      "[SUPPLY LINE 1 COMPLETE]\n",
      "✓ Entity extraction working\n",
      "✓ KPI fact table lookup working\n",
      "✓ Formatting utilities working\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 — Supply Line 1: Query → Entities → KPI Data → Formatted Output\n",
    "print(\"[SUPPLY LINE 1 - KPI FACT TABLE PIPELINE]\")\n",
    "print(\"Testing: user_query → EntityAdapter → MetricPipeline → formatted text\\n\")\n",
    "\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.supply_line_formatters import ( format_analytical_compact, format_value_compact, )\n",
    "from finrag_ml_tg1.rag_modules_src.metric_pipeline.src.pipeline import MetricPipeline\n",
    "\n",
    "METRIC_DATA_JSON = model_root / \"finrag_ml_tg1/rag_modules_src/metric_pipeline/data/downloaded_data.json\"\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "\n",
    "metric_pipeline = MetricPipeline( data_path=str(METRIC_DATA_JSON), company_dim_path=str(DIM_COMPANIES), )\n",
    "print(\"✓ MetricPipeline initialized\\n\")\n",
    "\n",
    "# Test Query\n",
    "test_query = \"What were Microsoft's and NVIDIA's total assets and revenue from 2021 to 2023?\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "print(\"[Step 1: Entity Extraction]\")\n",
    "entities = adapter.extract(test_query)\n",
    "print(f\"  Companies: {entities.companies.tickers}\")\n",
    "print(f\"  Years: {entities.years.years}\")\n",
    "print(f\"  Metrics: {entities.metrics.metrics[:3]}...\")  # Show first 3\n",
    "\n",
    "print(\"\\n[Step 2: KPI Fact Table Lookup]\")\n",
    "pipeline_result = metric_pipeline.process(test_query)\n",
    "\n",
    "if pipeline_result['success']:\n",
    "    print(f\"  ✓ Success: {pipeline_result['count']} data points\")\n",
    "    print(f\"  Coverage: {pipeline_result['stats']['found_with_values']}/{pipeline_result['stats']['total_combinations']}\")\n",
    "else:\n",
    "    print(f\"  ✗ Failed: {pipeline_result.get('reason', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n[Step 3: Format Output]\")\n",
    "compact_kpi_data = format_analytical_compact(pipeline_result)\n",
    "\n",
    "if compact_kpi_data:\n",
    "    print(\"Compact KPI Data:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(compact_kpi_data)\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Token estimate (useful for LLM context planning)\n",
    "    token_estimate = len(compact_kpi_data) // 4\n",
    "    print(f\"\\nToken estimate: ~{token_estimate} tokens\")\n",
    "else:\n",
    "    print(\"(No KPI data available)\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Summary\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[SUPPLY LINE 1 COMPLETE]\")\n",
    "print(\"✓ Entity extraction working\")\n",
    "print(\"✓ KPI fact table lookup working\")\n",
    "print(\"✓ Formatting utilities working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a7601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model root on sys.path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ Loaded 527 metric records\n",
      "✓ Unique tickers: 2\n",
      "✓ Year range: 2010-2025\n",
      "KPI Data:\n",
      "----------------------------------------------------------------------\n",
      "MSFT 2021: Total Assets=$333.8B\n",
      "MSFT 2022: Total Assets=$364.8B\n",
      "MSFT 2023: Total Assets=$412.0B\n",
      "NVDA 2021: Total Assets=$28.8B\n",
      "NVDA 2022: Total Assets=$44.2B, Revenue=$26.9B\n",
      "NVDA 2023: Total Assets=$41.2B, Revenue=$27.0B\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# 1. Put ModelPipeline on sys.path\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root in path tree\")\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "print(f\"✓ Model root on sys.path: {model_root}\")\n",
    "\n",
    "\n",
    "## SUPPLY LINE 1: ENTITY-RESULT CHAINING. DEMO. Query → Extract Entities → Validate/Embed → Get KPI Data → Format → Display\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.supply_line_formatters import format_analytical_compact\n",
    "from finrag_ml_tg1.rag_modules_src.metric_pipeline.src.pipeline import MetricPipeline\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "\n",
    "METRIC_DATA_JSON = model_root / \"finrag_ml_tg1/rag_modules_src/metric_pipeline/data/downloaded_data.json\"\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "\n",
    "adapter =  EntityAdapter( company_dim_path=DIM_COMPANIES, section_dim_path=DIM_SECTIONS )\n",
    "\n",
    "metric_pipeline = MetricPipeline(data_path=str(METRIC_DATA_JSON), company_dim_path=str(DIM_COMPANIES))\n",
    "\n",
    "query = \"What were Microsoft's and NVIDIA's total assets and revenue from 2021 to 2023?\"\n",
    "entities = adapter.extract(query)\n",
    "result = metric_pipeline.process(query)\n",
    "compact = format_analytical_compact(result)\n",
    "\n",
    "print(f\"KPI Data:\\n{'-'*70}\\n{compact or '(no data)'}\\n{'-'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485c2bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model root on sys.path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "between 2020 and 2023                    → [2020, 2021, 2022, 2023]\n",
      "from 2017 through 2020                   → [2017, 2018, 2019, 2020]\n",
      "2015 till 2019                           → [2015, 2016, 2017, 2018, 2019]\n",
      "during 2020-2023                         → [2020, 2021, 2022, 2023]\n",
      "revenue in 2021, 2022, and 2023          → [2021, 2022, 2023]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root in path tree\")\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "print(f\"✓ Model root on sys.path: {model_root}\")\n",
    "\n",
    "\n",
    "# Test the updated extractor\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.year_extractor import YearExtractor\n",
    "\n",
    "extractor = YearExtractor()\n",
    "\n",
    "test_phrases = [\n",
    "    \"between 2020 and 2023\",\n",
    "    \"from 2017 through 2020\",\n",
    "    \"2015 till 2019\",\n",
    "    \"during 2020-2023\",\n",
    "    \"revenue in 2021, 2022, and 2023\",\n",
    "]\n",
    "\n",
    "for phrase in test_phrases:\n",
    "    result = extractor.extract(phrase)\n",
    "    print(f\"{phrase:<40} → {result.years}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a720a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc2643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b5c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139180b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70998f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f66f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
