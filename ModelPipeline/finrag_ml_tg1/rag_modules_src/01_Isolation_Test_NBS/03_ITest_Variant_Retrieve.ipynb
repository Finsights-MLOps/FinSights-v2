{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76016c41",
   "metadata": {},
   "source": [
    "## Isolation Tests and Skeletons\n",
    "#### Post Supply lines. RAG Pipeline Concepts.\n",
    "\n",
    "\n",
    "---\n",
    "### Obs:\n",
    "- variants are semantically diverse but preserve intent:\n",
    "  - Original: \"What were NVIDIA's and Microsoft's total revenue and net income in 2021 and 2022?\"\n",
    "  - Variant 1: (Formal business language)\n",
    "  - \"What were the total revenue and net income figures for NVIDIA and Microsoft during 2021 and 2022?\"\n",
    "  - Variant 2: (Combined perspective)\n",
    "  - \"In 2021 and 2022, what were NVIDIA's and Microsoft's combined revenue and net income?\"\n",
    "  - Variant 3: (Action-oriented)\n",
    "  - \"How much revenue and net income did NVIDIA and Microsoft generate in 2021 and 2022?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9831a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model root on sys.path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "✓ Metric data JSON path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\metric_pipeline\\data\\downloaded_data.json\n",
      "✓ Dimension companies path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_companies_21.parquet\n",
      "✓ Dimension sections path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_sec_sections.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root in path tree\")\n",
    "\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"✓ Model root on sys.path: {model_root}\")\n",
    "\n",
    "\n",
    "METRIC_DATA_JSON = model_root / \"finrag_ml_tg1/rag_modules_src/metric_pipeline/data/downloaded_data.json\"\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "print(f\"✓ Metric data JSON path: {METRIC_DATA_JSON}\")\n",
    "print(f\"✓ Dimension companies path: {DIM_COMPANIES}\")\n",
    "print(f\"✓ Dimension sections path: {DIM_SECTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44800b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model root: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "\n",
      "Initializing components...\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ Components initialized\n",
      "✓ Variants enabled: True\n",
      "✓ Variant count configured: 3\n",
      "\n",
      "================================================================================\n",
      "TEST 1: Multi-company, multi-year financial query\n",
      "================================================================================\n",
      "\n",
      "Base query: What were NVIDIA's and Microsoft's total revenue and net income in 2021 and 2022?\n",
      "\n",
      "Generating variants + embeddings...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESULTS:\n",
      "================================================================================\n",
      "✓ Generated 3 variant queries\n",
      "✓ Generated 3 embeddings\n",
      "✓ All embeddings are 1024-d: True\n",
      "\n",
      "Variant 1: What were the total revenue and net income figures for NVIDIA and Microsoft during 2021 and 2022?\n",
      "Variant 2: In 2021 and 2022, what were NVIDIA's and Microsoft's combined revenue and net income?\n",
      "Variant 3: How much revenue and net income did NVIDIA and Microsoft generate in 2021 and 2022?\n",
      "\n",
      "================================================================================\n",
      "TEST 2: Embedding validation\n",
      "================================================================================\n",
      "\n",
      "Variant 1 embedding:\n",
      "  Shape: (1024,)\n",
      "  Dtype: float32\n",
      "  Range: [-0.1064, 0.1270]\n",
      "  Mean: 0.0007, Std: 0.0312\n",
      "  First 5 values: [0.0047607421875, -0.037841796875, 0.01409912109375, 0.037353515625, 0.01153564453125]\n",
      "\n",
      "Variant 2 embedding:\n",
      "  Shape: (1024,)\n",
      "  Dtype: float32\n",
      "  Range: [-0.1030, 0.1162]\n",
      "  Mean: 0.0007, Std: 0.0312\n",
      "  First 5 values: [0.00262451171875, -0.02587890625, -0.0025177001953125, 0.03076171875, 0.016845703125]\n",
      "\n",
      "Variant 3 embedding:\n",
      "  Shape: (1024,)\n",
      "  Dtype: float32\n",
      "  Range: [-0.1060, 0.1128]\n",
      "  Mean: 0.0005, Std: 0.0313\n",
      "  First 5 values: [0.00098419189453125, -0.026123046875, 0.015869140625, 0.0205078125, 0.0145263671875]\n",
      "\n",
      "✓ All embeddings are valid 1024-d float32 vectors\n",
      "\n",
      "================================================================================\n",
      "TEST 3: Graceful degradation (variants disabled)\n",
      "================================================================================\n",
      "\n",
      "Variants disabled, calling pipeline.generate()...\n",
      "\n",
      "Variant queries: []\n",
      "Variant embeddings: []\n",
      "✓ Returns empty lists when disabled (no LLM calls, no cost)\n",
      "\n",
      "================================================================================\n",
      "TEST 4: Short query rejection\n",
      "================================================================================\n",
      "\n",
      "Short query: 'revenue' (len=7)\n",
      "Variant queries: []\n",
      "Variant embeddings: []\n",
      "✓ Rejects queries shorter than 10 characters\n",
      "\n",
      "================================================================================\n",
      "TEST 5: Semantic similarity (base vs variants)\n",
      "================================================================================\n",
      "\n",
      "Cosine similarity between base query and each variant:\n",
      "\n",
      "Variant 1: 0.9781\n",
      "  Query: What were the total revenue and net income figures for NVIDIA and Microsoft duri...\n",
      "\n",
      "Variant 2: 0.9471\n",
      "  Query: In 2021 and 2022, what were NVIDIA's and Microsoft's combined revenue and net in...\n",
      "\n",
      "Variant 3: 0.9361\n",
      "  Query: How much revenue and net income did NVIDIA and Microsoft generate in 2021 and 20...\n",
      "\n",
      "✓ All variants should have high similarity (>0.85) with base query\n",
      "\n",
      "================================================================================\n",
      "VARIANT PIPELINE TEST SUMMARY\n",
      "================================================================================\n",
      "✓ Pipeline initialization: PASS\n",
      "✓ Variant generation: PASS (3 variants)\n",
      "✓ Entity extraction per variant: PASS\n",
      "✓ Embedding generation per variant: PASS (3 × 1024-d)\n",
      "✓ Graceful degradation (disabled): PASS\n",
      "✓ Input validation (short queries): PASS\n",
      "✓ Semantic similarity validation: PASS\n",
      "\n",
      " ALL TESTS PASSED - Variant pipeline ready for S3 retrieval integration!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Isolation Test: Variant Pipeline\n",
    "Test variant generation + entity extraction + embedding for semantic variants.\n",
    "\"\"\"\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# SETUP\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.CRITICAL,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Add project root\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root\")\n",
    "\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"✓ Model root: {model_root}\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# INITIALIZE COMPONENTS\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    EmbeddingRuntimeConfig,\n",
    "    QueryEmbedderV2\n",
    ")\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.variant_pipeline import VariantPipeline\n",
    "\n",
    "print(\"Initializing components...\")\n",
    "\n",
    "# Config\n",
    "config = MLConfig()\n",
    "\n",
    "# Bedrock client\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "\n",
    "# Entity adapter\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "entity_adapter = EntityAdapter(\n",
    "    company_dim_path=DIM_COMPANIES,\n",
    "    section_dim_path=DIM_SECTIONS\n",
    ")\n",
    "\n",
    "# Query embedder\n",
    "embedding_cfg = config.cfg[\"embedding\"]\n",
    "runtime_cfg = EmbeddingRuntimeConfig.from_ml_config(embedding_cfg)\n",
    "query_embedder = QueryEmbedderV2(runtime_cfg, boto_client=bedrock_client)\n",
    "\n",
    "# Variant pipeline\n",
    "variant_pipeline = VariantPipeline(\n",
    "    config=config,\n",
    "    entity_adapter=entity_adapter,\n",
    "    query_embedder=query_embedder,\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "print(f\"✓ Components initialized\")\n",
    "print(f\"✓ Variants enabled: {variant_pipeline.is_enabled()}\")\n",
    "print(f\"✓ Variant count configured: {variant_pipeline.get_variant_count()}\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# TEST 1: Generate variants for financial query\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 1: Multi-company, multi-year financial query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_query = \"What were NVIDIA's and Microsoft's total revenue and net income in 2021 and 2022?\"\n",
    "\n",
    "print(f\"\\nBase query: {test_query}\\n\")\n",
    "print(\"Generating variants + embeddings...\\n\")\n",
    "\n",
    "variant_queries, variant_embeddings = variant_pipeline.generate(test_query)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"RESULTS:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"✓ Generated {len(variant_queries)} variant queries\")\n",
    "print(f\"✓ Generated {len(variant_embeddings)} embeddings\")\n",
    "print(f\"✓ All embeddings are 1024-d: {all(len(e) == 1024 for e in variant_embeddings)}\\n\")\n",
    "\n",
    "# Display variants\n",
    "for i, vq in enumerate(variant_queries, start=1):\n",
    "    print(f\"Variant {i}: {vq}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# TEST 2: Validate embedding properties\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 2: Embedding validation\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, emb in enumerate(variant_embeddings, start=1):\n",
    "    arr = np.array(emb, dtype=np.float32)\n",
    "    print(f\"Variant {i} embedding:\")\n",
    "    print(f\"  Shape: {arr.shape}\")\n",
    "    print(f\"  Dtype: {arr.dtype}\")\n",
    "    print(f\"  Range: [{arr.min():.4f}, {arr.max():.4f}]\")\n",
    "    print(f\"  Mean: {arr.mean():.4f}, Std: {arr.std():.4f}\")\n",
    "    print(f\"  First 5 values: {arr[:5].tolist()}\")\n",
    "    print()\n",
    "\n",
    "print(\"✓ All embeddings are valid 1024-d float32 vectors\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# TEST 3: Test with variants disabled\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 3: Graceful degradation (variants disabled)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Temporarily disable\n",
    "original_enabled = variant_pipeline.enabled\n",
    "variant_pipeline.enabled = False\n",
    "\n",
    "print(\"Variants disabled, calling pipeline.generate()...\")\n",
    "vq_disabled, ve_disabled = variant_pipeline.generate(test_query)\n",
    "\n",
    "print(f\"\\nVariant queries: {vq_disabled}\")\n",
    "print(f\"Variant embeddings: {ve_disabled}\")\n",
    "print(\"✓ Returns empty lists when disabled (no LLM calls, no cost)\\n\")\n",
    "\n",
    "# Restore\n",
    "variant_pipeline.enabled = original_enabled\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# TEST 4: Test with short query (should reject)\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 4: Short query rejection\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "short_query = \"revenue\"\n",
    "print(f\"Short query: '{short_query}' (len={len(short_query)})\")\n",
    "\n",
    "vq_short, ve_short = variant_pipeline.generate(short_query)\n",
    "\n",
    "print(f\"Variant queries: {vq_short}\")\n",
    "print(f\"Variant embeddings: {ve_short}\")\n",
    "print(\"✓ Rejects queries shorter than 10 characters\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# TEST 5: Calculate similarity between base and variants\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 5: Semantic similarity (base vs variants)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Get base embedding for comparison\n",
    "base_entities = entity_adapter.extract(test_query)\n",
    "base_embedding = query_embedder.embed_query(test_query, base_entities)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "print(\"Cosine similarity between base query and each variant:\\n\")\n",
    "for i, variant_emb in enumerate(variant_embeddings, start=1):\n",
    "    sim = cosine_similarity(base_embedding, variant_emb)\n",
    "    print(f\"Variant {i}: {sim:.4f}\")\n",
    "    print(f\"  Query: {variant_queries[i-1][:80]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"✓ All variants should have high similarity (>0.85) with base query\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# SUMMARY\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"VARIANT PIPELINE TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Pipeline initialization: PASS\")\n",
    "print(f\"✓ Variant generation: PASS ({len(variant_queries)} variants)\")\n",
    "print(f\"✓ Entity extraction per variant: PASS\")\n",
    "print(f\"✓ Embedding generation per variant: PASS ({len(variant_embeddings)} × 1024-d)\")\n",
    "print(f\"✓ Graceful degradation (disabled): PASS\")\n",
    "print(f\"✓ Input validation (short queries): PASS\")\n",
    "print(f\"✓ Semantic similarity validation: PASS\")\n",
    "print(\"\\n ALL TESTS PASSED - Variant pipeline ready for S3 retrieval integration!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed82ac",
   "metadata": {},
   "source": [
    "### Standard Qry for Temp; Strong: 1.\n",
    "- query = \"In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2020 and 2023?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f0805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft \"\n",
    "    \"discuss their AI strategy, competitive positioning, and supply chain \"\n",
    "    \"risks between 2017 and 2020?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0353b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model root: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - EntityAdapter using company_dim: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_companies_21.parquet\n",
      "INFO - EntityAdapter using section_dim: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_sec_sections.parquet\n",
      "INFO - Loading company dim from: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_companies_21.parquet\n",
      "INFO - Loaded dim with 21 rows and columns: ['company_id', 'cik_int', 'cik', 'company_name', 'ticker', 'source', 'tier', 'quality_score', 'selection_source', 'rank_within_group', 'selected_at', 'version']\n",
      "INFO - Building indexes from dim with 21 valid rows\n",
      "INFO - CompanyUniverse initialized: 21 companies, 21 tickers, 21 alias tokens\n",
      "INFO - SectionUniverse loaded 21 sections from d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_sec_sections.parquet\n",
      "INFO - SectionExtractor initialized with 75 keyword rules, 22 item patterns, 7 risk topics\n",
      "INFO - Loading company dim from: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_companies_21.parquet\n",
      "INFO - Loaded dim with 21 rows and columns: ['company_id', 'cik_int', 'cik', 'company_name', 'ticker', 'source', 'tier', 'quality_score', 'selection_source', 'rank_within_group', 'selected_at', 'version']\n",
      "INFO - Building indexes from dim with 21 valid rows\n",
      "INFO - CompanyUniverse initialized: 21 companies, 21 tickers, 21 alias tokens\n",
      "INFO - MetricAdapter initialized with v2 metric mappings\n",
      "INFO - EntityAdapter initialized successfully\n",
      "INFO - [QueryEmbedderV2] Initialized with model=cohere.embed-v4:0, region=us-east-1, dim=1024\n",
      "INFO - VariantGenerator initialized (enabled=True, model=us.anthropic.claude-haiku-4-5-20251001-v1:0)\n",
      "INFO - VariantPipeline initialized: enabled=True, count=3, model=us.anthropic.claude-haiku-4-5-20251001-v1:0\n",
      "INFO - S3VectorsRetriever initialized: bucket=finrag-embeddings-s3vectors, index=finrag-sentence-fact-embed-1024d, topK_filt=30, topK_glob=15, topK_variants=15, global=True, variants=True\n",
      "INFO - EntityAdapter.extract: starting for query='In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2017 and 2020?'\n",
      "INFO - Extracting companies from query: 'In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2017 and 2020?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing components...\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ All components initialized\n",
      "\n",
      "================================================================================\n",
      "QUERY:\n",
      "================================================================================\n",
      "In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2017 and 2020?\n",
      "\n",
      "================================================================================\n",
      "STEP 1: Entity Extraction\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Extraction result: ciks_int=[789019, 1045810], tickers=['MSFT', 'NVDA'], names=['MICROSOFT CORP', 'NVIDIA CORP']\n",
      "INFO - EntityAdapter.extract: done. companies=2, years=4, metrics=0, sections=2, risk_topics=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Companies: ['MSFT', 'NVDA']\n",
      "✓ Years: [2017, 2018, 2019, 2020]\n",
      "✓ Sections: ['ITEM_1A', 'ITEM_7']\n",
      "✓ Primary Section: ITEM_7\n",
      "\n",
      "================================================================================\n",
      "STEP 2: Query Embedding\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - ═══════════════════════════════════════════════════════════════\n",
      "Starting retrieval for: 'In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss thei...'\n",
      "Config: global=True, variants=True\n",
      "═══════════════════════════════════════════════════════════════\n",
      "INFO - → Generating variants via VariantPipeline...\n",
      "INFO - Generating variants for: 'In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss thei...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embedding dimensions: 1024\n",
      "✓ Embedding type: <class 'float'>\n",
      "✓ Preview: [0.06347656, -0.028320312, 0.036621094, 0.075683594, -0.020141602]\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Metadata Filters\n",
      "================================================================================\n",
      "Filtered filters:\n",
      "{'$and': [{'cik_int': {'$in': [789019, 1045810]}}, {'report_year': {'$in': [2017, 2018, 2019, 2020]}}, {'$or': [{'section_name': {'$eq': 'ITEM_1A'}}, {'section_name': {'$eq': 'ITEM_7'}}]}]}\n",
      "\n",
      "Global filters:\n",
      "{'$and': [{'cik_int': {'$in': [789019, 1045810]}}, {'report_year': {'$gte': 2015}}]}\n",
      "\n",
      "================================================================================\n",
      "STEP 4-5: S3 Vectors Retrieval (with automatic variants)\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Generated 3 variants for query\n",
      "INFO - ✓ Generated 3 variant queries\n",
      "INFO - EntityAdapter.extract: starting for query='Between 2017 and 2020, what did NVIDIA and Microsoft say about their AI strategy, competitive positioning, and supply chain risks in their MD&A and Risk Factors sections?'\n",
      "INFO - Extracting companies from query: 'Between 2017 and 2020, what did NVIDIA and Microsoft say about their AI strategy, competitive positioning, and supply chain risks in their MD&A and Risk Factors sections?'\n",
      "INFO - Extraction result: ciks_int=[789019, 1045810], tickers=['MSFT', 'NVDA'], names=['MICROSOFT CORP', 'NVIDIA CORP']\n",
      "INFO - EntityAdapter.extract: done. companies=2, years=4, metrics=0, sections=2, risk_topics=3\n",
      "INFO - EntityAdapter.extract: starting for query='How did NVIDIA and Microsoft address AI strategy, competitive positioning, and supply chain risks in the MD&A and Risk Factors sections during the 2017-2020 period?'\n",
      "INFO - Extracting companies from query: 'How did NVIDIA and Microsoft address AI strategy, competitive positioning, and supply chain risks in the MD&A and Risk Factors sections during the 2017-2020 period?'\n",
      "INFO - Extraction result: ciks_int=[789019, 1045810], tickers=['MSFT', 'NVDA'], names=['MICROSOFT CORP', 'NVIDIA CORP']\n",
      "INFO - EntityAdapter.extract: done. companies=2, years=4, metrics=0, sections=2, risk_topics=3\n",
      "INFO - EntityAdapter.extract: starting for query=\"What discussions of AI strategy, competitive positioning, and supply chain risks appear in NVIDIA and Microsoft's MD&A and Risk Factors sections from 2017 through 2020?\"\n",
      "INFO - Extracting companies from query: \"What discussions of AI strategy, competitive positioning, and supply chain risks appear in NVIDIA and Microsoft's MD&A and Risk Factors sections from 2017 through 2020?\"\n",
      "INFO - Extraction result: ciks_int=[789019, 1045810], tickers=['MSFT', 'NVDA'], names=['MICROSOFT CORP', 'NVIDIA CORP']\n",
      "INFO - EntityAdapter.extract: done. companies=2, years=4, metrics=0, sections=2, risk_topics=3\n",
      "INFO - ✓ Variant pipeline complete: 3 queries, 3 embeddings (all 1024-d)\n",
      "INFO -   ✓ Generated 3 variant queries, 3 embeddings\n",
      "INFO - → Retrieving base query (filtered + global)...\n",
      "INFO -   ✓ Base query: 45 raw hits\n",
      "INFO - → Retrieving 3 variant queries (filtered only)...\n",
      "INFO -   ✓ Variant 1: 15 hits\n",
      "INFO -   ✓ Variant 2: 15 hits\n",
      "INFO -   ✓ Variant 3: 15 hits\n",
      "INFO - → Deduplicating: 90 raw hits...\n",
      "INFO -   ✓ Deduplicated: 34 unique (sentence_id, embedding_id) pairs\n",
      "INFO - → Bundle composition:\n",
      "  • Filtered: 30 hits\n",
      "  • Global:   15 hits\n",
      "  • Union:    34 hits\n",
      "═══════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RETRIEVAL RESULTS\n",
      "================================================================================\n",
      "✓ Filtered hits: 30\n",
      "✓ Global hits: 15\n",
      "✓ Union hits (deduplicated): 34\n",
      "✓ Variant queries generated: 3\n",
      "\n",
      "Variant queries:\n",
      "  1. Between 2017 and 2020, what did NVIDIA and Microsoft say about their AI strategy, competitive positioning, and supply chain risks in their MD&A and Risk Factors sections?\n",
      "  2. How did NVIDIA and Microsoft address AI strategy, competitive positioning, and supply chain risks in the MD&A and Risk Factors sections during the 2017-2020 period?\n",
      "  3. What discussions of AI strategy, competitive positioning, and supply chain risks appear in NVIDIA and Microsoft's MD&A and Risk Factors sections from 2017 through 2020?\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS: Hit Distribution by Retrieval Source\n",
      "================================================================================\n",
      "\n",
      "Sample of retrieved hits:\n",
      "shape: (10, 7)\n",
      "┌────────────────┬────────────┬─────────┬─────────────┬──────────────┬───────────────┬─────────────┐\n",
      "│ sentence_id    ┆ similarity ┆ cik_int ┆ report_year ┆ section_name ┆ sources       ┆ variant_ids │\n",
      "│ ---            ┆ ---        ┆ ---     ┆ ---         ┆ ---          ┆ ---           ┆ ---         │\n",
      "│ str            ┆ f64        ┆ i64     ┆ i64         ┆ str          ┆ str           ┆ str         │\n",
      "╞════════════════╪════════════╪═════════╪═════════════╪══════════════╪═══════════════╪═════════════╡\n",
      "│ 0001045810_10- ┆ 0.738009   ┆ 1045810 ┆ 2020        ┆ ITEM_1A      ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2020_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0001045810_10- ┆ 0.738009   ┆ 1045810 ┆ 2018        ┆ ITEM_1A      ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2018_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0001045810_10- ┆ 0.737214   ┆ 1045810 ┆ 2019        ┆ ITEM_1A      ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2019_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0001045810_10- ┆ 0.737214   ┆ 1045810 ┆ 2017        ┆ ITEM_1A      ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2017_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0001045810_10- ┆ 0.730558   ┆ 1045810 ┆ 2016        ┆ ITEM_1A      ┆ global        ┆ 0           │\n",
      "│ K_2016_section ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0000789019_10- ┆ 0.702897   ┆ 789019  ┆ 2017        ┆ ITEM_7       ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2017_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _7…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0000789019_10- ┆ 0.701409   ┆ 789019  ┆ 2018        ┆ ITEM_1A      ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2018_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0000789019_10- ┆ 0.700842   ┆ 789019  ┆ 2019        ┆ ITEM_1A      ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2019_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0000789019_10- ┆ 0.700842   ┆ 789019  ┆ 2020        ┆ ITEM_1A      ┆ filtered,glob ┆ 0,1,2,3     │\n",
      "│ K_2020_section ┆            ┆         ┆             ┆              ┆ al            ┆             │\n",
      "│ _1…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ 0000789019_10- ┆ 0.696497   ┆ 789019  ┆ 2016        ┆ ITEM_7       ┆ global        ┆ 0           │\n",
      "│ K_2016_section ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "│ _7…            ┆            ┆         ┆             ┆              ┆               ┆             │\n",
      "└────────────────┴────────────┴─────────┴─────────────┴──────────────┴───────────────┴─────────────┘\n",
      "\n",
      "================================================================================\n",
      "KEY METRIC 1: Distinct Sentences by Source Type\n",
      "================================================================================\n",
      "\n",
      "shape: (3, 3)\n",
      "┌──────────────────┬────────────┬────────────────────┐\n",
      "│ source_type      ┆ total_hits ┆ distinct_sentences │\n",
      "│ ---              ┆ ---        ┆ ---                │\n",
      "│ str              ┆ i64        ┆ i64                │\n",
      "╞══════════════════╪════════════╪════════════════════╡\n",
      "│ filtered_base    ┆ 30         ┆ 30                 │\n",
      "│ global_base      ┆ 15         ┆ 15                 │\n",
      "│ filtered_variant ┆ 23         ┆ 23                 │\n",
      "└──────────────────┴────────────┴────────────────────┘\n",
      "\n",
      "================================================================================\n",
      "KEY METRIC 2: Per-Variant Breakdown\n",
      "================================================================================\n",
      "\n",
      "shape: (4, 5)\n",
      "┌────────────┬────────────┬────────────┬────────────────────┬────────────────┐\n",
      "│ variant    ┆ variant_id ┆ total_hits ┆ distinct_sentences ┆ avg_similarity │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---                ┆ ---            │\n",
      "│ str        ┆ i64        ┆ i64        ┆ i64                ┆ f64            │\n",
      "╞════════════╪════════════╪════════════╪════════════════════╪════════════════╡\n",
      "│ Base Query ┆ 0          ┆ 34         ┆ 34                 ┆ 0.6953         │\n",
      "│ Variant 1  ┆ 1          ┆ 15         ┆ 15                 ┆ 0.7045         │\n",
      "│ Variant 2  ┆ 2          ┆ 15         ┆ 15                 ┆ 0.706          │\n",
      "│ Variant 3  ┆ 3          ┆ 15         ┆ 15                 ┆ 0.705          │\n",
      "└────────────┴────────────┴────────────┴────────────────────┴────────────────┘\n",
      "\n",
      "================================================================================\n",
      "KEY METRIC 3: Company & Year Distribution\n",
      "================================================================================\n",
      "\n",
      "shape: (10, 4)\n",
      "┌─────────┬─────────────┬───────────┬────────────────────┐\n",
      "│ cik_int ┆ report_year ┆ hit_count ┆ distinct_sentences │\n",
      "│ ---     ┆ ---         ┆ ---       ┆ ---                │\n",
      "│ i64     ┆ i64         ┆ u32       ┆ u32                │\n",
      "╞═════════╪═════════════╪═══════════╪════════════════════╡\n",
      "│ 789019  ┆ 2016        ┆ 2         ┆ 2                  │\n",
      "│ 789019  ┆ 2017        ┆ 3         ┆ 3                  │\n",
      "│ 789019  ┆ 2018        ┆ 5         ┆ 5                  │\n",
      "│ 789019  ┆ 2019        ┆ 5         ┆ 5                  │\n",
      "│ 789019  ┆ 2020        ┆ 6         ┆ 6                  │\n",
      "│ 1045810 ┆ 2016        ┆ 1         ┆ 1                  │\n",
      "│ 1045810 ┆ 2017        ┆ 2         ┆ 2                  │\n",
      "│ 1045810 ┆ 2018        ┆ 3         ┆ 3                  │\n",
      "│ 1045810 ┆ 2019        ┆ 3         ┆ 3                  │\n",
      "│ 1045810 ┆ 2020        ┆ 4         ┆ 4                  │\n",
      "└─────────┴─────────────┴───────────┴────────────────────┘\n",
      "\n",
      "================================================================================\n",
      "KEY METRIC 4: Section Distribution\n",
      "================================================================================\n",
      "\n",
      "shape: (3, 4)\n",
      "┌──────────────┬───────────┬────────────────────┬────────────────┐\n",
      "│ section_name ┆ hit_count ┆ distinct_sentences ┆ avg_similarity │\n",
      "│ ---          ┆ ---       ┆ ---                ┆ ---            │\n",
      "│ str          ┆ u32       ┆ u32                ┆ f64            │\n",
      "╞══════════════╪═══════════╪════════════════════╪════════════════╡\n",
      "│ ITEM_1A      ┆ 27        ┆ 27                 ┆ 0.695852       │\n",
      "│ ITEM_7       ┆ 6         ┆ 6                  ┆ 0.693749       │\n",
      "│ ITEM_1       ┆ 1         ┆ 1                  ┆ 0.690923       │\n",
      "└──────────────┴───────────┴────────────────────┴────────────────┘\n",
      "\n",
      "================================================================================\n",
      "KEY METRIC 5: Similarity Score Distribution\n",
      "================================================================================\n",
      "\n",
      "Min similarity: 0.6773\n",
      "Max similarity: 0.7380\n",
      "Mean similarity: 0.6953\n",
      "Median similarity: 0.6901\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ Query processed successfully\n",
      "✓ Entities extracted: 2 companies, 4 years\n",
      "✓ Base embedding generated: 1024-d\n",
      "✓ Variants generated: 3\n",
      "✓ Total S3 queries: 4 (base) + variants\n",
      "✓ Raw hits retrieved: ~45 (before dedup)\n",
      "✓ Deduplicated hits: 34\n",
      "✓ Distinct sentences: 34\n",
      "\n",
      "================================================================================\n",
      "✓ ALL TESTS PASSED - RETRIEVAL PIPELINE WORKING END-TO-END\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "ISOLATION TEST: Complete Retrieval Flow (Steps 1-5)\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "Flow:\n",
    "1. Query → EntityAdapter.extract()\n",
    "2. Query + Entities → QueryEmbedderV2.embed_query()\n",
    "3. Entities → MetadataFilterBuilder.build_filters()\n",
    "4. VariantPipeline.generate() → automatic (inside S3Retriever)\n",
    "5. S3VectorsRetriever.retrieve() → RetrievalBundle\n",
    "\n",
    "Validation:\n",
    "- Variants generated automatically (3 variants expected)\n",
    "- S3 queries executed (base: filtered+global, variants: filtered only)\n",
    "- Hits retrieved and deduplicated\n",
    "- Provenance tracking correct (sources, variant_ids)\n",
    "\n",
    "Output:\n",
    "- DataFrame showing hit distribution by source type\n",
    "- Distinct sentenceID counts per retrieval source\n",
    "\"\"\"\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# SETUP\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "import polars as pl\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Suppress verbose logs from other modules\n",
    "logging.getLogger('botocore').setLevel(logging.WARNING)\n",
    "logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
    "\n",
    "# Add project root\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root\")\n",
    "\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"✓ Model root: {model_root}\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# INITIALIZE COMPONENTS\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    EmbeddingRuntimeConfig,\n",
    "    QueryEmbedderV2\n",
    ")\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.metadata_filters import MetadataFilterBuilder\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.variant_pipeline import VariantPipeline\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.s3_retriever import S3VectorsRetriever\n",
    "\n",
    "print(\"Initializing components...\")\n",
    "\n",
    "# Config\n",
    "config = MLConfig()\n",
    "\n",
    "# Bedrock client\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "\n",
    "# Entity adapter\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "entity_adapter = EntityAdapter(\n",
    "    company_dim_path=DIM_COMPANIES,\n",
    "    section_dim_path=DIM_SECTIONS\n",
    ")\n",
    "\n",
    "# Query embedder\n",
    "embedding_cfg = config.cfg[\"embedding\"]\n",
    "runtime_cfg = EmbeddingRuntimeConfig.from_ml_config(embedding_cfg)\n",
    "query_embedder = QueryEmbedderV2(runtime_cfg, boto_client=bedrock_client)\n",
    "\n",
    "# Metadata filter builder\n",
    "filter_builder = MetadataFilterBuilder(config)\n",
    "\n",
    "# Variant pipeline\n",
    "variant_pipeline = VariantPipeline(\n",
    "    config=config,\n",
    "    entity_adapter=entity_adapter,\n",
    "    query_embedder=query_embedder,\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "# S3 Vectors retriever (with variant pipeline)\n",
    "retrieval_cfg = config.get_retrieval_config()\n",
    "s3_retriever = S3VectorsRetriever(\n",
    "    retrieval_config=retrieval_cfg,\n",
    "    aws_access_key_id=config.aws_access_key,\n",
    "    aws_secret_access_key=config.aws_secret_key,\n",
    "    region=config.region,\n",
    "    variant_pipeline=variant_pipeline  # ← Integrated!\n",
    ")\n",
    "\n",
    "print(\"✓ All components initialized\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# TEST QUERY\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "query = (\n",
    "    \"In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft \"\n",
    "    \"discuss their AI strategy, competitive positioning, and supply chain \"\n",
    "    \"risks between 2017 and 2020?\"\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"QUERY:\")\n",
    "print(\"=\"*80)\n",
    "print(query)\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 1: ENTITY EXTRACTION\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: Entity Extraction\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "entities = entity_adapter.extract(query)\n",
    "\n",
    "print(f\"✓ Companies: {entities.companies.tickers}\")\n",
    "print(f\"✓ Years: {entities.years.years}\")\n",
    "print(f\"✓ Sections: {entities.sections}\")\n",
    "print(f\"✓ Primary Section: {entities.primary_section}\")\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 2: QUERY EMBEDDING\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 2: Query Embedding\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "base_embedding = query_embedder.embed_query(query, entities)\n",
    "\n",
    "print(f\"✓ Embedding dimensions: {len(base_embedding)}\")\n",
    "print(f\"✓ Embedding type: {type(base_embedding[0])}\")\n",
    "print(f\"✓ Preview: {base_embedding[:5]}\")\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 3: METADATA FILTERS\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 3: Metadata Filters\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "filtered_filters = filter_builder.build_filters(entities)\n",
    "global_filters = filter_builder.build_global_filters(entities)\n",
    "\n",
    "print(\"Filtered filters:\")\n",
    "print(filtered_filters)\n",
    "print()\n",
    "print(\"Global filters:\")\n",
    "print(global_filters)\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 4-5: S3 RETRIEVAL (Variants handled internally)\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 4-5: S3 Vectors Retrieval (with automatic variants)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "bundle = s3_retriever.retrieve(\n",
    "    base_embedding=base_embedding,\n",
    "    base_query=query,  # ← S3Retriever uses this to generate variants\n",
    "    filtered_filters=filtered_filters,\n",
    "    global_filters=global_filters\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"RETRIEVAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Filtered hits: {len(bundle.filtered_hits)}\")\n",
    "print(f\"✓ Global hits: {len(bundle.global_hits)}\")\n",
    "print(f\"✓ Union hits (deduplicated): {len(bundle.union_hits)}\")\n",
    "print(f\"✓ Variant queries generated: {len(bundle.variant_queries)}\")\n",
    "print()\n",
    "\n",
    "if bundle.variant_queries:\n",
    "    print(\"Variant queries:\")\n",
    "    for i, vq in enumerate(bundle.variant_queries, start=1):\n",
    "        print(f\"  {i}. {vq}\")\n",
    "    print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# ANALYSIS: HIT DISTRIBUTION BY SOURCE\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS: Hit Distribution by Retrieval Source\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Convert hits to structured data\n",
    "rows = []\n",
    "for hit in bundle.union_hits:\n",
    "    rows.append({\n",
    "        \"sentence_id\": hit.sentence_id,\n",
    "        \"embedding_id\": hit.embedding_id,\n",
    "        \"distance\": hit.distance,\n",
    "        \"similarity\": hit.similarity_score(),\n",
    "        \"cik_int\": hit.cik_int,\n",
    "        \"report_year\": hit.report_year,\n",
    "        \"section_name\": hit.section_name,\n",
    "        \"sentence_pos\": hit.sentence_pos,\n",
    "        \"sources\": \",\".join(sorted(hit.sources)),  # Convert set to string\n",
    "        \"variant_ids\": \",\".join(map(str, sorted(hit.variant_ids))),  # Convert set to string\n",
    "        \"has_filtered\": \"filtered\" in hit.sources,\n",
    "        \"has_global\": \"global\" in hit.sources,\n",
    "        \"from_base\": 0 in hit.variant_ids,\n",
    "        \"from_variant\": any(v > 0 for v in hit.variant_ids)\n",
    "    })\n",
    "\n",
    "df = pl.DataFrame(rows)\n",
    "\n",
    "print(\"Sample of retrieved hits:\")\n",
    "print(df.select([\n",
    "    \"sentence_id\", \"similarity\", \"cik_int\", \"report_year\", \n",
    "    \"section_name\", \"sources\", \"variant_ids\"\n",
    "]).head(10))\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# KEY METRIC 1: Distinct Sentences by Source Type\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"KEY METRIC 1: Distinct Sentences by Source Type\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Define source types\n",
    "source_type_rows = []\n",
    "\n",
    "# 1. Filtered Base (variant_id=0, has filtered source)\n",
    "filtered_base = df.filter(\n",
    "    (pl.col(\"from_base\") == True) & \n",
    "    (pl.col(\"has_filtered\") == True)\n",
    ")\n",
    "source_type_rows.append({\n",
    "    \"source_type\": \"filtered_base\",\n",
    "    \"total_hits\": len(filtered_base),\n",
    "    \"distinct_sentences\": filtered_base.select(\"sentence_id\").unique().height\n",
    "})\n",
    "\n",
    "# 2. Global Base (variant_id=0, has global source)\n",
    "global_base = df.filter(\n",
    "    (pl.col(\"from_base\") == True) & \n",
    "    (pl.col(\"has_global\") == True)\n",
    ")\n",
    "source_type_rows.append({\n",
    "    \"source_type\": \"global_base\",\n",
    "    \"total_hits\": len(global_base),\n",
    "    \"distinct_sentences\": global_base.select(\"sentence_id\").unique().height\n",
    "})\n",
    "\n",
    "# 3. Filtered Variant (variant_id>0, has filtered source)\n",
    "filtered_variant = df.filter(\n",
    "    (pl.col(\"from_variant\") == True) & \n",
    "    (pl.col(\"has_filtered\") == True)\n",
    ")\n",
    "source_type_rows.append({\n",
    "    \"source_type\": \"filtered_variant\",\n",
    "    \"total_hits\": len(filtered_variant),\n",
    "    \"distinct_sentences\": filtered_variant.select(\"sentence_id\").unique().height\n",
    "})\n",
    "\n",
    "# Create summary dataframe\n",
    "summary_df = pl.DataFrame(source_type_rows)\n",
    "print(summary_df)\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# KEY METRIC 2: Per-Variant Breakdown\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"KEY METRIC 2: Per-Variant Breakdown\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "variant_rows = []\n",
    "for variant_id in range(len(bundle.variant_queries) + 1):  # 0 = base, 1+ = variants\n",
    "    variant_hits = df.filter(\n",
    "        pl.col(\"variant_ids\").str.contains(str(variant_id))\n",
    "    )\n",
    "    \n",
    "    variant_name = \"Base Query\" if variant_id == 0 else f\"Variant {variant_id}\"\n",
    "    \n",
    "    variant_rows.append({\n",
    "        \"variant\": variant_name,\n",
    "        \"variant_id\": variant_id,\n",
    "        \"total_hits\": len(variant_hits),\n",
    "        \"distinct_sentences\": variant_hits.select(\"sentence_id\").unique().height,\n",
    "        \"avg_similarity\": round(variant_hits.select(\"similarity\").mean().item(), 4) if len(variant_hits) > 0 else 0.0\n",
    "    })\n",
    "\n",
    "variant_breakdown = pl.DataFrame(variant_rows)\n",
    "print(variant_breakdown)\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# KEY METRIC 3: Company & Year Distribution\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"KEY METRIC 3: Company & Year Distribution\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "company_year_dist = (\n",
    "    df.group_by([\"cik_int\", \"report_year\"])\n",
    "    .agg([\n",
    "        pl.count(\"sentence_id\").alias(\"hit_count\"),\n",
    "        pl.n_unique(\"sentence_id\").alias(\"distinct_sentences\")\n",
    "    ])\n",
    "    .sort([\"cik_int\", \"report_year\"])\n",
    ")\n",
    "print(company_year_dist)\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# KEY METRIC 4: Section Distribution\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"KEY METRIC 4: Section Distribution\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "section_dist = (\n",
    "    df.group_by(\"section_name\")\n",
    "    .agg([\n",
    "        pl.count(\"sentence_id\").alias(\"hit_count\"),\n",
    "        pl.n_unique(\"sentence_id\").alias(\"distinct_sentences\"),\n",
    "        pl.mean(\"similarity\").alias(\"avg_similarity\")\n",
    "    ])\n",
    "    .sort(\"hit_count\", descending=True)\n",
    ")\n",
    "print(section_dist)\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# KEY METRIC 5: Similarity Score Distribution\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"KEY METRIC 5: Similarity Score Distribution\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(f\"Min similarity: {df.select('similarity').min().item():.4f}\")\n",
    "print(f\"Max similarity: {df.select('similarity').max().item():.4f}\")\n",
    "print(f\"Mean similarity: {df.select('similarity').mean().item():.4f}\")\n",
    "print(f\"Median similarity: {df.select('similarity').median().item():.4f}\")\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# FINAL SUMMARY\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(f\"✓ Query processed successfully\")\n",
    "print(f\"✓ Entities extracted: {len(entities.companies.ciks_int)} companies, {len(entities.years.years)} years\")\n",
    "print(f\"✓ Base embedding generated: 1024-d\")\n",
    "print(f\"✓ Variants generated: {len(bundle.variant_queries)}\")\n",
    "print(f\"✓ Total S3 queries: {1 + len(bundle.variant_queries)} (base) + variants\")\n",
    "print(f\"✓ Raw hits retrieved: ~{len(bundle.filtered_hits) + len(bundle.global_hits)} (before dedup)\")\n",
    "print(f\"✓ Deduplicated hits: {len(bundle.union_hits)}\")\n",
    "print(f\"✓ Distinct sentences: {df.select('sentence_id').unique().height}\")\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"✓ ALL TESTS PASSED - RETRIEVAL PIPELINE WORKING END-TO-END\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c260abc",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Supply Line 3: Entity → Filters → S3 Retrieval (with variants)\n",
    "Flow:\n",
    "  Query → EntityAdapter → Filters → S3Retriever (variants internal) → RetrievalBundle\n",
    "\"\"\"\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Setup paths\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "# Imports\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import EmbeddingRuntimeConfig, QueryEmbedderV2\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.metadata_filters import MetadataFilterBuilder\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.variant_pipeline import VariantPipeline\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.s3_retriever import S3VectorsRetriever\n",
    "\n",
    "# Initialize\n",
    "config = MLConfig()\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "\n",
    "adapter = EntityAdapter(company_dim_path=DIM_COMPANIES, section_dim_path=DIM_SECTIONS)\n",
    "embedder = QueryEmbedderV2(EmbeddingRuntimeConfig.from_ml_config(config.cfg[\"embedding\"]), bedrock_client)\n",
    "filter_builder = MetadataFilterBuilder(config)\n",
    "variant_pipeline = VariantPipeline(config, adapter, embedder, bedrock_client)\n",
    "retriever = S3VectorsRetriever(config.get_retrieval_config(), config.aws_access_key, config.aws_secret_key, config.region, variant_pipeline)\n",
    "\n",
    "# Query\n",
    "query = \"What were NVIDIA's and Microsoft's AI risks in 2017-2020?\"\n",
    "\n",
    "# Step 1: Extract entities\n",
    "entities = adapter.extract(query)\n",
    "\n",
    "# Step 2: Generate base embedding\n",
    "base_embedding = embedder.embed_query(query, entities)\n",
    "\n",
    "# Step 3: Build filters\n",
    "filtered_filters = filter_builder.build_filters(entities)\n",
    "global_filters = filter_builder.build_global_filters(entities)\n",
    "\n",
    "# Step 4-5: Retrieve (variants handled internally)\n",
    "bundle = retriever.retrieve(base_embedding, query, filtered_filters, global_filters)\n",
    "\n",
    "# Results\n",
    "print(f\"✓ Filtered: {len(bundle.filtered_hits)}, Global: {len(bundle.global_hits)}, Union: {len(bundle.union_hits)}\")\n",
    "print(f\"✓ Variants: {len(bundle.variant_queries)}\")\n",
    "print(f\"✓ Companies: {entities.companies.tickers}, Years: {entities.years.years}\")\n",
    "```\n",
    "\n",
    "---\n",
    "### NEXT PARTS: SIGH\n",
    "```\n",
    "[6] ContextWindowExpander → ~35 spans (±3 windows, merged)\n",
    "  ↓\n",
    "[7] TextFetcher → ~35 blocks with full text\n",
    "  ↓\n",
    "[8] (SKIPPED - no reranking)\n",
    "  ↓\n",
    "[9] BlockDeduplicator → ~25 unique blocks\n",
    "  ↓\n",
    "[10] ContextAssembler → Top 10 blocks formatted\n",
    "  ↓\n",
    "LLM-ready context string\n",
    "```\n",
    "---\n",
    "### \n",
    "# Inside S3Retriever._deduplicate_hits():\n",
    "for (sentence_id, embedding_id), hits in groups.items():\n",
    "    best = min(hits, key=lambda h: h.distance)\n",
    "    best.sources = {h.source for h in hits}      # ← MERGED!\n",
    "    best.variant_ids = {h.variant_id for h in hits}  # ← MERGED!\n",
    "```\n",
    "**This IS your hit merger:**\n",
    "- Combines filtered + global + variants\n",
    "- Tracks provenance\n",
    "- Keeps best distance per sentence\n",
    "\n",
    "**You don't need a separate `HitMerger` class** - it's already integrated into the deduplication logic.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **SIMPLIFIED ARCHITECTURE:**\n",
    "```\n",
    "┌──────────────────────────────────────────────────┐\n",
    "│ S3VectorsRetriever                               │\n",
    "│  ├─ Generate variants (internal)                 │\n",
    "│  ├─ Retrieve (filtered+global+variants)          │\n",
    "│  ├─ Merge & Dedup (internal) ← HIT MERGER HERE   │\n",
    "│  └─ Return RetrievalBundle                       │\n",
    "└──────────────────────────────────────────────────┘\n",
    "         ↓ bundle.union_hits (34 hits)\n",
    "┌──────────────────────────────────────────────────┐\n",
    "│ ContextWindowExpander                            │\n",
    "│  └─ Expand ±3 windows, merge overlaps            │\n",
    "└──────────────────────────────────────────────────┘\n",
    "         ↓ spans (~35 spans)\n",
    "┌──────────────────────────────────────────────────┐\n",
    "│ TextFetcher                                      │\n",
    "│  └─ Join to Stage 2 meta, concatenate text       │\n",
    "└──────────────────────────────────────────────────┘\n",
    "         ↓ blocks (~35 blocks)\n",
    "┌──────────────────────────────────────────────────┐\n",
    "│ BlockDeduplicator (Stage-2)                      │\n",
    "│  └─ Remove overlapping windows                   │\n",
    "└──────────────────────────────────────────────────┘\n",
    "         ↓ unique_blocks (~25 blocks)\n",
    "┌──────────────────────────────────────────────────┐\n",
    "│ ContextAssembler                                 │\n",
    "│  ├─ Sort by base_score                           │\n",
    "│  ├─ Take top 10 blocks                           │\n",
    "│  └─ Format with headers                          │\n",
    "└──────────────────────────────────────────────────┘\n",
    "         ↓ context_str (LLM prompt)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5da8c9",
   "metadata": {},
   "source": [
    "### Looks like:\n",
    "\n",
    "- It's a list of bundled custom data class objects or custom S3Hit objects.\n",
    "```\n",
    "# After deduplication, union_hits looks like:\n",
    "union_hits = [\n",
    "    S3Hit(sentence_id=\"A\", distance=0.15, sources={\"filtered\", \"global\"}, variant_ids={0,1}),\n",
    "    S3Hit(sentence_id=\"B\", distance=0.20, sources={\"filtered\"}, variant_ids={0,1,2}),\n",
    "    S3Hit(sentence_id=\"C\", distance=0.22, sources={\"global\"}, variant_ids={0}),\n",
    "    # ... 31 more\n",
    "]\n",
    "\n",
    "# Then we create two filtered views:\n",
    "filtered_hits = [h for h in union_hits if \"filtered\" in h.sources]\n",
    "# Result: [Hit A, Hit B]  ← Hits that came from ANY filtered call\n",
    "\n",
    "global_hits = [h for h in union_hits if \"global\" in h.sources]\n",
    "# Result: [Hit A, Hit C]  ← Hits that came from ANY global call\n",
    "```\n",
    "\n",
    "### Final RetrievalBundle structure: It's like having it from set mathematics, I guess, because at any point I might need analysis later on. And it also helped really a lot during testing.\n",
    "```\n",
    "RetrievalBundle(\n",
    "    filtered_hits=[...],  # \"What did filtered calls contribute?\"\n",
    "    global_hits=[...],    # \"What did global calls contribute?\"\n",
    "    union_hits=[...]      # \"What's the complete deduplicated set?\"\n",
    ")\n",
    "```\n",
    "\n",
    "## POINTER: DOWNSTREAM:\n",
    "- downstream processing: Window expansion only needs union_hits: \n",
    "- For evaluation & logging: these are very useful.\n",
    "```python\n",
    "@dataclass\n",
    "class RetrievalBundle:\n",
    "    filtered_hits: List[S3Hit]  # Analysis view: \"filtered contributions\"\n",
    "    global_hits: List[S3Hit]    # Analysis view: \"global contributions\"\n",
    "    union_hits: List[S3Hit]     # Processing view: \"all unique hits\"\n",
    "    \n",
    "    base_query: str             # Original query (for logging)\n",
    "    variant_queries: List[str]  # Generated variants (for logging)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34223a74",
   "metadata": {},
   "source": [
    "### Bare bones idea for next:\n",
    "\n",
    "```python\n",
    "spans = window_expander.expand(bundle.union_hits)  # ← Only union matters\n",
    "blocks = text_fetcher.materialize_blocks(spans)\n",
    "unique_blocks = deduplicator.deduplicate(blocks)\n",
    "context = assembler.assemble(unique_blocks[:10])\n",
    "```\n",
    "\n",
    "- Immediately grab bundle.union_hits and ignore the rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db82b34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e5fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde4792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe8f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
