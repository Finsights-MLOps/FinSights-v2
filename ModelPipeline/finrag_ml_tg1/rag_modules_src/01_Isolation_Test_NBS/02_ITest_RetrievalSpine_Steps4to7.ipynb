{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6fa660",
   "metadata": {},
   "source": [
    "## Isolation Tests and Skeletons\n",
    "#### Post Supply lines. RAG Pipeline Concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c71de83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model root on sys.path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "âœ“ Metric data JSON path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\metric_pipeline\\data\\downloaded_data.json\n",
      "âœ“ Dimension companies path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_companies_21.parquet\n",
      "âœ“ Dimension sections path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\dimensions\\finrag_dim_sec_sections.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot find 'ModelPipeline' root in path tree\")\n",
    "\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"âœ“ Model root on sys.path: {model_root}\")\n",
    "\n",
    "\n",
    "METRIC_DATA_JSON = model_root / \"finrag_ml_tg1/rag_modules_src/metric_pipeline/data/downloaded_data.json\"\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "print(f\"âœ“ Metric data JSON path: {METRIC_DATA_JSON}\")\n",
    "print(f\"âœ“ Dimension companies path: {DIM_COMPANIES}\")\n",
    "print(f\"âœ“ Dimension sections path: {DIM_SECTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8079dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded Stage 2 Meta parquet: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\meta_embeds\\finrag_fact_sentences_meta_embeds.parquet\n",
      "âœ“ Loaded Stage 3 S3 Vectors parquet: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\stage3_s3vectors\\cohere_1024d\\finrag_embeddings_s3vectors_cohere_1024d.parquet\n",
      "Stage 2 Meta schema:\n",
      "Schema([('cik', String), ('cik_int', Int32), ('name', String), ('tickers', List(String)), ('docID', String), ('sentenceID', String), ('section_ID', Int64), ('section_name', String), ('form', String), ('sic', String), ('sentence', String), ('filingDate', String), ('report_year', Int64), ('reportDate', String), ('temporal_bin', String), ('likely_kpi', Boolean), ('has_numbers', Boolean), ('has_comparison', Boolean), ('sample_created_at', Datetime(time_unit='us', time_zone='UTC')), ('last_modified_date', Datetime(time_unit='us', time_zone='UTC')), ('sample_version', String), ('source_file_path', String), ('load_method', String), ('row_hash', String), ('prev_sentenceID', String), ('next_sentenceID', String), ('sentence_char_length', UInt32), ('sentence_token_count', Int16), ('section_sentence_count', UInt32), ('embedding_id', String), ('embedding_model', String), ('embedding_dims', Int16), ('embedding_date', Datetime(time_unit='us', time_zone=None)), ('embedding_ref', String)])\n",
      "Stage 2 vector table:\n",
      "Schema([('sentenceID', String), ('embedding_id', String), ('embedding', List(Float32))])\n"
     ]
    }
   ],
   "source": [
    "## Quick Verifications:\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Load Stage 3 S3 Vectors parquet\n",
    "stage3_path = model_root / \"finrag_ml_tg1/data_cache/stage3_s3vectors/cohere_1024d/finrag_embeddings_s3vectors_cohere_1024d.parquet\"\n",
    "df = pl.read_parquet(stage3_path)\n",
    "\n",
    "# Check what section_name values look like\n",
    "# print(\"Sample section_name values:\")\n",
    "# print(df.select(\"section_name\").unique().head(10))\n",
    "\n",
    "# Stage 2 Meta table: ModelPipeline\\finrag_ml_tg1\\data_cache\\meta_embeds\\finrag_fact_sentences_meta_embeds.parquet\n",
    "stage2_path = model_root / \"finrag_ml_tg1/data_cache/meta_embeds/finrag_fact_sentences_meta_embeds.parquet\"\n",
    "df_stage2 = pl.read_parquet(stage2_path)\n",
    "print(f\"âœ“ Loaded Stage 2 Meta parquet: {stage2_path}\")\n",
    "\n",
    "# Stage 2 vector table: ModelPipeline\\finrag_ml_tg1\\data_cache\\embeddings\\cohere_1024d\\finrag_embeddings_cohere_1024d.parquet\n",
    "df_stage2_vecs = pl.read_parquet(model_root / \"finrag_ml_tg1/data_cache/embeddings/cohere_1024d/finrag_embeddings_cohere_1024d.parquet\")\n",
    "print(f\"âœ“ Loaded Stage 3 S3 Vectors parquet: {stage3_path}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "1. sentenceID is ALWAYS a string composite key\n",
    "Format: \"{cik}_{form}_{year}_section_{section}_{position}\"\n",
    "Example: \"0001045810_10-K_2019_section_7_13\"\n",
    "\"\"\"\n",
    "\n",
    "# print column names or schema of both tables.\n",
    "print(\"Stage 2 Meta schema:\")\n",
    "print(df_stage2.schema)\n",
    "print(\"Stage 2 vector table:\")\n",
    "print(df_stage2_vecs.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92fb0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "\n",
      "================================================================================\n",
      "TEST 1\n",
      "================================================================================\n",
      "\n",
      "Query: What was NVIDIA's, Apple's, and Microsoft's revenue and net income in 2020, 2021, and 2022?\n",
      "\n",
      "Companies: ['AAPL', 'MSFT', 'NVDA']\n",
      "CIKs: [320193, 789019, 1045810]\n",
      "Years: [2020, 2021, 2022]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FILTERS:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Filtered call:\n",
      "  cik_int: {'$in': [320193, 789019, 1045810]}\n",
      "  report_year: {'$in': [2020, 2021, 2022]}\n",
      "\n",
      "Global call:\n",
      "  cik_int: {'$in': [320193, 789019, 1045810]}\n",
      "  report_year: {'$gte': 2015}\n",
      "\n",
      "================================================================================\n",
      "TEST 2\n",
      "================================================================================\n",
      "\n",
      "Query: In Item 1A and Item 7A, what liquidity risks and market risks did Tesla highlight in 2019 and 2021?\n",
      "\n",
      "Companies: ['TSLA']\n",
      "CIKs: [1318605]\n",
      "Years: [2019, 2021]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FILTERS:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Filtered call:\n",
      "  cik_int: {'$eq': 1318605}\n",
      "  report_year: {'$in': [2019, 2021]}\n",
      "  section_name: {'$in': ['ITEM_7', 'ITEM_1A', 'ITEM_7A']}\n",
      "\n",
      "Global call:\n",
      "  cik_int: {'$eq': 1318605}\n",
      "  report_year: {'$gte': 2015}\n",
      "\n",
      "================================================================================\n",
      "TEST 3\n",
      "================================================================================\n",
      "\n",
      "Query: Looking at the MD&A (Item 7), how did Nvidia's gaming division and MSFT discuss operating results from 2017 to 2020?\n",
      "\n",
      "Companies: ['MSFT', 'NVDA']\n",
      "CIKs: [789019, 1045810]\n",
      "Years: [2017, 2018, 2019, 2020]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FILTERS:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Filtered call:\n",
      "  cik_int: {'$in': [789019, 1045810]}\n",
      "  report_year: {'$in': [2017, 2018, 2019, 2020]}\n",
      "  section_name: {'$eq': 'ITEM_7'}\n",
      "\n",
      "Global call:\n",
      "  cik_int: {'$in': [789019, 1045810]}\n",
      "  report_year: {'$gte': 2015}\n",
      "\n",
      "================================================================================\n",
      "TEST 4\n",
      "================================================================================\n",
      "\n",
      "Query: For EXXON MOBIL, Meta Platforms, and Walmrt, show total assets in Item 1, Item 7, and Item 8 for 2015-2019, 2022, and 2026.\n",
      "\n",
      "Companies: ['META', 'WMT', 'XOM']\n",
      "CIKs: [34088, 104169, 1326801]\n",
      "Years: [2015, 2016, 2017, 2018, 2019, 2022, 2026]\n",
      "  âš ï¸  Future years detected: [2026]\n",
      "  Warning: Query includes future years [2026]. These filings do not exist yet; any results will be empty or synthetic.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FILTERS:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Filtered call:\n",
      "  cik_int: {'$in': [34088, 104169, 1326801]}\n",
      "  report_year: {'$in': [2015, 2016, 2017, 2018, 2019, 2022]}\n",
      "  section_name: {'$in': ['ITEM_8', 'ITEM_7', 'ITEM_1']}\n",
      "\n",
      "Global call:\n",
      "  cik_int: {'$in': [34088, 104169, 1326801]}\n",
      "  report_year: {'$gte': 2015}\n",
      "\n",
      "================================================================================\n",
      "ALL TESTS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL: VISUAL FILTER TESTS - Just run and observe\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.metadata_filters import MetadataFilterBuilder\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "\n",
    "adapter = EntityAdapter( company_dim_path=DIM_COMPANIES, section_dim_path=DIM_SECTIONS )\n",
    "builder = MetadataFilterBuilder(recent_year_threshold=2015)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST QUERIES - Cover all filter dimensions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "test_queries = [\n",
    "    # Test 1: Multi-company + multi-year + metrics\n",
    "    \"What was NVIDIA's, Apple's, and Microsoft's revenue and net income in 2020, 2021, and 2022?\",\n",
    "    \n",
    "    # Test 2: Explicit sections + risk topics\n",
    "    \"In Item 1A and Item 7A, what liquidity risks and market risks did Tesla highlight in 2019 and 2021?\",\n",
    "    \n",
    "    # Test 3: Year range + MD&A + fuzzy names\n",
    "    \"Looking at the MD&A (Item 7), how did Nvidia's gaming division and MSFT discuss operating results from 2017 to 2020?\",\n",
    "    \n",
    "    # Test 4: Edge case stress (future years, fuzzy tickers, many sections)\n",
    "    \"For EXXON MOBIL, Meta Platforms, and Walmrt, show total assets in Item 1, Item 7, and Item 8 for 2015-2019, 2022, and 2026.\"\n",
    "]\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RUN TESTS - Simple loop with clean output\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"TEST {i}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nQuery: {query}\\n\")\n",
    "    \n",
    "    # Extract entities\n",
    "    entities = adapter.extract(query)\n",
    "    \n",
    "    # Build filters\n",
    "    filtered = builder.build_filters(entities)\n",
    "    global_f = builder.build_global_filters(entities)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Companies: {entities.companies.tickers if entities.companies else 'None'}\")\n",
    "    print(f\"CIKs: {list(entities.companies.ciks_int) if entities.companies else 'None'}\")\n",
    "    print(f\"Years: {entities.years.years if entities.years else 'None'}\")\n",
    "    if entities.years and entities.years.future_years:\n",
    "        print(f\"  âš ï¸  Future years detected: {entities.years.future_years}\")\n",
    "        print(f\"  Warning: {entities.years.warning}\")\n",
    "    \n",
    "    # Sections\n",
    "    if entities.sections:\n",
    "        sections_list = (\n",
    "            list(entities.sections.items) if hasattr(entities.sections, 'items') \n",
    "            else entities.sections.get('items', []) if isinstance(entities.sections, dict)\n",
    "            else []\n",
    "        )\n",
    "        if sections_list:\n",
    "            print(f\"Sections: {sections_list}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"FILTERS:\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"\\nFiltered call:\")\n",
    "    if filtered:\n",
    "        for key, val in filtered.items():\n",
    "            print(f\"  {key}: {val}\")\n",
    "    else:\n",
    "        print(\"  (no filters)\")\n",
    "    \n",
    "    print(\"\\nGlobal call:\")\n",
    "    if global_f:\n",
    "        for key, val in global_f.items():\n",
    "            print(f\"  {key}: {val}\")\n",
    "    else:\n",
    "        print(\"  (no filters)\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL TESTS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11a9af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] âœ“ AWS credentials loaded from aws_credentials.env\n",
      "Variant Config:\n",
      "  enabled: True\n",
      "  model_id: anthropic.claude-3-haiku-20240307-v1:0\n",
      "  count: 3\n",
      "  prompt preview: Rephrase this financial query {count} different ways while preserving the exact intent and entities....\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Retrieval Config:\n",
      "  top_k_filtered: 30\n",
      "  top_k_global: 18\n",
      "  enable_global: True\n",
      "  enable_variants: True\n",
      "  vector_bucket: finrag-embeddings-s3vectors\n",
      "  index_name: finrag-sentence-fact-embed-1024d\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL: TEST CONFIG LOADING (NO AWS CALLS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "\n",
    "config = MLConfig()\n",
    "\n",
    "# Test variant config\n",
    "variant_cfg = config.get_variant_config()\n",
    "print(\"Variant Config:\")\n",
    "print(f\"  enabled: {variant_cfg['enabled']}\")\n",
    "print(f\"  model_id: {variant_cfg['model_id']}\")\n",
    "print(f\"  count: {variant_cfg['count']}\")\n",
    "print(f\"  prompt preview: {variant_cfg['prompt_template'][:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test retrieval config\n",
    "retrieval_cfg = config.get_retrieval_config()\n",
    "print(\"Retrieval Config:\")\n",
    "print(f\"  top_k_filtered: {retrieval_cfg['top_k_filtered']}\")\n",
    "print(f\"  top_k_global: {retrieval_cfg['top_k_global']}\")\n",
    "print(f\"  enable_global: {retrieval_cfg['enable_global']}\")\n",
    "print(f\"  enable_variants: {retrieval_cfg['enable_variants']}\")\n",
    "print(f\"  vector_bucket: {retrieval_cfg['vector_bucket']}\")\n",
    "print(f\"  index_name: {retrieval_cfg['index_name']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f3d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] âœ“ AWS credentials loaded from aws_credentials.env\n",
      "Using model: us.anthropic.claude-haiku-4-5-20251001-v1:0\n",
      "Enabled: True\n",
      "Count: 3\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original Query:\n",
      "  In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2020 and 2023?\n",
      "\n",
      "================================================================================\n",
      "Generating variants...\n",
      "\n",
      "Generated 3 variants:\n",
      "\n",
      "1. Between 2020 and 2023, what did NVIDIA and Microsoft say about their AI strategy, competitive positioning, and supply chain risks in their MD&A and Risk Factors sections?\n",
      "\n",
      "2. How did NVIDIA and Microsoft address AI strategy, competitive positioning, and supply chain risks in the MD&A and Risk Factors sections from 2020 through 2023?\n",
      "\n",
      "3. In their MD&A and Risk Factors disclosures spanning 2020 to 2023, how did NVIDIA and Microsoft characterize their AI strategy, competitive standing, and supply chain risk exposure?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Entity Preservation Check:\n",
      "  Companies mentioned: NVIDIA, Microsoft\n",
      "  Sections referenced: MD&A (Item 7), Risk Factors (Item 1A)\n",
      "  Time period: 2020-2023\n",
      "  Topics: AI strategy, competitive positioning, supply chain risks\n",
      "\n",
      "  â†’ Variants should preserve ALL of these elements\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL: TEST VARIANT GENERATION - COMPLEX QUERY\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.variant_generator import VariantGenerator\n",
    "\n",
    "# Load config\n",
    "config = MLConfig()\n",
    "variant_cfg = config.get_variant_config()\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "\n",
    "print(f\"Using model: {variant_cfg['model_id']}\")\n",
    "print(f\"Enabled: {variant_cfg['enabled']}\")\n",
    "print(f\"Count: {variant_cfg['count']}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Initialize generator\n",
    "generator = VariantGenerator(variant_cfg, bedrock_client)\n",
    "\n",
    "# TOUGHER QUERY - Multi-company, sections, time range, narrative focus\n",
    "query = \"In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2020 and 2023?\"\n",
    "\n",
    "print(f\"Original Query:\\n  {query}\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"Generating variants...\\n\")\n",
    "\n",
    "variants = generator.generate(query)\n",
    "\n",
    "if variants:\n",
    "    print(f\"Generated {len(variants)} variants:\\n\")\n",
    "    for i, variant in enumerate(variants, 1):\n",
    "        print(f\"{i}. {variant}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No variants generated (check logs)\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify preservation of entities\n",
    "print(\"\\nEntity Preservation Check:\")\n",
    "print(f\"  Companies mentioned: NVIDIA, Microsoft\")\n",
    "print(f\"  Sections referenced: MD&A (Item 7), Risk Factors (Item 1A)\")\n",
    "print(f\"  Time period: 2020-2023\")\n",
    "print(f\"  Topics: AI strategy, competitive positioning, supply chain risks\")\n",
    "print(\"\\n  â†’ Variants should preserve ALL of these elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb23e4a",
   "metadata": {},
   "source": [
    "``` \n",
    "ALL looks good.\n",
    "âœ… Zero entity loss - All companies, sections, years, and topics preserved\n",
    "âœ… Meaningful variation - Each variant has different structure/phrasing\n",
    "âœ… Semantic equivalence - All variants ask the same fundamental question\n",
    "âœ… Natural language - No awkward phrasing or grammatical errors \n",
    "```\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6715f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] âœ“ AWS credentials loaded from aws_credentials.env\n",
      "âœ“ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "Query: What was NVIDIA's revenue in 2021?\n",
      "Embedding dims: 1024\n",
      "Embedding preview: [-0.012878418, -0.0066223145, 0.013366699, 0.010498047, 0.008178711]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ§ª TEST 1: Open Retrieval (No Filters)\n",
      "\n",
      "âœ… Retrieval succeeded\n",
      "   Filtered hits: 30\n",
      "   Global hits: 0\n",
      "   Union hits: 30\n",
      "\n",
      "ğŸ“‹ First 5 hits:\n",
      "   1. sentence_id=0001045810_10-K_2019_section_7_13, similarity=0.829, cik=1045810, year=2019\n",
      "   2. sentence_id=0001045810_10-K_2016_section_7_15, similarity=0.823, cik=1045810, year=2016\n",
      "   3. sentence_id=0001045810_10-K_2020_section_7_13, similarity=0.820, cik=1045810, year=2020\n",
      "   4. sentence_id=0001045810_10-K_2019_section_15_451, similarity=0.815, cik=1045810, year=2019\n",
      "   5. sentence_id=0001045810_10-K_2018_section_15_478, similarity=0.815, cik=1045810, year=2018\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª TEST 2: Simple Filter (CIK only)\n",
      "\n",
      "âœ… Retrieval succeeded\n",
      "   Union hits: 30\n",
      "\n",
      "ğŸ“‹ First 5 hits:\n",
      "   1. sentence_id=0001045810_10-K_2019_section_7_13, similarity=0.829, cik=1045810, year=2019\n",
      "   2. sentence_id=0001045810_10-K_2016_section_7_15, similarity=0.823, cik=1045810, year=2016\n",
      "   3. sentence_id=0001045810_10-K_2020_section_7_13, similarity=0.820, cik=1045810, year=2020\n",
      "   4. sentence_id=0001045810_10-K_2018_section_15_478, similarity=0.815, cik=1045810, year=2018\n",
      "   5. sentence_id=0001045810_10-K_2019_section_15_451, similarity=0.815, cik=1045810, year=2019\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª TEST 3: Direct S3 Vectors Call (Bypass Retriever Class)\n",
      "\n",
      "âœ… Direct S3 call succeeded\n",
      "   Returned 10 vectors\n",
      "\n",
      "ğŸ“‹ First 3 raw responses:\n",
      "   1. distance=0.34216630458831787, metadata keys=['embedding_id', 'report_year', 'section_name', 'section_sentence_count', 'sentence_pos', 'sentenceID', 'cik_int', 'sic']\n",
      "      sentenceID=0001045810_10-K_2019_section_7_13, cik_int=1045810\n",
      "   2. distance=0.35432976484298706, metadata keys=['section_name', 'report_year', 'embedding_id', 'sic', 'cik_int', 'sentenceID', 'sentence_pos', 'section_sentence_count']\n",
      "      sentenceID=0001045810_10-K_2016_section_7_15, cik_int=1045810\n",
      "   3. distance=0.3605709671974182, metadata keys=['report_year', 'embedding_id', 'section_name', 'sentence_pos', 'cik_int', 'sentenceID', 'sic', 'section_sentence_count']\n",
      "      sentenceID=0001045810_10-K_2020_section_7_13, cik_int=1045810\n",
      "\n",
      "================================================================================\n",
      "âœ… DIAGNOSTIC COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DIAGNOSTIC: Minimal S3 Vectors Test\n",
    "# Test if S3VectorsRetriever can get ANY results at all\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.s3_retriever import S3VectorsRetriever\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    EmbeddingRuntimeConfig,\n",
    "    QueryEmbedderV2\n",
    ")\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "import numpy as np\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "config = MLConfig()\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "\n",
    "# Simple query\n",
    "query = \"What was NVIDIA's revenue in 2021?\"\n",
    "\n",
    "# Get embedding\n",
    "adapter = EntityAdapter(DIM_COMPANIES, DIM_SECTIONS)\n",
    "entities = adapter.extract(query)\n",
    "\n",
    "embedding_cfg_dict = config.cfg[\"embedding\"]\n",
    "runtime_cfg = EmbeddingRuntimeConfig.from_ml_config(embedding_cfg_dict)\n",
    "embedder = QueryEmbedderV2(runtime_cfg, boto_client=bedrock_client)\n",
    "\n",
    "embedding = embedder.embed_query(query, entities)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Embedding dims: {len(embedding)}\")\n",
    "print(f\"Embedding preview: {embedding[:5]}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 1: No filters at all (open retrieval)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n TEST 1: Open Retrieval (No Filters)\\n\")\n",
    "\n",
    "retrieval_cfg = config.get_retrieval_config()\n",
    "retrieval_cfg['min_similarity'] = 0.0  # Accept everything\n",
    "retrieval_cfg['enable_global'] = False  # Only one call for simplicity\n",
    "\n",
    "retriever = S3VectorsRetriever(\n",
    "    retrieval_config=retrieval_cfg,\n",
    "    aws_access_key_id=config.aws_access_key,\n",
    "    aws_secret_access_key=config.aws_secret_key,\n",
    "    region=config.region\n",
    ")\n",
    "\n",
    "try:\n",
    "    bundle = retriever.retrieve(\n",
    "        base_embedding=embedding,\n",
    "        variant_embeddings=[],\n",
    "        filtered_filters=None,  # â† NO FILTERS\n",
    "        global_filters=None,\n",
    "        base_query=query\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Retrieval succeeded\")\n",
    "    print(f\"   Filtered hits: {len(bundle.filtered_hits)}\")\n",
    "    print(f\"   Global hits: {len(bundle.global_hits)}\")\n",
    "    print(f\"   Union hits: {len(bundle.union_hits)}\")\n",
    "    \n",
    "    if bundle.union_hits:\n",
    "        print(f\"\\nğŸ“‹ First 5 hits:\")\n",
    "        for i, hit in enumerate(bundle.union_hits[:5], 1):\n",
    "            print(f\"   {i}. sentence_id={hit.sentence_id}, \"\n",
    "                  f\"similarity={hit.similarity_score():.3f}, \"\n",
    "                  f\"cik={hit.cik_int}, year={hit.report_year}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ No hits returned even with no filters\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Exception during retrieval: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 2: Simple filter (single CIK)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" TEST 2: Simple Filter (CIK only)\\n\")\n",
    "\n",
    "simple_filter = {\"cik_int\": {\"$eq\": 1045810}}  # NVIDIA\n",
    "\n",
    "try:\n",
    "    bundle2 = retriever.retrieve(\n",
    "        base_embedding=embedding,\n",
    "        variant_embeddings=[],\n",
    "        filtered_filters=simple_filter,\n",
    "        global_filters=None,\n",
    "        base_query=query\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Retrieval succeeded\")\n",
    "    print(f\"   Union hits: {len(bundle2.union_hits)}\")\n",
    "    \n",
    "    if bundle2.union_hits:\n",
    "        print(f\"\\nğŸ“‹ First 5 hits:\")\n",
    "        for i, hit in enumerate(bundle2.union_hits[:5], 1):\n",
    "            print(f\"   {i}. sentence_id={hit.sentence_id}, \"\n",
    "                  f\"similarity={hit.similarity_score():.3f}, \"\n",
    "                  f\"cik={hit.cik_int}, year={hit.report_year}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ No hits with simple CIK filter\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Exception during retrieval: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 3: Check actual S3 client directly (bypass our class)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" TEST 3: Direct S3 Vectors Call (Bypass Retriever Class)\\n\")\n",
    "\n",
    "import boto3\n",
    "\n",
    "s3v = boto3.client(\n",
    "    's3vectors',\n",
    "    region_name=config.region,\n",
    "    aws_access_key_id=config.aws_access_key,\n",
    "    aws_secret_access_key=config.aws_secret_key\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = s3v.query_vectors(\n",
    "        vectorBucketName=retrieval_cfg['vector_bucket'],\n",
    "        indexName=retrieval_cfg['index_name'],\n",
    "        queryVector={\"float32\": embedding},\n",
    "        topK=10,\n",
    "        returnMetadata=True,\n",
    "        returnDistance=True\n",
    "        # No filter - open retrieval\n",
    "    )\n",
    "    \n",
    "    vectors = response.get('vectors', [])\n",
    "    print(f\"âœ… Direct S3 call succeeded\")\n",
    "    print(f\"   Returned {len(vectors)} vectors\")\n",
    "    \n",
    "    if vectors:\n",
    "        print(f\"\\nğŸ“‹ First 3 raw responses:\")\n",
    "        for i, vec in enumerate(vectors[:3], 1):\n",
    "            md = vec.get('metadata', {})\n",
    "            dist = vec.get('distance', 'N/A')\n",
    "            print(f\"   {i}. distance={dist}, metadata keys={list(md.keys())}\")\n",
    "            print(f\"      sentenceID={md.get('sentenceID')}, cik_int={md.get('cik_int')}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Direct S3 call returned 0 vectors\")\n",
    "        print(f\"   Full response: {response}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Direct S3 call failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… DIAGNOSTIC COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test different filter patterns to find what S3 Vectors accepts\n",
    "\n",
    "# # Pattern A: Single section (works in diagnostic test)\n",
    "# filter_A = {\n",
    "#     'cik_int': {'$in': [789019, 1045810]},\n",
    "#     'report_year': {'$in': [2020, 2023]},\n",
    "#     'section_name': {'$eq': 'ITEM_7'}  # Single value\n",
    "# }\n",
    "\n",
    "# # Pattern B: Multiple sections with $in\n",
    "# filter_B = {\n",
    "#     'cik_int': {'$in': [789019, 1045810]},\n",
    "#     'report_year': {'$in': [2020, 2023]},\n",
    "#     'section_name': {'$in': ['ITEM_7', 'ITEM_1A']}  # Multiple - MIGHT FAIL\n",
    "# }\n",
    "\n",
    "# # Pattern C: OR wrapper (AWS S3 Vectors syntax)\n",
    "# filter_C = {\n",
    "#     '$and': [\n",
    "#         {'cik_int': {'$in': [789019, 1045810]}},\n",
    "#         {'report_year': {'$in': [2020, 2023]}},\n",
    "#         {'$or': [\n",
    "#             {'section_name': {'$eq': 'ITEM_7'}},\n",
    "#             {'section_name': {'$eq': 'ITEM_1A'}}\n",
    "#         ]}\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317c8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] âœ“ AWS credentials loaded from aws_credentials.env\n",
      "âœ“ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "Query: In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2020 and 2023?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ STEP 1: Entity Extraction\n",
      "\n",
      "Companies: ['MSFT', 'NVDA']\n",
      "CIKs: [789019, 1045810]\n",
      "Years: [2020, 2023]\n",
      "Sections: N/A\n",
      "\n",
      "================================================================================\n",
      "ğŸ”§ STEP 2: Build Filters\n",
      "\n",
      "Filtered call filter:\n",
      "{'$and': [{'cik_int': {'$in': [789019, 1045810]}}, {'report_year': {'$in': [2020, 2023]}}, {'$or': [{'section_name': {'$eq': 'ITEM_1A'}}, {'section_name': {'$eq': 'ITEM_7'}}]}]}\n",
      "\n",
      "Global call filter:\n",
      "{'cik_int': {'$in': [789019, 1045810]}, 'report_year': {'$gte': 2015}}\n",
      "\n",
      "================================================================================\n",
      "ğŸ§  STEP 3: Query Embedding\n",
      "\n",
      "Embedding: 1024D vector\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ STEP 4: Retrieval (Filtered + Global)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global call failed for variant 0: An error occurred (ValidationException) when calling the QueryVectors operation: Invalid query filter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RETRIEVAL SUCCEEDED\n",
      "\n",
      "Filtered hits: 30\n",
      "Global hits: 0\n",
      "Union (deduplicated): 30\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š First 5 Results:\n",
      "\n",
      "1. sentence_id: 0001045810_10-K_2020_section_1A_204\n",
      "   similarity: 0.737\n",
      "   cik: 1045810, year: 2020, section: ITEM_1A\n",
      "   source: filtered, embedding_id: bedrock_cohere_v4_1024d_20251109_1407...\n",
      "\n",
      "2. sentence_id: 0001045810_10-K_2020_section_1A_168\n",
      "   similarity: 0.701\n",
      "   cik: 1045810, year: 2020, section: ITEM_1A\n",
      "   source: filtered, embedding_id: bedrock_cohere_v4_1024d_20251109_1407...\n",
      "\n",
      "3. sentence_id: 0000789019_10-K_2020_section_1A_218\n",
      "   similarity: 0.701\n",
      "   cik: 789019, year: 2020, section: ITEM_1A\n",
      "   source: filtered, embedding_id: bedrock_cohere_v4_1024d_20251109_1355...\n",
      "\n",
      "4. sentence_id: 0000789019_10-K_2020_section_1A_163\n",
      "   similarity: 0.699\n",
      "   cik: 789019, year: 2020, section: ITEM_1A\n",
      "   source: filtered, embedding_id: bedrock_cohere_v4_1024d_20251109_1355...\n",
      "\n",
      "5. sentence_id: 0000789019_10-K_2020_section_1A_166\n",
      "   similarity: 0.691\n",
      "   cik: 789019, year: 2020, section: ITEM_1A\n",
      "   source: filtered, embedding_id: bedrock_cohere_v4_1024d_20251109_1355...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” Filter Validation:\n",
      "\n",
      "Expected CIKs: {1045810, 789019}\n",
      "Actual CIKs: {1045810, 789019}\n",
      "  âœ… Match!\n",
      "\n",
      "Expected Years: {2020, 2023}\n",
      "Actual Years: {2020}\n",
      "  âœ… Match!\n",
      "\n",
      "Expected Sections: {'ITEM_1A', 'ITEM_7'}\n",
      "Actual Sections: {'ITEM_1A', 'ITEM_7'}\n",
      "  âœ… Match!\n",
      "\n",
      "================================================================================\n",
      "âœ… SANITY TEST COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# QUICK SANITY TEST: Filtered + Global with Complex Query\n",
    "# Purpose: Verify filter syntax fix (should take <30 seconds)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    EmbeddingRuntimeConfig,\n",
    "    QueryEmbedderV2\n",
    ")\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.metadata_filters import MetadataFilterBuilder\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.s3_retriever import S3VectorsRetriever\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "config = MLConfig()\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "\n",
    "adapter = EntityAdapter(\n",
    "    company_dim_path=DIM_COMPANIES,\n",
    "    section_dim_path=DIM_SECTIONS\n",
    ")\n",
    "\n",
    "embedding_cfg = config.cfg[\"embedding\"]\n",
    "runtime_cfg = EmbeddingRuntimeConfig.from_ml_config(embedding_cfg)\n",
    "embedder = QueryEmbedderV2(runtime_cfg, boto_client=bedrock_client)\n",
    "\n",
    "filter_builder = MetadataFilterBuilder(recent_year_threshold=2015)\n",
    "\n",
    "retrieval_cfg = config.get_retrieval_config()\n",
    "retrieval_cfg['min_similarity'] = 0.0  # Accept all results for now\n",
    "\n",
    "retriever = S3VectorsRetriever(\n",
    "    retrieval_config=retrieval_cfg,\n",
    "    aws_access_key_id=config.aws_access_key,\n",
    "    aws_secret_access_key=config.aws_secret_key,\n",
    "    region=config.region\n",
    ")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST QUERY\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "query = \"In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2020 and 2023?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 1: Extract Entities\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"\\nğŸ“‹ STEP 1: Entity Extraction\\n\")\n",
    "\n",
    "entities = adapter.extract(query)\n",
    "\n",
    "print(f\"Companies: {entities.companies.tickers}\")\n",
    "print(f\"CIKs: {list(entities.companies.ciks_int)}\")\n",
    "print(f\"Years: {entities.years.years}\")\n",
    "print(f\"Sections: {entities.sections.items if hasattr(entities.sections, 'items') else 'N/A'}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 2: Build Filters\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”§ STEP 2: Build Filters\\n\")\n",
    "\n",
    "filtered_filters = filter_builder.build_filters(entities)\n",
    "global_filters = filter_builder.build_global_filters(entities)\n",
    "\n",
    "print(\"Filtered call filter:\")\n",
    "print(filtered_filters)\n",
    "\n",
    "print(\"\\nGlobal call filter:\")\n",
    "print(global_filters)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 3: Generate Embedding\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ§  STEP 3: Query Embedding\\n\")\n",
    "\n",
    "embedding = embedder.embed_query(query, entities)\n",
    "print(f\"Embedding: {len(embedding)}D vector\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 4: RETRIEVE (Filtered + Global)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ STEP 4: Retrieval (Filtered + Global)\\n\")\n",
    "\n",
    "try:\n",
    "    bundle = retriever.retrieve(\n",
    "        base_embedding=embedding,\n",
    "        variant_embeddings=[],  # No variants for sanity test\n",
    "        filtered_filters=filtered_filters,\n",
    "        global_filters=global_filters,\n",
    "        base_query=query\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… RETRIEVAL SUCCEEDED\\n\")\n",
    "    print(f\"Filtered hits: {len(bundle.filtered_hits)}\")\n",
    "    print(f\"Global hits: {len(bundle.global_hits)}\")\n",
    "    print(f\"Union (deduplicated): {len(bundle.union_hits)}\")\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Show first 5 results\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if bundle.union_hits:\n",
    "        print(\"\\n\" + \"â”€\"*80)\n",
    "        print(\"ğŸ“Š First 5 Results:\\n\")\n",
    "        \n",
    "        for i, hit in enumerate(bundle.union_hits[:5], 1):\n",
    "            print(f\"{i}. sentence_id: {hit.sentence_id}\")\n",
    "            print(f\"   similarity: {hit.similarity_score():.3f}\")\n",
    "            print(f\"   cik: {hit.cik_int}, year: {hit.report_year}, section: {hit.section_name}\")\n",
    "            print(f\"   source: {hit.source}, embedding_id: {hit.embedding_id[:40]}...\")\n",
    "            print()\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Validate results match filters\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"â”€\"*80)\n",
    "    print(\"ğŸ” Filter Validation:\\n\")\n",
    "    \n",
    "    expected_ciks = {789019, 1045810}  # MSFT, NVDA\n",
    "    expected_years = {2020, 2023}\n",
    "    expected_sections = {\"ITEM_7\", \"ITEM_1A\"}\n",
    "    \n",
    "    actual_ciks = {h.cik_int for h in bundle.filtered_hits}\n",
    "    actual_years = {h.report_year for h in bundle.filtered_hits}\n",
    "    actual_sections = {h.section_name for h in bundle.filtered_hits}\n",
    "    \n",
    "    print(f\"Expected CIKs: {expected_ciks}\")\n",
    "    print(f\"Actual CIKs: {actual_ciks}\")\n",
    "    print(f\"  âœ… Match!\" if actual_ciks.issubset(expected_ciks) else f\"  âŒ Mismatch!\")\n",
    "    \n",
    "    print(f\"\\nExpected Years: {expected_years}\")\n",
    "    print(f\"Actual Years: {actual_years}\")\n",
    "    print(f\"  âœ… Match!\" if actual_years.issubset(expected_years) else f\"  âŒ Mismatch!\")\n",
    "    \n",
    "    print(f\"\\nExpected Sections: {expected_sections}\")\n",
    "    print(f\"Actual Sections: {actual_sections}\")\n",
    "    print(f\"  âœ… Match!\" if actual_sections.issubset(expected_sections) else f\"  âŒ Mismatch!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ RETRIEVAL FAILED\\n\")\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… SANITY TEST COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbde7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22024092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] âœ“ AWS credentials loaded from aws_credentials.env\n",
      "âœ“ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "Query: In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2020 and 2023?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ” STEP 1: Entity Extraction\n",
      "\n",
      "Companies: ['MSFT', 'NVDA']\n",
      "CIKs: [789019, 1045810]\n",
      "Years: [2020, 2023]\n",
      "\n",
      "Filtered filters: {'$and': [{'cik_int': {'$in': [789019, 1045810]}}, {'report_year': {'$in': [2020, 2023]}}, {'$or': [{'section_name': {'$eq': 'ITEM_1A'}}, {'section_name': {'$eq': 'ITEM_7'}}]}]}\n",
      "Global filters: {'$and': [{'cik_int': {'$in': [789019, 1045810]}}, {'report_year': {'$gte': 2015}}]}\n",
      "\n",
      "================================================================================\n",
      "ğŸ§  STEP 2: Query Embedding\n",
      "\n",
      "Embedding: 1024D vector, preview: [0.07470703, -0.045410156, 0.008178711, 0.057128906, -0.018554688]\n",
      "\n",
      "================================================================================\n",
      " EXPERIMENT: Similarity Threshold Impact\n",
      "================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Testing threshold: 0.0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Filtered hits: 30\n",
      "  Global hits: 18\n",
      "  Union (unique): 45\n",
      "  Similarity range: [0.674, 0.737]\n",
      "  Mean similarity: 0.693\n",
      "  Median similarity: 0.687\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Testing threshold: 0.2\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Filtered hits: 30\n",
      "  Global hits: 18\n",
      "  Union (unique): 45\n",
      "  Similarity range: [0.674, 0.737]\n",
      "  Mean similarity: 0.693\n",
      "  Median similarity: 0.687\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Testing threshold: 0.3\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Filtered hits: 30\n",
      "  Global hits: 18\n",
      "  Union (unique): 45\n",
      "  Similarity range: [0.674, 0.737]\n",
      "  Mean similarity: 0.693\n",
      "  Median similarity: 0.687\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Testing threshold: 0.4\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Filtered hits: 30\n",
      "  Global hits: 18\n",
      "  Union (unique): 45\n",
      "  Similarity range: [0.674, 0.737]\n",
      "  Mean similarity: 0.693\n",
      "  Median similarity: 0.687\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Testing threshold: 0.5\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Filtered hits: 30\n",
      "  Global hits: 18\n",
      "  Union (unique): 45\n",
      "  Similarity range: [0.674, 0.737]\n",
      "  Mean similarity: 0.693\n",
      "  Median similarity: 0.687\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š SUMMARY TABLE\n",
      "================================================================================\n",
      "\n",
      "shape: (5, 8)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ threshold â”† union_hits â”† filtered_hits â”† global_hits â”† min_sim  â”† max_sim  â”† mean_sim â”† rejected â”‚\n",
      "â”‚ ---       â”† ---        â”† ---           â”† ---         â”† ---      â”† ---      â”† ---      â”† ---      â”‚\n",
      "â”‚ f64       â”† i64        â”† i64           â”† i64         â”† f64      â”† f64      â”† f64      â”† i64      â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0.0       â”† 45         â”† 30            â”† 18          â”† 0.674072 â”† 0.737008 â”† 0.693082 â”† 0        â”‚\n",
      "â”‚ 0.2       â”† 45         â”† 30            â”† 18          â”† 0.674072 â”† 0.737008 â”† 0.693082 â”† 0        â”‚\n",
      "â”‚ 0.3       â”† 45         â”† 30            â”† 18          â”† 0.674072 â”† 0.737008 â”† 0.693082 â”† 0        â”‚\n",
      "â”‚ 0.4       â”† 45         â”† 30            â”† 18          â”† 0.674072 â”† 0.737008 â”† 0.693082 â”† 0        â”‚\n",
      "â”‚ 0.5       â”† 45         â”† 30            â”† 18          â”† 0.674072 â”† 0.737008 â”† 0.693082 â”† 0        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¬ DEEP DIVE: What Gets Rejected at threshold=0.3?\n",
      "================================================================================\n",
      "\n",
      "No hits rejected at threshold=0.3\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ˆ DISTANCE DISTRIBUTION (threshold=0.0)\n",
      "================================================================================\n",
      "\n",
      "Similarity distribution:\n",
      "  [0.0-0.2):   0 \n",
      "  [0.2-0.3):   0 \n",
      "  [0.3-0.4):   0 \n",
      "  [0.4-0.5):   0 \n",
      "  [0.5-0.6):   0 \n",
      "  [0.6-0.7):  29 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  [0.7-0.8):  16 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  [0.8-0.9):   0 \n",
      "  [0.9-1.0):   0 \n",
      "\n",
      "================================================================================\n",
      "âœ… EXPERIMENT COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "## Similarity threshold impact analysis testing. \n",
    "## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Research Question: Should we filter by min_similarity given S3 Vectors' top-K?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    EmbeddingRuntimeConfig,\n",
    "    QueryEmbedderV2\n",
    ")\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.metadata_filters import MetadataFilterBuilder\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.s3_retriever import S3VectorsRetriever\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.variant_generator import VariantGenerator\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "config = MLConfig()\n",
    "\n",
    "# Initialize all components\n",
    "adapter = EntityAdapter(\n",
    "    company_dim_path=DIM_COMPANIES,\n",
    "    section_dim_path=DIM_SECTIONS\n",
    ")\n",
    "\n",
    "embedding_cfg_dict = config.cfg[\"embedding\"]\n",
    "runtime_cfg = EmbeddingRuntimeConfig.from_ml_config(embedding_cfg_dict)\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "embedder = QueryEmbedderV2(runtime_cfg, boto_client=bedrock_client)\n",
    "\n",
    "filter_builder = MetadataFilterBuilder(recent_year_threshold=2015)\n",
    "\n",
    "variant_cfg = config.get_variant_config()\n",
    "variant_generator = VariantGenerator(variant_cfg, bedrock_client)\n",
    "\n",
    "# Test query\n",
    "query = \"In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2020 and 2023?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEP 1: Extract Entities & Build Filters\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ” STEP 1: Entity Extraction\\n\")\n",
    "entities = adapter.extract(query)\n",
    "\n",
    "print(f\"Companies: {entities.companies.tickers}\")\n",
    "print(f\"CIKs: {list(entities.companies.ciks_int)}\")\n",
    "print(f\"Years: {entities.years.years}\")\n",
    "\n",
    "filtered_filters = filter_builder.build_filters(entities)\n",
    "global_filters = filter_builder.build_global_filters(entities)\n",
    "\n",
    "print(f\"\\nFiltered filters: {filtered_filters}\")\n",
    "print(f\"Global filters: {global_filters}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEP 2: Generate Embedding\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ§  STEP 2: Query Embedding\\n\")\n",
    "\n",
    "embedding = embedder.embed_query(query, entities)\n",
    "print(f\"Embedding: {len(embedding)}D vector, preview: {embedding[:5]}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXPERIMENT: Test Different Similarity Thresholds\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EXPERIMENT: Similarity Threshold Impact\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "thresholds = [0.0, 0.2, 0.3, 0.4, 0.5]\n",
    "results = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\n{'â”€'*80}\")\n",
    "    print(f\"Testing threshold: {threshold}\")\n",
    "    print('â”€'*80)\n",
    "    \n",
    "    # Create retriever with this threshold\n",
    "    retrieval_cfg = config.get_retrieval_config()\n",
    "    retrieval_cfg['min_similarity'] = threshold\n",
    "    retrieval_cfg['enable_variants'] = False  # Disable variants for clean test\n",
    "    \n",
    "    retriever = S3VectorsRetriever(\n",
    "        retrieval_config=retrieval_cfg,\n",
    "        aws_access_key_id=config.aws_access_key,\n",
    "        aws_secret_access_key=config.aws_secret_key,\n",
    "        region=config.region\n",
    "    )\n",
    "    \n",
    "    # Retrieve (base query only, no variants)\n",
    "    bundle = retriever.retrieve(\n",
    "        base_embedding=embedding,\n",
    "        variant_embeddings=[],\n",
    "        filtered_filters=filtered_filters,\n",
    "        global_filters=global_filters,\n",
    "        base_query=query\n",
    "    )\n",
    "    \n",
    "    # Collect statistics\n",
    "    filtered_count = len(bundle.filtered_hits)\n",
    "    global_count = len(bundle.global_hits)\n",
    "    union_count = len(bundle.union_hits)\n",
    "    \n",
    "    # Distance distribution\n",
    "    distances = [h.distance for h in bundle.union_hits]\n",
    "    similarities = [h.similarity_score() for h in bundle.union_hits]\n",
    "    \n",
    "    results[threshold] = {\n",
    "        'filtered_count': filtered_count,\n",
    "        'global_count': global_count,\n",
    "        'union_count': union_count,\n",
    "        'distances': distances,\n",
    "        'similarities': similarities,\n",
    "        'bundle': bundle\n",
    "    }\n",
    "    \n",
    "    print(f\"  Filtered hits: {filtered_count}\")\n",
    "    print(f\"  Global hits: {global_count}\")\n",
    "    print(f\"  Union (unique): {union_count}\")\n",
    "    \n",
    "    if similarities:\n",
    "        print(f\"  Similarity range: [{min(similarities):.3f}, {max(similarities):.3f}]\")\n",
    "        print(f\"  Mean similarity: {np.mean(similarities):.3f}\")\n",
    "        print(f\"  Median similarity: {np.median(similarities):.3f}\")\n",
    "    else:\n",
    "        print(\"  No hits passed threshold\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ANALYSIS: Summary Table\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š SUMMARY TABLE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "summary_rows = []\n",
    "for threshold in thresholds:\n",
    "    r = results[threshold]\n",
    "    summary_rows.append({\n",
    "        'threshold': threshold,\n",
    "        'union_hits': r['union_count'],\n",
    "        'filtered_hits': r['filtered_count'],\n",
    "        'global_hits': r['global_count'],\n",
    "        'min_sim': min(r['similarities']) if r['similarities'] else None,\n",
    "        'max_sim': max(r['similarities']) if r['similarities'] else None,\n",
    "        'mean_sim': np.mean(r['similarities']) if r['similarities'] else None,\n",
    "        'rejected': results[0.0]['union_count'] - r['union_count']  # vs no filter\n",
    "    })\n",
    "\n",
    "summary_df = pl.DataFrame(summary_rows)\n",
    "print(summary_df)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DEEP DIVE: Inspect Rejected Hits at threshold=0.3\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ”¬ DEEP DIVE: What Gets Rejected at threshold=0.3?\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "all_hits = results[0.0]['bundle'].union_hits  # No filtering\n",
    "filtered_hits = results[0.3]['bundle'].union_hits  # With 0.3 threshold\n",
    "\n",
    "# Find rejected hits\n",
    "all_sentence_ids = {h.sentence_id for h in all_hits}\n",
    "kept_sentence_ids = {h.sentence_id for h in filtered_hits}\n",
    "rejected_sentence_ids = all_sentence_ids - kept_sentence_ids\n",
    "\n",
    "if rejected_sentence_ids:\n",
    "    rejected_hits = [h for h in all_hits if h.sentence_id in rejected_sentence_ids]\n",
    "    \n",
    "    print(f\"Rejected {len(rejected_hits)} hits:\\n\")\n",
    "    \n",
    "    rejected_data = []\n",
    "    for h in rejected_hits:\n",
    "        rejected_data.append({\n",
    "            'sentence_id': h.sentence_id,\n",
    "            'similarity': h.similarity_score(),\n",
    "            'distance': h.distance,\n",
    "            'cik': h.cik_int,\n",
    "            'year': h.report_year,\n",
    "            'section': h.sec_item_canonical,\n",
    "            'source': h.source\n",
    "        })\n",
    "    \n",
    "    rejected_df = pl.DataFrame(rejected_data).sort('similarity', descending=True)\n",
    "    print(rejected_df)\n",
    "    \n",
    "    print(f\"\\nRejected similarity range: [{min(h.similarity_score() for h in rejected_hits):.3f}, {max(h.similarity_score() for h in rejected_hits):.3f}]\")\n",
    "else:\n",
    "    print(\"No hits rejected at threshold=0.3\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VISUALIZATION: Distance Distribution\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ˆ DISTANCE DISTRIBUTION (threshold=0.0)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "all_sims = results[0.0]['similarities']\n",
    "if all_sims:\n",
    "    # Simple ASCII histogram\n",
    "    bins = [0.0, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    hist, _ = np.histogram(all_sims, bins=bins)\n",
    "    \n",
    "    print(\"Similarity distribution:\")\n",
    "    for i, (low, high) in enumerate(zip(bins[:-1], bins[1:])):\n",
    "        bar = 'â–ˆ' * int(hist[i] * 50 / max(hist)) if max(hist) > 0 else ''\n",
    "        print(f\"  [{low:.1f}-{high:.1f}): {hist[i]:3d} {bar}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ee4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0217847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
