{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18c0a8d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "- Proposed S3 folder layout for meta and embedding assets.\n",
    "- Tests Bedrock connectivity via boto3 client and simple embedding call.\n",
    "- Describes sentenceID pattern and validates reliability with Polars regex checks.\n",
    "\n",
    "**Core 1**:\n",
    "- Local caching of Stage 1, Stage 2 and embedding tables.\n",
    "- Transforms Stage 1 facts into Stage 2 meta with ML columns.\n",
    "\n",
    "**Core 2**:\n",
    "- Details filtering modes (full vs parameterized) over CIKs and years.\n",
    "- Implements token-aware embedding batches respecting Cohere limits and timing.\n",
    "- Merges new embeddings into existing vectors table using concat and de-duplicate.\n",
    "- Updates meta table embedding metadata only for successfully embedded sentences.\n",
    "- Saves merged vectors and updated meta to S3 and local cache.\n",
    "\n",
    "**Analytics**:\n",
    "- Analyzes token distributions, model limits, and per-1k-token cost sensitivity.\n",
    "- Explains importance of preserving order between sentence IDs and embedding rows.\n",
    "- Breaks down S3 upload, storage, and egress costs for large parquet files.\n",
    "\n",
    "#### Code Auth: Joel Markapudi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93529b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe3e304",
   "metadata": {},
   "source": [
    "### Potential Structure for S3.\n",
    "```\n",
    "├── DATA_MERGE_ASSETS/                 # existing structure\n",
    "│   ├── FINRAG_FACT_SENTENCES/\n",
    "│   └── FINRAG_FACT_METRICS/\n",
    "│\n",
    "└── ML_EMBED_ASSETS/                        \n",
    "    ├── EMBED_META_FACT/\n",
    "    │   └── finrag_fact_sentences_final.parquet\n",
    "    │\n",
    "    └── EMBED_VECTORS/\n",
    "        ├── cohere_v3_768d/\n",
    "        │   ├── finrag_embeddings_cohere_v3.parquet\n",
    "        │   ├── metadata.json\n",
    "        │   └── validation_report.json\n",
    "        │\n",
    "        └── titan_v2_1024d/            # Future\n",
    "            └── ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca70a78",
   "metadata": {},
   "source": [
    "### Quick Tests 1 - 2, \n",
    "- Check for boto3.client and then check for model access through AWS org account credentials. \n",
    "- Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c16013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bedrock client created successfully\n",
      "  Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Zero-cost test (no API call)\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    bedrock = boto3.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "    print(\"✓ Bedrock client created successfully\")\n",
    "    print(f\"  Region: {bedrock.meta.region_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6984d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ Found ModelPipeline via file path: D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "✓ Config loaded\n",
      "  Bucket: sentence-data-ingestion\n",
      "  Region: us-east-1\n",
      "  Model: cohere.embed-v4:0\n",
      "✓ Bedrock API works!\n",
      "  Model: cohere.embed-v4:0\n",
      "  Dimensions: 1024\n",
      "  First 5 values: [0.048339844, 0.040039062, -0.020874023, -0.012573242, -0.044921875]\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add loaders to path\n",
    "sys.path.append(str(Path.cwd().parent / 'loaders'))\n",
    "\n",
    "from ml_config_loader import MLConfig\n",
    "\n",
    "# Initialize config (loads AWS credentials automatically)\n",
    "config = MLConfig()\n",
    "\n",
    "print(\"✓ Config loaded\")\n",
    "print(f\"  Bucket: {config.bucket}\")\n",
    "print(f\"  Region: {config.region}\")\n",
    "print(f\"  Model: {config.bedrock_model_id}\")\n",
    "\n",
    "\n",
    "\n",
    "# Cell 2: Test Bedrock API\n",
    "import json\n",
    "\n",
    "# Get Bedrock client (uses config credentials)\n",
    "bedrock = config.get_bedrock_client()\n",
    "\n",
    "# Test embedding with v4\n",
    "body = json.dumps({\n",
    "    \"texts\": [\"Revenue increased significantly.\"],\n",
    "    \"input_type\": config.bedrock_input_type,\n",
    "    \"embedding_types\": [\"float\"],\n",
    "    \"output_dimension\": config.bedrock_dimensions\n",
    "})\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "    body=body,\n",
    "    modelId=config.bedrock_model_id,\n",
    "    accept='*/*',\n",
    "    contentType='application/json'\n",
    ")\n",
    "\n",
    "result = json.loads(response['body'].read())\n",
    "embeddings = result['embeddings']['float']\n",
    "\n",
    "print(f\"✓ Bedrock API works!\")\n",
    "print(f\"  Model: {config.bedrock_model_id}\")\n",
    "print(f\"  Dimensions: {len(embeddings[0])}\")\n",
    "print(f\"  First 5 values: {embeddings[0][:5]}\")\n",
    "# print(f\"  Cost: ~$0.0000005\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7a8c0",
   "metadata": {},
   "source": [
    "### Prep work: 01: Load S3 fact sentences, modify and create new columns, save back to S3 - finrag_fact_sentences_meta_embeds.parquet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443e95a",
   "metadata": {},
   "source": [
    "### Analysis and patterns.\n",
    "- Apple 2016 ITEM_1:\n",
    "  first: 0000320193_10-K_2016_section_1_0\n",
    "  last:  0000320193_10-K_2016_section_1_99\n",
    "- Pattern: `{CIK}_{filing}_{year}_section_{section_ID}_{sequence}`\n",
    "- We'll create the shifts of plus one and minus one for the sentence ID to perform a concept of previous and next sentence ID. But this is a rough scheme or an idea. Later we may not actually use this thoroughly because we cannot really depend on this particular element. element if the clustered key or unique key from various sources is not following the exact same pattern.\n",
    "- Local file downloaded at: ModelPipeline\\finrag_ml_tg1\\data_cache\\stage1_facts\\finrag_fact_sentences.parquet\n",
    "\n",
    "- \"Revenue increased 15% to $274.5 billion.\" Average across millions of English sentences: 1 word ≈ 1.33 tokens\n",
    "  ``` \n",
    "  - Word count: 6 words\n",
    "  - Token count (actual): 9 tokens\n",
    "    - ['Revenue', 'increased', '15', '%', 'to', '$', '274', '.', '5', 'billion', '.']\n",
    "  - Approximation: 6 × 1.33 = 8 tokens\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2985b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\stage1_facts\\finrag_fact_sentences.parquet\n",
      "✓ Loaded: 469,252 rows\n",
      "\n",
      "======================================================================\n",
      "SENTENCEID PATTERN VALIDATION\n",
      "======================================================================\n",
      "\n",
      "Total rows: 469,252\n",
      "\n",
      "[Full Pattern: CIK_filing_year_section_sectionID_sequence]\n",
      "  Valid: 469,252 (100.00%)\n",
      "  Invalid: 0 (0.00%)\n",
      "\n",
      "[Numeric Suffix Only: ends with number]\n",
      "  Valid: 469,252 (100.00%)\n",
      "  Invalid: 0 (0.00%)\n",
      "\n",
      "✓ Examples of VALID sentenceIDs (parsed):\n",
      "  0000034088_10-K_2006_section_10_1\n",
      "    → CIK: 0000034088, Year: 2006, Section: 10, Seq: 1\n",
      "  0000034088_10-K_2006_section_11_2\n",
      "    → CIK: 0000034088, Year: 2006, Section: 11, Seq: 2\n",
      "  0000034088_10-K_2006_section_12_10\n",
      "    → CIK: 0000034088, Year: 2006, Section: 12, Seq: 10\n",
      "  0000034088_10-K_2006_section_12_11\n",
      "    → CIK: 0000034088, Year: 2006, Section: 12, Seq: 11\n",
      "  0000034088_10-K_2006_section_12_13\n",
      "    → CIK: 0000034088, Year: 2006, Section: 12, Seq: 13\n",
      "\n",
      "[Component Validation]\n",
      "  CIK extracted: 469,252 rows\n",
      "  Filing extracted: 469,252 rows\n",
      "  Year extracted: 469,252 rows\n",
      "  Section extracted: 469,252 rows\n",
      "  Sequence extracted: 469,252 rows\n",
      "\n",
      "======================================================================\n",
      "✅ RECOMMENDATION: Pattern highly reliable (≥95%)\n",
      "   → Safe to use shift() for prev/next_sentenceID\n",
      "   → Sequence numbers are trustworthy for ordering\n",
      "======================================================================\n",
      "\n",
      "Latest year: 2025\n",
      "Sample sentenceIDs:\n",
      "  0000104169_10-K_2025_section_10_0\n",
      "  0000104169_10-K_2025_section_10_1\n",
      "  0000104169_10-K_2025_section_10_10\n",
      "  0000104169_10-K_2025_section_10_11\n",
      "  0000104169_10-K_2025_section_10_2\n",
      "  0000104169_10-K_2025_section_10_3\n",
      "  0000104169_10-K_2025_section_10_4\n",
      "  0000104169_10-K_2025_section_10_5\n",
      "  0000104169_10-K_2025_section_10_6\n",
      "  0000104169_10-K_2025_section_10_7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_rows': 469252,\n",
       " 'full_pattern_valid_count': 469252,\n",
       " 'full_pattern_valid_pct': 100.0,\n",
       " 'numeric_suffix_valid_count': 469252,\n",
       " 'numeric_suffix_valid_pct': 100.0,\n",
       " 'recommendation': 'reliable'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentID_pattern_validation import validate_sentenceid_pattern\n",
    "\n",
    "validate_sentenceid_pattern()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972179bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ Found ModelPipeline via file path: D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "======================================================================\n",
      "DATA PREPARATION PIPELINE\n",
      "======================================================================\n",
      "Model: cohere.embed-v4:0 (1024d)\n",
      "\n",
      "[Stage 1 Table - Downloading from S3]\n",
      "  Source: s3://sentence-data-ingestion/DATA_MERGE_ASSETS/FINRAG_FACT_SENTENCES/finrag_fact_sentences.parquet\n",
      "  Size: 23.1 MB\n",
      "  Downloaded: 469,252 rows (Cost: $0.0020 egress)\n",
      "  ✓ Cached to: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\stage1_facts\\finrag_fact_sentences.parquet\n",
      "\n",
      "[Stage 2 Meta Table - Downloading from S3]\n",
      "  Source: s3://sentence-data-ingestion/ML_EMBED_ASSETS/EMBED_META_FACT/finrag_fact_sentences_meta_embeds.parquet\n",
      "  Size: 33.9 MB\n",
      "  Downloaded: 469,252 rows (Cost: $0.0030 egress)\n",
      "  ✓ Cached to: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\meta_embeds\\finrag_fact_sentences_meta_embeds.parquet\n",
      "\n",
      "[Embeddings Fact - Downloading from S3] Provider: cohere_1024d\n",
      "  Source: s3://sentence-data-ingestion/ML_EMBED_ASSETS/EMBED_VECTORS/cohere_1024d/finrag_embeddings_cohere_1024d.parquet\n",
      "  Size: 363.0 MB\n",
      "  Downloaded: 203,076 rows (Cost: $0.0319 egress)\n",
      "  ✓ Cached to: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\embeddings\\cohere_1024d\\finrag_embeddings_cohere_1024d.parquet\n",
      "\n",
      "======================================================================\n",
      "✓ DATA PREPARATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Tables initialized / cached:\n",
      "  ✓ Stage 1 cached locally\n",
      "  ✓ Stage 2 meta cached locally\n",
      "  ✓ Embeddings cached locally → { cohere_1024d: 203076 rows }\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'stage1_cached': True,\n",
       " 'stage2_meta_cached': True,\n",
       " 'embeds_cached': ['cohere_1024d'],\n",
       " 'meta_table_initialized': False,\n",
       " 'vectors_table_initialized': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA PREPARATION PIPELINE\n",
    "# Creates Stage 2 meta table and initializes empty vectors table\n",
    "# ============================================================================\n",
    "# ============================================================================\n",
    "# PARAMETERS - Execution Control\n",
    "# INIT_*: Creates on S3 (one-time) -- initial, such as 1st table, very first time.\n",
    "# FORCE_REINIT_*: Recreates (destructive) -- deletes and recreates.\n",
    "# CACHE_*: Downloads locally -- downloads from remote to local cache for faster dev, assuming your folders are empty.\n",
    "# FORCE_RECACHE_*: Re-downloads -- forces re-download even if local cache exists. i.e. a basic refresh, override.\n",
    "# ============================================================================\n",
    "\n",
    "from data_preparation import DataPreparationPipeline\n",
    "\n",
    "DataPreparationPipeline(\n",
    "    cache_stage1_locally=True,\n",
    "    force_recache_stage1=True,\n",
    "    cache_stage2_locally=True,\n",
    "    force_recache_stage2=True,\n",
    "    cache_embeds_locally=True,\n",
    "    force_recache_embeds=True,\n",
    "    embeds_provider=\"cohere_1024d\",\n",
    "    init_meta_table=False,\n",
    "    force_reinit_meta=False,\n",
    "    init_vectors_table=False,\n",
    "    force_reinit_vectors=False\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3495f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc90fb15",
   "metadata": {},
   "source": [
    "### Embedding Generation, Storage and Push, & Embedding metadata update in main fact_sentences_meta_embed table\n",
    "\n",
    "- At filtering step:\n",
    "   - `filtered_sentence_ids = df_filtered['sentenceID'].to_list()`\n",
    "- List is your anchor throughout the pipeline\n",
    "   - Knowing which sentences to embed. Knowing which meta rows to update. Progress tracking. Cost estimation.\n",
    "- Merge.\n",
    "  - `merged = pl.concat([existing_df, new_df])` \n",
    "  - `merged = merged.unique(subset=[key], keep='last') `\n",
    "\n",
    "- p50 (median): 33 tokens\n",
    "- p75: 48 tokens\n",
    "- p95: 77 tokens\n",
    "- p99: 117 tokens\n",
    "- max: 2,281 tokens (outlier - likely table)\n",
    "- 99.7% of sentences: <500 tokens\n",
    "\n",
    "- Bedrock Cohere v4 limits:\n",
    "   - Max tokens per text: 512 tokens\n",
    "   - Max texts per batch: 96\n",
    "   - Max total request tokens: ~50K (undocumented, but conservative estimate)\n",
    "\n",
    "### Right on aws cohere page: \"Smaller chunks improve retrieval and cost\" \n",
    "- Long chunks: More tokens = higher embedding cost\n",
    "- Short chunks: Fewer tokens = lower cost\n",
    "-   1,000 chunks × 500 tokens each = 500K tokens → $0.05\n",
    "-   1,000 chunks × 50 tokens each = 50K tokens → $0.005\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "# TOP: Constants & Path Resolution\n",
    "config = MLConfig()\n",
    "VECTORS_URI = ...\n",
    "META_URI = ...\n",
    "\n",
    "# STEP 1: Load meta table (helper)\n",
    "df_meta = load_meta_table_with_cache(config)\n",
    "\n",
    "# STEP 2: Filter (returns anchor)\n",
    "df_filtered, filtered_ids = filter_sentences(df_meta, config)\n",
    "\n",
    "# STEP 3: Generate embeddings\n",
    "df_vectors, embedding_id, skipped_ids = generate_embeddings_batch(...)\n",
    "\n",
    "# STEP 4: Merge vectors (simplified - no existence checks)\n",
    "merged_vectors = merge_vectors_table(df_vectors, VECTORS_URI, storage_options)\n",
    "\n",
    "# STEP 5: Update meta (use anchor)\n",
    "updated_meta = update_meta_table(df_meta, filtered_ids, skipped_ids, model_info)\n",
    "\n",
    "# STEP 6: Save both\n",
    "Save vectors\n",
    "Save meta\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- EMBEDS:\n",
    "- APPLE; 2016? -> // → 47,755 tokens processed → Cost: $0.0048\n",
    "\n",
    "- Actual file on S3: 21MB (compressed with ZSTD)\n",
    "- EGRESS: code overstated the cost by 10x // 21MB / 1024 × $0.09 = $0.0018 (not $0.0246)\n",
    "\n",
    "data_cache/stage1_facts/ → Stage-1 parquet\n",
    "data_cache/meta_embeds/ → Stage-2 meta (35 cols)\n",
    "data_cache/embeddings/<provider>/ → vectors per provider (e.g., cohere_1024d/)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020c3bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ Found ModelPipeline via file path: D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "======================================================================\n",
      "EMBEDDING GENERATION PIPELINE\n",
      "======================================================================\n",
      "Mode: parameterized\n",
      "Model: cohere.embed-v4:0 (1024d)\n",
      "\n",
      "[Resolved Paths]\n",
      "  Vectors: ML_EMBED_ASSETS/EMBED_VECTORS/cohere_1024d/finrag_embeddings_cohere_1024d.parquet\n",
      "  Meta: ML_EMBED_ASSETS/EMBED_META_FACT/finrag_fact_sentences_meta_embeds.parquet\n",
      "✓ Using cached meta table\n",
      "  Loaded: 469,252 rows × 34 columns (Cost: $0.00)\n",
      "\n",
      "[Filtering: PARAMETERIZED MODE]\n",
      "  CIKs: [34088, 59478, 104169, 200406, 320193, 789019, 813762, 814585, 890926, 909832, 1018724, 1045810, 1065280, 1141391, 1273813, 1276520, 1318605, 1326801, 1341439, 1403161, 1652044]\n",
      "  Years: [2012, 2013, 2014]\n",
      "  Companies selected:\n",
      "    - EXXON MOBIL CORP (CIK: 34088)\n",
      "    - ELI LILLY & Co (CIK: 59478)\n",
      "    - Walmart Inc. (CIK: 104169)\n",
      "    - JOHNSON & JOHNSON (CIK: 200406)\n",
      "    - Apple Inc. (CIK: 320193)\n",
      "    - MICROSOFT CORP (CIK: 789019)\n",
      "    - ICAHN ENTERPRISES L.P. (CIK: 813762)\n",
      "    - MBIA INC (CIK: 814585)\n",
      "    - RADIAN GROUP INC (CIK: 890926)\n",
      "    - COSTCO WHOLESALE CORP /NEW (CIK: 909832)\n",
      "    - AMAZON COM INC (CIK: 1018724)\n",
      "    - NVIDIA CORP (CIK: 1045810)\n",
      "    - NETFLIX INC (CIK: 1065280)\n",
      "    - Mastercard Inc (CIK: 1141391)\n",
      "    - ASSURED GUARANTY LTD (CIK: 1273813)\n",
      "    - GENWORTH FINANCIAL INC (CIK: 1276520)\n",
      "    - Tesla, Inc. (CIK: 1318605)\n",
      "    - Meta Platforms, Inc. (CIK: 1326801)\n",
      "    - ORACLE CORP (CIK: 1341439)\n",
      "    - VISA INC. (CIK: 1403161)\n",
      "  Total sentences: 31,078\n",
      "\n",
      "[Generating Embeddings]\n",
      "  Model: cohere.embed-v4:0\n",
      "  Dimensions: 1024\n",
      "  Input sentences: 31,078\n",
      "  ⚠️  Skipped 1 outliers (>1000 tokens, 0.00%)\n",
      "  Embedding: 31,077 sentences\n",
      "    Batch Number: 25 | Progress: 2,400/31,077 (7.7%) | last 1.19s | avg/batch 1.77s | ETA 528s\n",
      "    Batch Number: 50 | Progress: 4,800/31,077 (15.4%) | last 1.03s | avg/batch 1.45s | ETA 397s\n",
      "    Batch Number: 75 | Progress: 7,200/31,077 (23.2%) | last 1.04s | avg/batch 1.32s | ETA 329s\n",
      "    Batch Number: 100 | Progress: 9,600/31,077 (30.9%) | last 0.99s | avg/batch 1.25s | ETA 279s\n",
      "    Batch Number: 125 | Progress: 12,000/31,077 (38.6%) | last 0.98s | avg/batch 1.19s | ETA 237s\n",
      "    Batch Number: 150 | Progress: 14,400/31,077 (46.3%) | last 0.98s | avg/batch 1.16s | ETA 202s\n",
      "    Batch Number: 175 | Progress: 16,800/31,077 (54.1%) | last 1.01s | avg/batch 1.19s | ETA 177s\n",
      "    Batch Number: 200 | Progress: 19,200/31,077 (61.8%) | last 2.04s | avg/batch 1.22s | ETA 151s\n",
      "    Batch Number: 225 | Progress: 21,600/31,077 (69.5%) | last 0.98s | avg/batch 1.25s | ETA 123s\n",
      "    Batch Number: 250 | Progress: 24,000/31,077 (77.2%) | last 0.96s | avg/batch 1.28s | ETA 94s\n",
      "    Batch Number: 275 | Progress: 26,400/31,077 (85.0%) | last 1.61s | avg/batch 1.29s | ETA 63s\n",
      "    Batch Number: 300 | Progress: 28,800/31,077 (92.7%) | last 0.93s | avg/batch 1.31s | ETA 31s\n",
      "  ✓ Completed: 31,077 embeddings in 324 batches | time 428.2s | avg/batch 1.32s\n",
      "  Tokens: 1,203,035 | Cost: $0.1203\n",
      "\n",
      "[Merging Vectors]\n",
      "  Existing: 375,971 rows\n",
      "  New: 31,077 rows\n",
      "  ✓ Merged: 407,048 rows (replaced 0)\n",
      "\n",
      "[Updating Meta Table]\n",
      "  Total rows: 469,252\n",
      "  Successfully embedded: 31,077\n",
      "  Skipped (outliers): 1\n",
      "  ✓ Updated: 407,048 total rows now have embeddings\n",
      "\n",
      "[Saving Results]\n",
      "  Vectors → S3: s3://sentence-data-ingestion/ML_EMBED_ASSETS/EMBED_VECTORS/cohere_1024d/finrag_embeddings_cohere_1024d.parquet\n",
      "  ✓ S3 saved: 407,048 rows (Cost: $0.00 - ingress)\n",
      "  Vectors → Local: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\embeddings\\cohere_1024d\\finrag_embeddings_cohere_1024d.parquet\n",
      "  ✓ Cached locally\n",
      "  Meta → S3: s3://sentence-data-ingestion/ML_EMBED_ASSETS/EMBED_META_FACT/finrag_fact_sentences_meta_embeds.parquet\n",
      "  ✓ S3 saved: 469,252 rows (Cost: $0.00 - ingress)\n",
      "  Meta → Local: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\meta_embeds\\finrag_fact_sentences_meta_embeds.parquet\n",
      "  ✓ Cached locally\n",
      "\n",
      "  Local cache locations:\n",
      "    - d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\embeddings\\cohere_1024d\\finrag_embeddings_cohere_1024d.parquet\n",
      "    - d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\data_cache\\meta_embeds\\finrag_fact_sentences_meta_embeds.parquet\n",
      "\n",
      "======================================================================\n",
      "✓ EMBEDDING PIPELINE COMPLETE\n",
      "======================================================================\n",
      "  Mode: parameterized\n",
      "  Sentences embedded: 31,077\n",
      "  Sentences skipped: 1\n",
      "  Total vectors in storage: 407,048\n",
      "  Total meta rows with embeddings: 407,048\n",
      "  Embedding ID: bedrock_cohere_v4_1024d_20251209_0958\n",
      "  Total tokens: 1,203,035\n",
      "  Total cost: $0.1203\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EMBEDDING GENERATION PIPELINE\n",
    "# Generates embeddings for filtered sentences and merges with existing data\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "COHERE SPECIFIC:\n",
    "    Batch fills when EITHER condition met:\n",
    "    1. 96 texts reached, OR\n",
    "    2. Total tokens reached\n",
    "def __init__(\n",
    "        self,\n",
    "        max_tokens_per_sentence=1000,    # Outlier filter\n",
    "        max_texts_per_batch=96,          # Cohere API limit\n",
    "        max_tokens_per_batch=128000,     # Cohere v4 capacity\n",
    "        batch_log_interval=40            # Progress print frequency\n",
    "    ):\n",
    "\"\"\"\n",
    "\n",
    "from embedding_generation import EmbeddingGenerationPipeline\n",
    "\n",
    "# with defaults (all settings from ml_config.yaml)\n",
    "summary = EmbeddingGenerationPipeline(batch_log_interval=25).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ff818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af94707b",
   "metadata": {},
   "source": [
    "### Why so much cost tracking and token-wise API tracking analysis? Costs.\n",
    "- console itself runs inside an AWS-managed web app -> browser fetches a pre-signed HTTPS URL generated by the console service -> in-region access or intra-AWS traffic, which is often free. but.\n",
    "- personal downloads also route through CloudFront or their internal edge acceleration, which may absorb small transfer fees.\n",
    "- Batch ETL pulling hundreds of GB per day from S3 to local, Repeated egress from multiple regions - Awareness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d071538",
   "metadata": {},
   "source": [
    "### Order Preserve Proof: Important.\n",
    "```\n",
    "\n",
    "# Building batch (order maintained)\n",
    "current_batch = []  # List preserves insertion order\n",
    "for idx, row in enumerate(sentences_data):\n",
    "    current_batch.append({'id': sent_id, 'text': sent_text})\n",
    "    all_sentence_ids.append(sent_id)  # Same order as batch\n",
    "\n",
    "# API call\n",
    "texts = [item['text'] for item in current_batch]  # Preserves order\n",
    "batch_embeddings = _call_bedrock_api(...)  # Returns in same order\n",
    "\n",
    "# Collection\n",
    "all_embeddings.extend(batch_embeddings)  # Appends in order\n",
    "\n",
    "\n",
    "df_vectors = pl.DataFrame({\n",
    "    'sentenceID': all_sentence_ids,  # [id_0, id_1, id_2, ...]\n",
    "    'embedding': all_embeddings       # [emb_0, emb_1, emb_2, ...]\n",
    "})\n",
    "\n",
    "# Row 0: sentenceID[0] → embedding[0]\n",
    "# Row 1: sentenceID[1] → embedding[1]\n",
    "# Perfect 1-to-1 mapping\n",
    "\n",
    "```\n",
    "\n",
    "### True cost analysis:\n",
    "```\n",
    "1. Polars: Serialize 469,252 rows → 281MB Parquet file (in RAM)\n",
    "2. PyArrow: Write to temporary buffer\n",
    "3. Boto3: PUT request to S3\n",
    "4. S3: Receives 281MB upload\n",
    "5. S3: Atomically replaces old object\n",
    "6. Old version: Deleted (or moved to versioning if enabled)\n",
    "\n",
    "Network transfer: 281MB upload (ingress = $0.00)\n",
    "S3 operation: PutObject (free)\n",
    "Storage: 281MB × $0.023/GB/month = $0.006/month\n",
    "```\n",
    "\n",
    "- 0.36 + 0.26 + 0.120 = $0.746 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126ecd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654fda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705a90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d72cab40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
