{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9554a170",
   "metadata": {},
   "source": [
    "## Post Vector Put Validation And Sanity - S3 Vector bucket\n",
    "\n",
    "1. Test 1 — list_vectors (sample): ingestion & schema sanity ( Confirms the index isn’t empty and  loader’s PutVectors calls succeeded.)\n",
    "   \n",
    "2. Test 2 — get_vectors(keys=[…]): id-mapping correctness ( specific key from Stage-3 (sentenceID_numsurrogate) and round-trips it via the vector index, returned key equals the one inserted, and the attached sentenceID matches the source Parquet. )\n",
    "   \n",
    "3. Test 3 — query_vectors with a random 1024-d vector: ANN path is live. ( query plane works: you get topK results back for a valid-shape query vector. index accepts. )\n",
    "   \n",
    "4. Test 4 — single-column equality filter (cik_int): confirms filtering works as expected and returns the correct subset of vectors.\n",
    "   - Distances are now present (~0.909–0.917…), confirming  earlier “NULL distance” was just missing\n",
    "\n",
    "5. Test 5 — multi-column AND filter (cik_int + report_year): confirms compound filtering works as expected and returns the correct subset of vectors.\n",
    "   1. 5A — AND(cik==1276520, year∈{2016..2020}, section==ITEM_1A)\n",
    "   2. 5B — range(2016 ≤ year ≤ 2020)\n",
    "   3. 5C — AND(cik==1276520, OR(section==ITEM_7, ITEM_1A))\n",
    "   4. 5D — negative control (non-filterable key) -- Clean HTTP 400\n",
    "\n",
    "6. Strong Gold Test Design - Deterministic Neighbor Test (Gold = local window in same doc section).\n",
    "   - Builds automatic gold set, Anchors, and evaluates self@1, hits@k, MRR@k for filtered and open regimes. And hardest cases too.\n",
    "   ``` \n",
    "   - anchor :: tuple (cik, year, section, key, pos). \n",
    "   - gold set G(anchor) = { sentences from the same (cik, year, section) whose sentence_pos lies in [pos−W, pos+W] \\ {pos}, where W is a small window }\n",
    "   - Self@1 : anchor itself returned as rank 1 when you query with its embedding. Sanity check for ID alignment and distance. \n",
    "   - Hit@k : Does any member of the gold set G(anchor) appear within the top-k results excluding the anchor itself? We report Hit@1, Hit@3, Hit@5.\n",
    "   - MRR@k (Mean Reciprocal Rank): For each anchor, find the first rank r (excluding self) where a gold neighbor appears. \n",
    "   - ; contribute 1/r if r ≤ k, else 0. Average over anchors. ( Rewards earlier hits more strongly than Hit@k. )\n",
    "   - “Hardest cases”: Anchors whose first gold hit rank is ∞ (no gold found in top-k) or very large.\n",
    "   ```\n",
    "\n",
    "\n",
    "### Understanding distance, metrics on S3 vector results:\n",
    "- seeing distance = null because the API does not return distances unless you explicitly ask for them. S3 Vectors, returnDistance defaults to false even when returnMetadata is true; you must set both flags when you want scores plus metadata in the same response.\n",
    "- On filter grammar: S3 Vectors supports a JSON filter language with $and, $or, $eq, $ne, $gt, $gte, $lt, $lte, $in, $nin, $exists.\n",
    "- SQL-ish or Dynamo-like failed\n",
    "- Redo: (a) requests distances correctly, (b) exercises the official filter grammar (including compound AND/OR and ranges), (c) verifies types and monotonic ranking, and (d) catches the permission edge case when you ask for metadata (you need both s3vectors:QueryVectors and s3vectors:GetVectors).\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5039a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config loader ready\n",
      "Available S3 Vectors methods:\n",
      "  - can_paginate\n",
      "  - close\n",
      "  - create_index\n",
      "  - create_vector_bucket\n",
      "  - delete_index\n",
      "  - delete_vector_bucket\n",
      "  - delete_vector_bucket_policy\n",
      "  - delete_vectors\n",
      "  - exceptions\n",
      "  - generate_presigned_url\n",
      "  - get_index\n",
      "  - get_paginator\n",
      "  - get_vector_bucket\n",
      "  - get_vector_bucket_policy\n",
      "  - get_vectors\n",
      "  - get_waiter\n",
      "  - list_indexes\n",
      "  - list_vector_buckets\n",
      "  - list_vectors\n",
      "  - meta\n",
      "  - put_vector_bucket_policy\n",
      "  - put_vectors\n",
      "  - query_vectors\n",
      "  - waiter_names\n"
     ]
    }
   ],
   "source": [
    "## Path loading for the loaders/ and also, a simple list of available methods in the s3vectors client.\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Now import works\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "print(\"✓ Config loader ready\")\n",
    "\n",
    "import boto3\n",
    "\n",
    "s3vectors = boto3.client('s3vectors', region_name='us-east-1')\n",
    "\n",
    "# List all available methods\n",
    "methods = [m for m in dir(s3vectors) if not m.startswith('_')]\n",
    "print(\"Available S3 Vectors methods:\")\n",
    "for m in sorted(methods):\n",
    "    print(f\"  - {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f54070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "======================================================================\n",
      "TEST 1: List Vectors (Sample)\n",
      "======================================================================\n",
      "\n",
      "✓ Successfully retrieved 10 vectors\n",
      "  Total in index: ~203,076 (not returned by list API)\n",
      "\n",
      "[Sample Vector 1]\n",
      "  Key: -2660538714400376423\n",
      "  Data type: dict_keys(['float32'])\n",
      "  Vector dimensions: 1024d\n",
      "\n",
      "  Metadata (8 fields):\n",
      "    - sentence_pos: 70\n",
      "    - sic: 6351\n",
      "    - section_sentence_count: 378\n",
      "    - embedding_id: bedrock_cohere_v4_1024d_20251109_1355\n",
      "    - section_name: ITEM_1A\n",
      "    - report_year: 2018\n",
      "    - cik_int: 890926\n",
      "    - sentenceID: 0000890926_10-K_2018_section_1A_70\n",
      "\n",
      "[Sample Vector 2]\n",
      "  Key: 6984152936648599200\n",
      "  CIK: 1065280\n",
      "  Year: 2020\n",
      "  Section: ITEM_6\n",
      "\n",
      "✓ TEST 1 PASSED: Vectors exist and have correct structure\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST 1: List Vectors - Verify Data Exists\n",
    "# ============================================================================\n",
    "\n",
    "import boto3\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "\n",
    "config = MLConfig()\n",
    "s3vectors = boto3.client(\"s3vectors\", region_name=config.region,\n",
    "                         aws_access_key_id=config.aws_access_key,\n",
    "                         aws_secret_access_key=config.aws_secret_key)\n",
    "\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME = \"finrag-sentence-fact-embed-1024d\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 1: List Vectors (Sample)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # List first 10 vectors\n",
    "    response = s3vectors.list_vectors(\n",
    "        vectorBucketName=VECTOR_BUCKET,\n",
    "        indexName=INDEX_NAME,\n",
    "        maxResults=10,\n",
    "        returnData=True,       # Include vector data\n",
    "        returnMetadata=True    # Include metadata\n",
    "    )\n",
    "    \n",
    "    vectors = response.get('vectors', [])\n",
    "    \n",
    "    print(f\"\\n✓ Successfully retrieved {len(vectors)} vectors\")\n",
    "    print(f\"  Total in index: ~203,076 (not returned by list API)\")\n",
    "    \n",
    "    if vectors:\n",
    "        print(f\"\\n[Sample Vector 1]\")\n",
    "        v = vectors[0]\n",
    "        print(f\"  Key: {v['key']}\")\n",
    "        print(f\"  Data type: {v.get('data', {}).keys()}\")\n",
    "        print(f\"  Vector dimensions: {len(v.get('data', {}).get('float32', []))}d\")\n",
    "        \n",
    "        metadata = v.get('metadata', {})\n",
    "        print(f\"\\n  Metadata ({len(metadata)} fields):\")\n",
    "        for key, value in metadata.items():\n",
    "            value_str = str(value)[:50] + \"...\" if len(str(value)) > 50 else str(value)\n",
    "            print(f\"    - {key}: {value_str}\")\n",
    "        \n",
    "        print(f\"\\n[Sample Vector 2]\")\n",
    "        if len(vectors) > 1:\n",
    "            v2 = vectors[1]\n",
    "            print(f\"  Key: {v2['key']}\")\n",
    "            print(f\"  CIK: {v2.get('metadata', {}).get('cik_int')}\")\n",
    "            print(f\"  Year: {v2.get('metadata', {}).get('report_year')}\")\n",
    "            print(f\"  Section: {v2.get('metadata', {}).get('section_name')}\")\n",
    "    \n",
    "    print(f\"\\n✓ TEST 1 PASSED: Vectors exist and have correct structure\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ TEST 1 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37b480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "======================================================================\n",
      "TEST 2: Get Vector by Key\n",
      "======================================================================\n",
      "\n",
      "[Test Parameters]\n",
      "  Key to retrieve: -6100147366912333961\n",
      "  Expected sentenceID: 0001403161_10-K_2020_section_1A_90\n",
      "\n",
      "✓ Vector retrieved successfully\n",
      "  Retrieved key: -6100147366912333961\n",
      "  Retrieved sentenceID: 0001403161_10-K_2020_section_1A_90\n",
      "  Match: True\n",
      "\n",
      "[Embedding Check]\n",
      "  Dimension: 1024d\n",
      "  First 5 values: [0.0257568359375, 0.0015716552734375, 0.052490234375, -0.0189208984375, 0.0029754638671875]\n",
      "  Data type: <class 'float'>\n",
      "\n",
      "[Metadata Check]\n",
      "  Fields present: ['section_name', 'sentence_pos', 'embedding_id', 'section_sentence_count', 'sentenceID', 'report_year', 'sic', 'cik_int']\n",
      "  cik_int: 1403161\n",
      "  report_year: 2020\n",
      "  section_name: ITEM_1A\n",
      "\n",
      "✓ TEST 2 PASSED: Vector retrieval works correctly\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST 2: Get Vector by Key - Direct Lookup\n",
    "# ============================================================================\n",
    "\n",
    "import boto3\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "config = MLConfig()\n",
    "s3vectors = boto3.client(\"s3vectors\", region_name=config.region,\n",
    "                         aws_access_key_id=config.aws_access_key,\n",
    "                         aws_secret_access_key=config.aws_secret_key)\n",
    "\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME = \"finrag-sentence-fact-embed-1024d\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 2: Get Vector by Key\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load Stage 3 to get a real key\n",
    "cache_path = config.get_s3vectors_cache_path(\"cohere_1024d\")\n",
    "df_stage3 = pl.read_parquet(cache_path)\n",
    "sample_key = str(df_stage3['sentenceID_numsurrogate'][0])\n",
    "sample_sentenceID = df_stage3['sentenceID'][0]\n",
    "\n",
    "print(f\"\\n[Test Parameters]\")\n",
    "print(f\"  Key to retrieve: {sample_key}\")\n",
    "print(f\"  Expected sentenceID: {sample_sentenceID}\")\n",
    "\n",
    "try:\n",
    "    response = s3vectors.get_vectors(\n",
    "        vectorBucketName=VECTOR_BUCKET,\n",
    "        indexName=INDEX_NAME,\n",
    "        keys=[sample_key],\n",
    "        returnData=True,\n",
    "        returnMetadata=True\n",
    "    )\n",
    "    \n",
    "    vectors = response.get('vectors', [])\n",
    "    \n",
    "    if len(vectors) == 0:\n",
    "        print(f\"\\n✗ TEST 2 FAILED: Vector not found for key {sample_key}\")\n",
    "    else:\n",
    "        v = vectors[0]\n",
    "        retrieved_key = v['key']\n",
    "        retrieved_sentenceID = v.get('metadata', {}).get('sentenceID')\n",
    "        \n",
    "        print(f\"\\n✓ Vector retrieved successfully\")\n",
    "        print(f\"  Retrieved key: {retrieved_key}\")\n",
    "        print(f\"  Retrieved sentenceID: {retrieved_sentenceID}\")\n",
    "        print(f\"  Match: {retrieved_sentenceID == sample_sentenceID}\")\n",
    "        \n",
    "        # Check embedding\n",
    "        embedding = v.get('data', {}).get('float32', [])\n",
    "        print(f\"\\n[Embedding Check]\")\n",
    "        print(f\"  Dimension: {len(embedding)}d\")\n",
    "        print(f\"  First 5 values: {embedding[:5]}\")\n",
    "        print(f\"  Data type: {type(embedding[0]) if embedding else 'N/A'}\")\n",
    "        \n",
    "        # Check all metadata\n",
    "        metadata = v.get('metadata', {})\n",
    "        print(f\"\\n[Metadata Check]\")\n",
    "        print(f\"  Fields present: {list(metadata.keys())}\")\n",
    "        print(f\"  cik_int: {metadata.get('cik_int')}\")\n",
    "        print(f\"  report_year: {metadata.get('report_year')}\")\n",
    "        print(f\"  section_name: {metadata.get('section_name')}\")\n",
    "        \n",
    "        print(f\"\\n✓ TEST 2 PASSED: Vector retrieval works correctly\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ TEST 2 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e106301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "======================================================================\n",
      "DIAGNOSTIC: Index Status Check\n",
      "======================================================================\n",
      "\n",
      "[Index Configuration]\n",
      "  Name: finrag-sentence-fact-embed-1024d\n",
      "  Status: Check console for vector count\n",
      "  Created: 2025-11-10 14:52:15-05:00\n",
      "  Dimension: 1024\n",
      "  Distance: cosine\n",
      "\n",
      "[Attempting to list vectors...]\n",
      "  Vectors found: 5\n",
      "  ✓ Index contains vectors\n",
      "  Sample key: -2660538714400376423\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST 2.1: Index Populated Test: Check Index Vector Count\n",
    "# ============================================================================\n",
    "\n",
    "import boto3\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "\n",
    "config = MLConfig()\n",
    "s3vectors = boto3.client(\"s3vectors\", region_name=config.region,\n",
    "                         aws_access_key_id=config.aws_access_key,\n",
    "                         aws_secret_access_key=config.aws_secret_key)\n",
    "\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME = \"finrag-sentence-fact-embed-1024d\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIAGNOSTIC: Index Status Check\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check index details\n",
    "response = s3vectors.get_index(\n",
    "    vectorBucketName=VECTOR_BUCKET,\n",
    "    indexName=INDEX_NAME\n",
    ")\n",
    "\n",
    "index_data = response['index']\n",
    "\n",
    "print(f\"\\n[Index Configuration]\")\n",
    "print(f\"  Name: {index_data['indexName']}\")\n",
    "print(f\"  Status: Check console for vector count\")\n",
    "print(f\"  Created: {index_data['creationTime']}\")\n",
    "print(f\"  Dimension: {index_data['dimension']}\")\n",
    "print(f\"  Distance: {index_data['distanceMetric']}\")\n",
    "\n",
    "# Try list_vectors to see if ANY vectors exist\n",
    "print(f\"\\n[Attempting to list vectors...]\")\n",
    "try:\n",
    "    list_response = s3vectors.list_vectors(\n",
    "        vectorBucketName=VECTOR_BUCKET,\n",
    "        indexName=INDEX_NAME,\n",
    "        maxResults=5\n",
    "    )\n",
    "    \n",
    "    vectors = list_response.get('vectors', [])\n",
    "    print(f\"  Vectors found: {len(vectors)}\")\n",
    "    \n",
    "    if vectors:\n",
    "        print(f\"  ✓ Index contains vectors\")\n",
    "        print(f\"  Sample key: {vectors[0]['key']}\")\n",
    "    else:\n",
    "        print(f\"  ✗ Index appears EMPTY!\")\n",
    "        print(f\"  This explains zero query results\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  Error listing vectors: {e}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ee1732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "shape: (10, 6)\n",
      "┌──────┬──────────────────────┬──────────┬─────────┬─────────────┬──────────────┐\n",
      "│ rank ┆ key                  ┆ distance ┆ cik_int ┆ report_year ┆ section_name │\n",
      "│ ---  ┆ ---                  ┆ ---      ┆ ---     ┆ ---         ┆ ---          │\n",
      "│ i64  ┆ str                  ┆ f64      ┆ i64     ┆ i64         ┆ str          │\n",
      "╞══════╪══════════════════════╪══════════╪═════════╪═════════════╪══════════════╡\n",
      "│ 1    ┆ 6322569510623725774  ┆ 0.886695 ┆ 1318605 ┆ 2016        ┆ ITEM_8       │\n",
      "│ 2    ┆ -8217675960081250299 ┆ 0.888923 ┆ 1318605 ┆ 2018        ┆ ITEM_8       │\n",
      "│ 3    ┆ -1701519652995191919 ┆ 0.888923 ┆ 1318605 ┆ 2017        ┆ ITEM_8       │\n",
      "│ 4    ┆ -1663766618521785107 ┆ 0.888923 ┆ 1318605 ┆ 2019        ┆ ITEM_8       │\n",
      "│ 5    ┆ -1315218437024154496 ┆ 0.892382 ┆ 1318605 ┆ 2016        ┆ ITEM_8       │\n",
      "│ 6    ┆ 3163729756936668591  ┆ 0.892447 ┆ 1318605 ┆ 2020        ┆ ITEM_8       │\n",
      "│ 7    ┆ -8048853950037971886 ┆ 0.894671 ┆ 1273813 ┆ 2019        ┆ ITEM_7       │\n",
      "│ 8    ┆ 6232058925969875945  ┆ 0.896807 ┆ 1045810 ┆ 2020        ┆ ITEM_1       │\n",
      "│ 9    ┆ -958952854495862781  ┆ 0.899079 ┆ 1276520 ┆ 2019        ┆ ITEM_7       │\n",
      "│ 10   ┆ 4662150451690956370  ┆ 0.899827 ┆ 1318605 ┆ 2017        ┆ ITEM_8       │\n",
      "└──────┴──────────────────────┴──────────┴─────────┴─────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST 3: Query Vectors - DataFrame Output\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "import boto3, numpy as np, polars as pl\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "\n",
    "cfg = MLConfig()\n",
    "s3v = boto3.client(\"s3vectors\", region_name=cfg.region,\n",
    "                   aws_access_key_id=cfg.aws_access_key,\n",
    "                   aws_secret_access_key=cfg.aws_secret_key)\n",
    "\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME    = \"finrag-sentence-fact-embed-1024d\"\n",
    "DIM           = 1024\n",
    "\n",
    "# random 1024-d probe just to test shape/latency; replace with a real query embed to validate semantics\n",
    "probe = np.random.randn(DIM).astype(np.float32).tolist()\n",
    "\n",
    "resp = s3v.query_vectors(\n",
    "    vectorBucketName=VECTOR_BUCKET,\n",
    "    indexName=INDEX_NAME,\n",
    "    queryVector={\"float32\": probe},\n",
    "    topK=10,\n",
    "    returnMetadata=True,     # include  cik/year/section metadata\n",
    "    returnDistance=True      # <-- REQUIRED to see numeric distances\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for i, v in enumerate(resp.get(\"vectors\", []), 1):\n",
    "    rows.append({\n",
    "        \"rank\": i,\n",
    "        \"key\": v[\"key\"],\n",
    "        \"distance\": v.get(\"distance\"),\n",
    "        \"cik_int\": v.get(\"metadata\", {}).get(\"cik_int\"),\n",
    "        \"report_year\": v.get(\"metadata\", {}).get(\"report_year\"),\n",
    "        \"section_name\": v.get(\"metadata\", {}).get(\"section_name\")\n",
    "    })\n",
    "\n",
    "df = pl.DataFrame(rows)\n",
    "\n",
    "# Assertions: distances present and monotonic nondecreasing by rank\n",
    "assert df[\"distance\"].is_not_null().all(), \"distance missing; set returnDistance=True\"\n",
    "assert (df[\"distance\"].diff().fill_null(0) >= 0).all(), \"ranking not monotonic by distance\"\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb7f59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "shape: (10, 5)\n",
      "┌──────┬──────────┬──────┬─────────┬──────┐\n",
      "│ rank ┆ distance ┆ year ┆ section ┆ sic  │\n",
      "│ ---  ┆ ---      ┆ ---  ┆ ---     ┆ ---  │\n",
      "│ i64  ┆ f64      ┆ i64  ┆ str     ┆ str  │\n",
      "╞══════╪══════════╪══════╪═════════╪══════╡\n",
      "│ 1    ┆ 0.908764 ┆ 2020 ┆ ITEM_7  ┆ 6311 │\n",
      "│ 2    ┆ 0.927659 ┆ 2020 ┆ ITEM_1  ┆ 6311 │\n",
      "│ 3    ┆ 0.928635 ┆ 2020 ┆ ITEM_1  ┆ 6311 │\n",
      "│ 4    ┆ 0.929487 ┆ 2019 ┆ ITEM_1A ┆ 6311 │\n",
      "│ 5    ┆ 0.929487 ┆ 2020 ┆ ITEM_1A ┆ 6311 │\n",
      "│ 6    ┆ 0.929487 ┆ 2018 ┆ ITEM_1A ┆ 6311 │\n",
      "│ 7    ┆ 0.930932 ┆ 2016 ┆ ITEM_8  ┆ 6311 │\n",
      "│ 8    ┆ 0.931147 ┆ 2018 ┆ ITEM_8  ┆ 6311 │\n",
      "│ 9    ┆ 0.931147 ┆ 2016 ┆ ITEM_8  ┆ 6311 │\n",
      "│ 10   ┆ 0.931147 ┆ 2017 ┆ ITEM_8  ┆ 6311 │\n",
      "└──────┴──────────┴──────┴─────────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST 4: Query Vectors - Simple Filter (Single Column)\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "\n",
    "import boto3, numpy as np, polars as pl\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "\n",
    "cfg = MLConfig()\n",
    "s3v = boto3.client(\"s3vectors\", region_name=cfg.region,\n",
    "                   aws_access_key_id=cfg.aws_access_key,\n",
    "                   aws_secret_access_key=cfg.aws_secret_key)\n",
    "\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME    = \"finrag-sentence-fact-embed-1024d\"\n",
    "DIM           = 1024\n",
    "\n",
    "# random 1024-d probe just to test shape/latency; replace with a real query embed to validate semantics\n",
    "probe = np.random.randn(DIM).astype(np.float32).tolist()\n",
    "\n",
    "\n",
    "flt = {\"cik_int\": 1276520}  # equality uses implicit $eq\n",
    "\n",
    "resp = s3v.query_vectors(\n",
    "    vectorBucketName=VECTOR_BUCKET,\n",
    "    indexName=INDEX_NAME,\n",
    "    queryVector={\"float32\": probe},\n",
    "    topK=10,\n",
    "    filter=flt,              # server-side filtering\n",
    "    returnMetadata=True,\n",
    "    returnDistance=True\n",
    ")\n",
    "\n",
    "hits = resp.get(\"vectors\", [])\n",
    "assert hits, \"no hits returned\"\n",
    "\n",
    "# Every hit must satisfy cik_int == 1276520\n",
    "assert all(h.get(\"metadata\", {}).get(\"cik_int\") == 1276520 for h in hits), \"filter not applied on cik_int\"\n",
    "# Distances present and monotonic\n",
    "dists = [h.get(\"distance\") for h in hits]\n",
    "assert all(d is not None for d in dists), \"distance missing; set returnDistance=True\"\n",
    "assert all((dists[i] - dists[i-1]) >= 0 for i in range(1, len(dists))), \"non-monotonic ranking\"\n",
    "\n",
    "print(pl.DataFrame([{\n",
    "    \"rank\": i+1,\n",
    "    \"distance\": round(dists[i], 6),\n",
    "    \"year\": hits[i][\"metadata\"].get(\"report_year\"),\n",
    "    \"section\": hits[i][\"metadata\"].get(\"section_name\"),\n",
    "    \"sic\": hits[i][\"metadata\"].get(\"sic\")\n",
    "} for i in range(len(hits))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f9ea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "\n",
      "===== 5A: AND(cik == 1276520, year ∈ {2016..2020}, section == ITEM_1A) =====\n",
      "Hits: 20\n",
      "shape: (10, 5)\n",
      "┌──────┬──────────┬─────────┬─────────────┬──────────────┐\n",
      "│ rank ┆ distance ┆ cik_int ┆ report_year ┆ section_name │\n",
      "│ ---  ┆ ---      ┆ ---     ┆ ---         ┆ ---          │\n",
      "│ i64  ┆ f64      ┆ i64     ┆ i64         ┆ str          │\n",
      "╞══════╪══════════╪═════════╪═════════════╪══════════════╡\n",
      "│ 1    ┆ 0.920175 ┆ 1276520 ┆ 2020        ┆ ITEM_1A      │\n",
      "│ 2    ┆ 0.923693 ┆ 1276520 ┆ 2019        ┆ ITEM_1A      │\n",
      "│ 3    ┆ 0.924222 ┆ 1276520 ┆ 2018        ┆ ITEM_1A      │\n",
      "│ 4    ┆ 0.924348 ┆ 1276520 ┆ 2016        ┆ ITEM_1A      │\n",
      "│ 5    ┆ 0.924348 ┆ 1276520 ┆ 2017        ┆ ITEM_1A      │\n",
      "│ 6    ┆ 0.927017 ┆ 1276520 ┆ 2016        ┆ ITEM_1A      │\n",
      "│ 7    ┆ 0.927017 ┆ 1276520 ┆ 2017        ┆ ITEM_1A      │\n",
      "│ 8    ┆ 0.927017 ┆ 1276520 ┆ 2019        ┆ ITEM_1A      │\n",
      "│ 9    ┆ 0.927017 ┆ 1276520 ┆ 2018        ┆ ITEM_1A      │\n",
      "│ 10   ┆ 0.932276 ┆ 1276520 ┆ 2020        ┆ ITEM_1A      │\n",
      "└──────┴──────────┴─────────┴─────────────┴──────────────┘\n",
      "5A: PASS\n",
      "\n",
      "===== 5B: range(2016 ≤ year ≤ 2020) =====\n",
      "Hits: 20\n",
      "shape: (10, 5)\n",
      "┌──────┬──────────┬─────────┬─────────────┬──────────────┐\n",
      "│ rank ┆ distance ┆ cik_int ┆ report_year ┆ section_name │\n",
      "│ ---  ┆ ---      ┆ ---     ┆ ---         ┆ ---          │\n",
      "│ i64  ┆ f64      ┆ i64     ┆ i64         ┆ str          │\n",
      "╞══════╪══════════╪═════════╪═════════════╪══════════════╡\n",
      "│ 1    ┆ 0.892246 ┆ 34088   ┆ 2017        ┆ ITEM_15      │\n",
      "│ 2    ┆ 0.892724 ┆ 34088   ┆ 2019        ┆ ITEM_15      │\n",
      "│ 3    ┆ 0.892724 ┆ 34088   ┆ 2019        ┆ ITEM_15      │\n",
      "│ 4    ┆ 0.892724 ┆ 34088   ┆ 2020        ┆ ITEM_15      │\n",
      "│ 5    ┆ 0.892724 ┆ 34088   ┆ 2016        ┆ ITEM_15      │\n",
      "│ 6    ┆ 0.892724 ┆ 34088   ┆ 2018        ┆ ITEM_15      │\n",
      "│ 7    ┆ 0.892724 ┆ 34088   ┆ 2020        ┆ ITEM_15      │\n",
      "│ 8    ┆ 0.896338 ┆ 1341439 ┆ 2017        ┆ ITEM_7       │\n",
      "│ 9    ┆ 0.896338 ┆ 1341439 ┆ 2016        ┆ ITEM_7       │\n",
      "│ 10   ┆ 0.896338 ┆ 1341439 ┆ 2017        ┆ ITEM_15      │\n",
      "└──────┴──────────┴─────────┴─────────────┴──────────────┘\n",
      "5B: PASS\n",
      "\n",
      "===== 5C: AND(cik == 1276520, OR(section == ITEM_7, ITEM_1A)) =====\n",
      "Hits: 20\n",
      "shape: (10, 5)\n",
      "┌──────┬──────────┬─────────┬─────────────┬──────────────┐\n",
      "│ rank ┆ distance ┆ cik_int ┆ report_year ┆ section_name │\n",
      "│ ---  ┆ ---      ┆ ---     ┆ ---         ┆ ---          │\n",
      "│ i64  ┆ f64      ┆ i64     ┆ i64         ┆ str          │\n",
      "╞══════╪══════════╪═════════╪═════════════╪══════════════╡\n",
      "│ 1    ┆ 0.920175 ┆ 1276520 ┆ 2020        ┆ ITEM_1A      │\n",
      "│ 2    ┆ 0.923693 ┆ 1276520 ┆ 2019        ┆ ITEM_1A      │\n",
      "│ 3    ┆ 0.924222 ┆ 1276520 ┆ 2018        ┆ ITEM_1A      │\n",
      "│ 4    ┆ 0.924348 ┆ 1276520 ┆ 2016        ┆ ITEM_1A      │\n",
      "│ 5    ┆ 0.924348 ┆ 1276520 ┆ 2017        ┆ ITEM_1A      │\n",
      "│ 6    ┆ 0.927017 ┆ 1276520 ┆ 2016        ┆ ITEM_1A      │\n",
      "│ 7    ┆ 0.927017 ┆ 1276520 ┆ 2019        ┆ ITEM_1A      │\n",
      "│ 8    ┆ 0.927017 ┆ 1276520 ┆ 2017        ┆ ITEM_1A      │\n",
      "│ 9    ┆ 0.927017 ┆ 1276520 ┆ 2018        ┆ ITEM_1A      │\n",
      "│ 10   ┆ 0.932135 ┆ 1276520 ┆ 2020        ┆ ITEM_7       │\n",
      "└──────┴──────────┴─────────┴─────────────┴──────────────┘\n",
      "5C: PASS\n",
      "\n",
      "===== 5D: filter on non-filterable metadata (embedding_id) (expect 400) =====\n",
      "Got expected HTTP 400 for non-filterable filter.\n",
      "5D: PASS\n",
      "\n",
      "All Test 5 sub-cases completed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST 5: Compound filter suite (5A–5D) for S3 Vectors\n",
    "# - AND with IN set\n",
    "# - Numeric range (gte/lte)\n",
    "# - OR combined with AND\n",
    "# - Negative: filter on a non-filterable key -> expect 400\n",
    "# ============================================================================\n",
    "\n",
    "import boto3, numpy as np, polars as pl\n",
    "from botocore.exceptions import ClientError\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "\n",
    "# --- Config & client ---\n",
    "cfg = MLConfig()\n",
    "s3v = boto3.client(\n",
    "    \"s3vectors\",\n",
    "    region_name=cfg.region,\n",
    "    aws_access_key_id=cfg.aws_access_key,\n",
    "    aws_secret_access_key=cfg.aws_secret_key,\n",
    ")\n",
    "\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME    = \"finrag-sentence-fact-embed-1024d\"\n",
    "DIM           = 1024\n",
    "\n",
    "# Random probe just to exercise the path; replace with a real query embedding to test semantic quality\n",
    "probe = np.random.randn(DIM).astype(np.float32).tolist()\n",
    "qvec = {\"float32\": probe}\n",
    "\n",
    "# --- Utilities ---\n",
    "\n",
    "def run_query(name, flt, topk=20, show_cols=(\"distance\",\"cik_int\",\"report_year\",\"section_name\"), max_rows=10):\n",
    "    \"\"\"Run a query with distance+metadata, return Polars DataFrame and raw hits.\"\"\"\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    resp = s3v.query_vectors(\n",
    "        vectorBucketName=VECTOR_BUCKET,\n",
    "        indexName=INDEX_NAME,\n",
    "        queryVector=qvec,\n",
    "        topK=topk,\n",
    "        filter=flt,\n",
    "        returnMetadata=True,\n",
    "        returnDistance=True,\n",
    "    )\n",
    "    hits = resp.get(\"vectors\", [])\n",
    "    print(f\"Hits: {len(hits)}\")\n",
    "\n",
    "    # Build a compact table for inspection\n",
    "    rows = []\n",
    "    for i, v in enumerate(hits, 1):\n",
    "        md = v.get(\"metadata\", {}) or {}\n",
    "        row = {\"rank\": i, \"distance\": v.get(\"distance\")}\n",
    "        row.update({ \"cik_int\": md.get(\"cik_int\"),\n",
    "                     \"report_year\": md.get(\"report_year\"),\n",
    "                     \"section_name\": md.get(\"section_name\"),\n",
    "                     \"sic\": md.get(\"sic\") })\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pl.DataFrame(rows)\n",
    "    if len(df) > 0:\n",
    "        # Keep a small selection of columns for display\n",
    "        cols = [\"rank\"] + [c for c in show_cols if c in df.columns]\n",
    "        print(df.select(cols).head(max_rows))\n",
    "    else:\n",
    "        print(\"No results.\")\n",
    "\n",
    "    # Core invariants\n",
    "    if len(df) > 0:\n",
    "        assert df[\"distance\"].is_not_null().all(), \"distance missing; set returnDistance=True\"\n",
    "        dist = df[\"distance\"].to_list()\n",
    "        assert all((dist[i] - dist[i-1]) >= -1e-12 for i in range(1, len(dist))), \"ranking not monotonic by distance\"\n",
    "\n",
    "    return df, hits\n",
    "\n",
    "def expect_400_on_filter(name, flt):\n",
    "    \"\"\"Run a query expected to fail due to non-filterable metadata; assert HTTP 400.\"\"\"\n",
    "    print(f\"\\n===== {name} (expect 400) =====\")\n",
    "    try:\n",
    "        s3v.query_vectors(\n",
    "            vectorBucketName=VECTOR_BUCKET,\n",
    "            indexName=INDEX_NAME,\n",
    "            queryVector=qvec,\n",
    "            topK=5,\n",
    "            filter=flt,\n",
    "            returnMetadata=True,\n",
    "            returnDistance=True,\n",
    "        )\n",
    "        raise AssertionError(\"Expected 400 when filtering on a non-filterable key, but query succeeded\")\n",
    "    except ClientError as e:\n",
    "        status = e.response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\", 0)\n",
    "        if status != 400:\n",
    "            raise AssertionError(f\"Expected HTTP 400, got {status}\")\n",
    "        print(\"Got expected HTTP 400 for non-filterable filter.\")\n",
    "\n",
    "# --- 5A. AND of three predicates (CIK, year IN set, section exact) ---\n",
    "flt_5A = {\n",
    "    \"$and\": [\n",
    "        {\"cik_int\": {\"$eq\": 1276520}},\n",
    "        {\"report_year\": {\"$in\": [2016, 2017, 2018, 2019, 2020]}},\n",
    "        {\"section_name\": {\"$eq\": \"ITEM_1A\"}},\n",
    "    ]\n",
    "}\n",
    "df_5A, hits_5A = run_query(\"5A: AND(cik == 1276520, year ∈ {2016..2020}, section == ITEM_1A)\", flt_5A)\n",
    "if len(df_5A) > 0:\n",
    "    assert (df_5A[\"cik_int\"] == 1276520).all(), \"CIK mismatch in 5A\"\n",
    "    assert df_5A[\"report_year\"].is_in([2016, 2017, 2018, 2019, 2020]).all(), \"Year not in set in 5A\"\n",
    "    assert (df_5A[\"section_name\"] == \"ITEM_1A\").all(), \"Section mismatch in 5A\"\n",
    "print(\"5A: PASS\")\n",
    "\n",
    "# --- 5B. Numeric range only (year between 2016 and 2020 inclusive) ---\n",
    "flt_5B = {\"report_year\": {\"$gte\": 2016, \"$lte\": 2020}}\n",
    "df_5B, hits_5B = run_query(\"5B: range(2016 ≤ year ≤ 2020)\", flt_5B)\n",
    "if len(df_5B) > 0:\n",
    "    years = df_5B[\"report_year\"].drop_nulls().to_list()\n",
    "    assert all(2016 <= y <= 2020 for y in years), \"Year out of range in 5B\"\n",
    "print(\"5B: PASS\")\n",
    "\n",
    "# --- 5C. OR between two sections, combined with a CIK ---\n",
    "flt_5C = {\n",
    "    \"$and\": [\n",
    "        {\"cik_int\": {\"$eq\": 1276520}},\n",
    "        {\"$or\": [\n",
    "            {\"section_name\": {\"$eq\": \"ITEM_7\"}},\n",
    "            {\"section_name\": {\"$eq\": \"ITEM_1A\"}},\n",
    "        ]}\n",
    "    ]\n",
    "}\n",
    "df_5C, hits_5C = run_query(\"5C: AND(cik == 1276520, OR(section == ITEM_7, ITEM_1A))\", flt_5C)\n",
    "if len(df_5C) > 0:\n",
    "    allowed = {\"ITEM_7\", \"ITEM_1A\"}\n",
    "    assert (df_5C[\"cik_int\"] == 1276520).all(), \"CIK mismatch in 5C\"\n",
    "    assert set(df_5C[\"section_name\"].drop_nulls().to_list()).issubset(allowed), \"Section mismatch in 5C\"\n",
    "print(\"5C: PASS\")\n",
    "\n",
    "# --- 5D. Negative: filtering on a non-filterable key should 400 ---\n",
    "# Adjust the key below to one you actually configured as non-filterable at index creation time.\n",
    "# From  config: sentenceID, embedding_id, section_sentence_count were non-filterable.\n",
    "flt_5D = {\"embedding_id\": {\"$eq\": \"some-id\"}}\n",
    "expect_400_on_filter(\"5D: filter on non-filterable metadata (embedding_id)\", flt_5D)\n",
    "print(\"5D: PASS\")\n",
    "\n",
    "print(\"\\nAll Test 5 sub-cases completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f62a47",
   "metadata": {},
   "source": [
    "### Gold test / “quality” tests on top: \n",
    "(1) a deterministic neighbor test using a small gold set of sentences and their known nearest neighbors to compute hit@k, and \n",
    "(2) potentially later, a distance calibration script or Platt-style mapping ideas ( to can reject low-confidence hits consistently across CIK/year slices.)\n",
    "\n",
    "### Design - Attempt Gold Test P1, Gold Test P2, Gold Test P3 (Business Realism). \n",
    "### Gold Test P1 Explanation: \n",
    "- We build a gold set automatically from our own corpus using structure already have (cik_int, report_year, section_name, sentence_pos). \n",
    "- For each anchor sentence, “true neighbors” are defined as sentences from the same document slice—same cik_int, report_year, and section_name—that lie within a small positional window (e.g., ±3) around sentence_pos. \n",
    "- This exploits the fact that adjacent sentences in the same section are very likely to be semantically close. It gives we deterministic, explainable positives without hand labels.\n",
    "\n",
    "**What this measures:**\n",
    "- Self@1: whether the index returns the exact anchor as the top-1 neighbor (sanity and id/shape check).\n",
    "- Hit@k vs the gold window: with and without a server-side filter.\n",
    "- Filtered regime restricts candidates to the same (cik, year, section)—tests pure ranking quality.\n",
    "- Open regime allows global candidates—tests robustness when relevant text competes with other issuers/years/sections.\n",
    "- MRR@k and distance stats: median, percentile bands to see calibration drift.\n",
    "- Hard negatives: we also report the best-ranked false positive so we can spot systematic confusions (e.g., “ITEM_7” bleeding into “ITEM_1A”).\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------\n",
    "- **Deeper Explanation:** its closest “true” neighbors should be nearby sentences from the same issuer (cik_int), same year, same section, typically within a small positional window around the anchor’s sentence_pos.\n",
    "- that is, **inexpensive, deterministic ground truth without hand labels.**\n",
    "- anchor :: tuple (cik, year, section, key, pos). \n",
    "- gold set G(anchor) = { sentences from the same (cik, year, section) whose sentence_pos lies in [pos−W, pos+W] \\ {pos}, where W is a small window }\n",
    "- Self@1 : anchor itself returned as rank 1 when we query with its embedding. Sanity check for ID alignment and distance. \n",
    "- Hit@k : Does any member of the gold set G(anchor) appear within the top-k results excluding the anchor itself? We report Hit@1, Hit@3, Hit@5.\n",
    "- MRR@k (Mean Reciprocal Rank): For each anchor, find the first rank r (excluding self) where a gold neighbor appears. \n",
    "- ; contribute 1/r if r ≤ k, else 0. Average over anchors. ( Rewards earlier hits more strongly than Hit@k. )\n",
    "- “Hardest cases”: Anchors whose first gold hit rank is ∞ (no gold found in top-k) or very large.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b7faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joems\\AppData\\Local\\Temp\\ipykernel_36756\\3670486126.py:66: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  sec_sizes = df.group_by(gcols).agg(pl.count().alias(\"n\")).filter(pl.col(\"n\") >= section_minlen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anchors evaluated: 60\n",
      "\n",
      "=== Filtered regime (same CIK/year/section) ===\n",
      "Self@1:  96.7%\n",
      "Hit@1:   0.0%\n",
      "Hit@3:   58.3%\n",
      "Hit@5:   66.7%\n",
      "MRR@30: 0.311\n",
      "Median distance (non-self): 0.559\n",
      "\n",
      "=== Open regime (no filter) ===\n",
      "Self@1:  58.3%\n",
      "Hit@1:   0.0%\n",
      "Hit@3:   0.0%\n",
      "Hit@5:   0.0%\n",
      "MRR@30: 0.036\n",
      "Median distance (non-self): 0.376\n",
      "\n",
      "=== Hardest cases (filtered) ===\n",
      "shape: (5, 6)\n",
      "┌───────┬──────┬─────────┬────────────┬─────────────────────┬───────────────┐\n",
      "│ cik   ┆ year ┆ sec     ┆ anchor_pos ┆ rank_first_hit_filt ┆ dist_med_filt │\n",
      "│ ---   ┆ ---  ┆ ---     ┆ ---        ┆ ---                 ┆ ---           │\n",
      "│ i64   ┆ i64  ┆ str     ┆ i64        ┆ f64                 ┆ f64           │\n",
      "╞═══════╪══════╪═════════╪════════════╪═════════════════════╪═══════════════╡\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 2          ┆ inf                 ┆ 0.607892      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_2  ┆ 1          ┆ inf                 ┆ 0.593437      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_2  ┆ 81         ┆ inf                 ┆ 0.590238      │\n",
      "│ 34088 ┆ 2016 ┆ ITEM_2  ┆ 1          ┆ inf                 ┆ 0.53692       │\n",
      "│ 34088 ┆ 2017 ┆ ITEM_15 ┆ 910        ┆ inf                 ┆ 0.434466      │\n",
      "└───────┴──────┴─────────┴────────────┴─────────────────────┴───────────────┘\n",
      "\n",
      "=== Hardest cases (open) ===\n",
      "shape: (5, 6)\n",
      "┌───────┬──────┬─────────┬────────────┬─────────────────────┬───────────────┐\n",
      "│ cik   ┆ year ┆ sec     ┆ anchor_pos ┆ rank_first_hit_open ┆ dist_med_open │\n",
      "│ ---   ┆ ---  ┆ ---     ┆ ---        ┆ ---                 ┆ ---           │\n",
      "│ i64   ┆ i64  ┆ str     ┆ i64        ┆ f64                 ┆ f64           │\n",
      "╞═══════╪══════╪═════════╪════════════╪═════════════════════╪═══════════════╡\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 2          ┆ inf                 ┆ 0.250427      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 231        ┆ inf                 ┆ 0.394132      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 418        ┆ inf                 ┆ 0.256457      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 665        ┆ inf                 ┆ 0.341348      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_1A ┆ 18         ┆ inf                 ┆ 0.380094      │\n",
      "└───────┴──────┴─────────┴────────────┴─────────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Deterministic Neighbor Test (Gold = local window in same doc section)\n",
    "\n",
    "# - Builds automatic gold sets from Stage 3 Parquet\n",
    "# - Computes Self@1, Hit@k, MRR@k for filtered and open regimes\n",
    "# - Prints failure cases for inspection\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3, numpy as np, polars as pl, math, statistics as stats\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration\n",
    "# ---------------------------\n",
    "cfg = MLConfig()\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME    = \"finrag-sentence-fact-embed-1024d\"\n",
    "DIM           = cfg.s3vectors_dimensions(\"cohere_1024d\")  # 1024\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# WINDOW        = 3       # gold neighbor window on sentence_pos (±W)\n",
    "# TOPK_OPEN     = 20      # topK for open-regime queries\n",
    "# TOPK_FILT     = 20      # topK for filtered-regime queries\n",
    "# MAX_ANCHORS   = 40      # number of anchors to evaluate (raise to 200+ later)\n",
    "# SECTION_MINLEN= 40      # only sample sections with at least this many sentences\n",
    "# SEED          = 7\n",
    "\n",
    "WINDOW        = 5        # widen local gold to ±5 sentences\n",
    "TOPK_FILT     = 30       # give the filtered regime more search budget\n",
    "TOPK_OPEN     = 30       # mild bump for open regime to surface a few true locals\n",
    "MAX_ANCHORS   = 60       # slightly larger sample for stability of metrics\n",
    "SECTION_MINLEN= 20       # avoid tiny/fragmented sections as anchors/gold sources\n",
    "SEED          = 7        # keep deterministic comparability\n",
    "\n",
    "# Client\n",
    "s3v = boto3.client(\"s3vectors\",\n",
    "                   region_name=cfg.region,\n",
    "                   aws_access_key_id=cfg.aws_access_key,\n",
    "                   aws_secret_access_key=cfg.aws_secret_key)\n",
    "\n",
    "# Load Stage 3 cache (local Parquet)\n",
    "stage3_path = cfg.get_s3vectors_cache_path(\"cohere_1024d\")\n",
    "df = pl.read_parquet(stage3_path)\n",
    "\n",
    "# ---------------------------\n",
    "# Helper functions\n",
    "# ---------------------------\n",
    "def cosine_distance(a, b):\n",
    "    # For sanity checks only (we rely on service distances for metrics)\n",
    "    a = np.asarray(a, dtype=np.float32); b = np.asarray(b, dtype=np.float32)\n",
    "    na = np.linalg.norm(a); nb = np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0: return 1.0\n",
    "    return 1.0 - float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def pick_anchors(df, max_anchors=MAX_ANCHORS, section_minlen=SECTION_MINLEN, seed=SEED):\n",
    "    # Choose anchors deterministically but spaced across sections/doc-years\n",
    "    # 1) group by (cik, year, section), keep only reasonably long sections\n",
    "    gcols = [\"cik_int\", \"report_year\", \"section_name\"]\n",
    "    sec_sizes = df.group_by(gcols).agg(pl.count().alias(\"n\")).filter(pl.col(\"n\") >= section_minlen)\n",
    "    long_secs = sec_sizes.join(df, on=gcols, how=\"inner\")\n",
    "\n",
    "    # Stable order ensures determinism\n",
    "    long_secs = long_secs.sort(by=[\"cik_int\",\"report_year\",\"section_name\",\"sentence_pos\"])\n",
    "\n",
    "    # stride-pick within each section to avoid adjacent anchors\n",
    "    anchors = []\n",
    "    for (cik, yr, sec), sub in long_secs.group_by(gcols, maintain_order=True):\n",
    "        arr = sub.select([\"sentenceID_numsurrogate\",\"sentence_pos\"]).to_dicts()\n",
    "        # stride length ~ n // (desired per-section), but keep it simple/consistent:\n",
    "        stride = max( max(1, len(arr)//5), 4 )\n",
    "        for idx in range(0, len(arr), stride):\n",
    "            anchors.append((cik, yr, sec, arr[idx][\"sentenceID_numsurrogate\"], arr[idx][\"sentence_pos\"]))\n",
    "            if len(anchors) >= max_anchors:\n",
    "                break\n",
    "        if len(anchors) >= max_anchors:\n",
    "            break\n",
    "    return anchors\n",
    "\n",
    "def gold_neighbors(df, anchor_key, cik, yr, sec, pos, window=WINDOW):\n",
    "    # All neighbors in the same doc slice with |pos' - pos| in (1..W)\n",
    "    sub = df.filter(\n",
    "        (pl.col(\"cik_int\")==cik) &\n",
    "        (pl.col(\"report_year\")==yr) &\n",
    "        (pl.col(\"section_name\")==sec) &\n",
    "        (pl.col(\"sentence_pos\").is_between(pos-window, pos+window))\n",
    "    ).select([\"sentenceID_numsurrogate\",\"sentence_pos\"])\n",
    "    gold = [int(k) for k in sub[\"sentenceID_numsurrogate\"].to_list()\n",
    "            if int(k) != int(anchor_key)]\n",
    "    return set(gold)  # set for fast membership\n",
    "\n",
    "def query_neighbors(query_vec, flt=None, topk=20):\n",
    "    resp = s3v.query_vectors(\n",
    "        vectorBucketName=VECTOR_BUCKET,\n",
    "        indexName=INDEX_NAME,\n",
    "        queryVector={\"float32\": query_vec},\n",
    "        topK=topk,\n",
    "        filter=flt,\n",
    "        returnMetadata=True,\n",
    "        returnDistance=True\n",
    "    )\n",
    "    hits = resp.get(\"vectors\", [])\n",
    "    # return (keys, distances, metadata list)\n",
    "    keys = [int(h[\"key\"]) for h in hits]\n",
    "    dists = [h.get(\"distance\") for h in hits]\n",
    "    meta  = [h.get(\"metadata\", {}) for h in hits]\n",
    "    return keys, dists, meta\n",
    "\n",
    "def mrr_at_k(ranks, k):\n",
    "    # ranks is a list of 1-based rank, None where no hit\n",
    "    rr = []\n",
    "    for r in ranks:\n",
    "        if r is None or r > k:\n",
    "            rr.append(0.0)\n",
    "        else:\n",
    "            rr.append(1.0/float(r))\n",
    "    return sum(rr)/len(rr) if rr else 0.0\n",
    "\n",
    "# ---------------------------\n",
    "# Build anchor set and run evaluation\n",
    "# ---------------------------\n",
    "anchors = pick_anchors(df, max_anchors=MAX_ANCHORS, section_minlen=SECTION_MINLEN, seed=SEED)\n",
    "\n",
    "results = []\n",
    "for (cik, yr, sec, key, pos) in anchors:\n",
    "    row = df.filter(pl.col(\"sentenceID_numsurrogate\")==key).select(\n",
    "        [\"embedding\",\"sentenceID_numsurrogate\",\"sentence_pos\"]\n",
    "    ).to_dicts()[0]\n",
    "    qvec = np.asarray(row[\"embedding\"], dtype=np.float32).tolist()\n",
    "\n",
    "    # Gold set = window neighbors in same doc slice\n",
    "    G = gold_neighbors(df, key, cik, yr, sec, pos, window=WINDOW)\n",
    "\n",
    "    # Filtered regime: restrict to same (cik, year, section)\n",
    "    flt = {\"$and\":[\n",
    "        {\"cik_int\":{\"$eq\": int(cik)}},\n",
    "        {\"report_year\":{\"$eq\": int(yr)}},\n",
    "        {\"section_name\":{\"$eq\": str(sec)}}\n",
    "    ]}\n",
    "    keys_f, dists_f, meta_f = query_neighbors(qvec, flt=flt, topk=TOPK_FILT)\n",
    "    # Open regime: no filter\n",
    "    keys_o, dists_o, meta_o = query_neighbors(qvec, flt=None, topk=TOPK_OPEN)\n",
    "\n",
    "    # Record metrics\n",
    "    # Self@1: expect the anchor itself at rank 1 (service returns the same key)\n",
    "    self1_f = (len(keys_f)>0 and keys_f[0]==key)\n",
    "    self1_o = (len(keys_o)>0 and keys_o[0]==key)\n",
    "\n",
    "    # Hit@k against G, ignoring self at rank 1\n",
    "    def first_hit_rank(keys, gold):\n",
    "        for i,k_ in enumerate(keys, start=1):\n",
    "            if k_==key:  # skip self\n",
    "                continue\n",
    "            if k_ in gold:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    r1_f = first_hit_rank(keys_f, G)\n",
    "    r1_o = first_hit_rank(keys_o, G)\n",
    "\n",
    "    hit1_f = (r1_f is not None and r1_f<=1)\n",
    "    hit3_f = (r1_f is not None and r1_f<=3)\n",
    "    hit5_f = (r1_f is not None and r1_f<=5)\n",
    "    hit1_o = (r1_o is not None and r1_o<=1)\n",
    "    hit3_o = (r1_o is not None and r1_o<=3)\n",
    "    hit5_o = (r1_o is not None and r1_o<=5)\n",
    "\n",
    "    # Distances (exclude self when computing stats)\n",
    "    def dist_wo_self(keys, dists):\n",
    "        out = []\n",
    "        for k_, d in zip(keys, dists):\n",
    "            if k_==key: continue\n",
    "            if d is not None: out.append(float(d))\n",
    "        return out\n",
    "\n",
    "    Df = dist_wo_self(keys_f, dists_f)\n",
    "    Do = dist_wo_self(keys_o, dists_o)\n",
    "\n",
    "    results.append({\n",
    "        \"cik\": int(cik), \"year\": int(yr), \"sec\": sec, \"anchor_pos\": int(pos),\n",
    "        \"self@1_filt\": int(self1_f), \"self@1_open\": int(self1_o),\n",
    "        \"hit1_filt\": int(hit1_f), \"hit3_filt\": int(hit3_f), \"hit5_filt\": int(hit5_f),\n",
    "        \"hit1_open\": int(hit1_o), \"hit3_open\": int(hit3_o), \"hit5_open\": int(hit5_o),\n",
    "        \"rank_first_hit_filt\": (r1_f or math.inf),\n",
    "        \"rank_first_hit_open\": (r1_o or math.inf),\n",
    "        \"dist_med_filt\": (stats.median(Df) if Df else float(\"nan\")),\n",
    "        \"dist_med_open\": (stats.median(Do) if Do else float(\"nan\")),\n",
    "    })\n",
    "\n",
    "res = pl.DataFrame(results)\n",
    "\n",
    "# ---------------------------\n",
    "# Summaries\n",
    "# ---------------------------\n",
    "def pct(x): \n",
    "    return f\"{100.0*float(x):.1f}%\"\n",
    "\n",
    "N = len(res)\n",
    "print(f\"\\nAnchors evaluated: {N}\")\n",
    "print(\"\\n=== Filtered regime (same CIK/year/section) ===\")\n",
    "print(f\"Self@1:  {pct(res['self@1_filt'].mean())}\")\n",
    "print(f\"Hit@1:   {pct(res['hit1_filt'].mean())}\")\n",
    "print(f\"Hit@3:   {pct(res['hit3_filt'].mean())}\")\n",
    "print(f\"Hit@5:   {pct(res['hit5_filt'].mean())}\")\n",
    "mrr_f = mrr_at_k([int(r) if r!=math.inf else None for r in res['rank_first_hit_filt'].to_list()], k=TOPK_FILT)\n",
    "print(f\"MRR@{TOPK_FILT}: {mrr_f:.3f}\")\n",
    "print(f\"Median distance (non-self): {res['dist_med_filt'].drop_nulls().median():.3f}\")\n",
    "\n",
    "print(\"\\n=== Open regime (no filter) ===\")\n",
    "print(f\"Self@1:  {pct(res['self@1_open'].mean())}\")\n",
    "print(f\"Hit@1:   {pct(res['hit1_open'].mean())}\")\n",
    "print(f\"Hit@3:   {pct(res['hit3_open'].mean())}\")\n",
    "print(f\"Hit@5:   {pct(res['hit5_open'].mean())}\")\n",
    "mrr_o = mrr_at_k([int(r) if r!=math.inf else None for r in res['rank_first_hit_open'].to_list()], k=TOPK_OPEN)\n",
    "print(f\"MRR@{TOPK_OPEN}: {mrr_o:.3f}\")\n",
    "print(f\"Median distance (non-self): {res['dist_med_open'].drop_nulls().median():.3f}\")\n",
    "\n",
    "# Hardest misses (top few where rank_first_hit is large)\n",
    "hard_f = res.sort([\"rank_first_hit_filt\"], descending=True).head(5)\n",
    "hard_o = res.sort([\"rank_first_hit_open\"], descending=True).head(5)\n",
    "print(\"\\n=== Hardest cases (filtered) ===\")\n",
    "print(hard_f.select([\"cik\",\"year\",\"sec\",\"anchor_pos\",\"rank_first_hit_filt\",\"dist_med_filt\"]))\n",
    "print(\"\\n=== Hardest cases (open) ===\")\n",
    "print(hard_o.select([\"cik\",\"year\",\"sec\",\"anchor_pos\",\"rank_first_hit_open\",\"dist_med_open\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fe68c",
   "metadata": {},
   "source": [
    "### Gold Test P2?: What changes if you include tiny sections\n",
    "\n",
    "- Metric semantics drift. gold window built on sentence position, sections with 3–20 sentences yield very few non-self “gold” neighbors. pushes Hit@k down (no available positives) or, if W is large relative to section length, it inflates Hit@k (everything becomes gold). \n",
    "- Distance distribution skews. In small sections, the nearest non-self neighbors are often structural (headers, enumerations) rather than semantic. higher median distances for first hits, which—if used to calibrate an acceptance threshold—will make runtime RAG more permissive than it should be.\n",
    "- \"Anchor representativeness drops\". handful of short sections can dominate anchors if you don’t stratify, over-weighting boilerplate or footers and masking performance where retrieval actually matters (long narrative sections like 1A, 7, 7A).\n",
    "- doesn’t mirror production ?? RAG - still query across all sections, yes—but success on tiny sections is mostly about global retrieval + reranking, not local nearest-neighbor behavior inside a 10-line section.\n",
    "\n",
    "#### It’s fair to “trust the embedding,” but evaluation must separate:\n",
    "\n",
    "- Can the index find tight paraphrases inside a topical neighborhood? (primary suite)\n",
    "- What happens when the neighborhood is too small to contain paraphrases? (small-sections suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29799371",
   "metadata": {},
   "source": [
    "### Gold Test 2: Concept Upgrades:\n",
    "- Adaptive windowing (per-anchor): Instead of a fixed ±W, compute an effective window that expands just enough to yield a minimal number of candidate gold neighbors for that anchor, capped by a max. \n",
    "```\n",
    "    Base window: W_BASE (e.g., 5), Max window cap: W_MAX (e.g., 12)\n",
    "    Gold target: G_TARGET (e.g., at least 2 non-self neighbors)\n",
    "    Logic: start at W_BASE; widen ±w until gold size ≥ G_TARGET or w == W_MAX or section boundaries reached.\n",
    "```\n",
    "- Cardinality-aware reporting: Small sections can have no available golds even after expansion\n",
    "```\n",
    "    Covered anchors (|G| ≥ 1): contribute to Hit@k and MRR.\n",
    "    Uncovered anchors (|G| = 0): excluded from those aggregates, but reported via Coverage%.\n",
    "```\n",
    "- Section-balanced anchor sampling.\n",
    "- Bucket results by section_len (e.g., <10, 10–19, 20–39, 40+) and print bucket-level Coverage% and Hit@5.\n",
    "\n",
    "### Coverage Res:\n",
    "- Coverage% tells you how often adaptive windowing could assemble at least one non-self gold neighbor. If coverage is low in a bucket (e.g., <10), those sections simply don’t contain local paraphrases; you’ll rely on global retrieval + reranking in production.\n",
    "- Filtered metrics (covered only) remain a measure of local semantic tightness, apples-to-apples with P1.\n",
    "- Stratified table gives you immediate visibility into small sections without letting them redefine your main aggregates.\n",
    "```\n",
    "Keep: TOPK_FILT=30, TOPK_OPEN=30\n",
    "P2-specific: W_BASE=5, W_MAX=12, G_TARGET=2, MAX_PER_SEC=3, MAX_ANCHORS=60\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0cd894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joems\\AppData\\Local\\Temp\\ipykernel_59080\\853864438.py:43: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  .agg(pl.count().alias(\"section_len\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anchors evaluated: 60\n",
      "Coverage (anchors with ≥1 gold after adaptive window): 66.7%\n",
      "\n",
      "=== Filtered regime (same CIK/year/section) — covered anchors only ===\n",
      "Self@1:  100.0%\n",
      "Hit@1:   0.0%\n",
      "Hit@3:   75.0%\n",
      "Hit@5:   80.0%\n",
      "MRR@30: 0.379\n",
      "Median distance (non-self): 0.540\n",
      "\n",
      "=== Open regime (no filter) — covered anchors only ===\n",
      "Self@1:  62.5%\n",
      "Hit@1:   0.0%\n",
      "Hit@3:   0.0%\n",
      "Hit@5:   2.5%\n",
      "MRR@30: 0.032\n",
      "Median distance (non-self): 0.333\n",
      "\n",
      "=== Hardest cases (filtered, covered) ===\n",
      "shape: (5, 9)\n",
      "┌───────┬──────┬─────────┬────────────┬───┬───────┬───────────┬─────────┬───────────────┐\n",
      "│ cik   ┆ year ┆ sec     ┆ anchor_pos ┆ … ┆ w_eff ┆ gold_size ┆ r1_filt ┆ dist_med_filt │\n",
      "│ ---   ┆ ---  ┆ ---     ┆ ---        ┆   ┆ ---   ┆ ---       ┆ ---     ┆ ---           │\n",
      "│ i64   ┆ i64  ┆ str     ┆ i64        ┆   ┆ i64   ┆ i64       ┆ f64     ┆ f64           │\n",
      "╞═══════╪══════╪═════════╪════════════╪═══╪═══════╪═══════════╪═════════╪═══════════════╡\n",
      "│ 34088 ┆ 2015 ┆ ITEM_1  ┆ 19         ┆ … ┆ 5     ┆ 3         ┆ inf     ┆ 0.634482      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 2          ┆ … ┆ 12    ┆ 1         ┆ inf     ┆ 0.607892      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_2  ┆ 81         ┆ … ┆ 5     ┆ 2         ┆ inf     ┆ 0.590238      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_4  ┆ 1          ┆ … ┆ 12    ┆ 1         ┆ inf     ┆ NaN           │\n",
      "│ 34088 ┆ 2016 ┆ ITEM_2  ┆ 1          ┆ … ┆ 5     ┆ 5         ┆ inf     ┆ 0.53692       │\n",
      "└───────┴──────┴─────────┴────────────┴───┴───────┴───────────┴─────────┴───────────────┘\n",
      "\n",
      "=== Hardest cases (open, covered) ===\n",
      "shape: (5, 9)\n",
      "┌───────┬──────┬─────────┬────────────┬───┬───────┬───────────┬─────────┬───────────────┐\n",
      "│ cik   ┆ year ┆ sec     ┆ anchor_pos ┆ … ┆ w_eff ┆ gold_size ┆ r1_open ┆ dist_med_open │\n",
      "│ ---   ┆ ---  ┆ ---     ┆ ---        ┆   ┆ ---   ┆ ---       ┆ ---     ┆ ---           │\n",
      "│ i64   ┆ i64  ┆ str     ┆ i64        ┆   ┆ i64   ┆ i64       ┆ f64     ┆ f64           │\n",
      "╞═══════╪══════╪═════════╪════════════╪═══╪═══════╪═══════════╪═════════╪═══════════════╡\n",
      "│ 34088 ┆ 2015 ┆ ITEM_1  ┆ 0          ┆ … ┆ 12    ┆ 2         ┆ inf     ┆ 0.486946      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_1  ┆ 19         ┆ … ┆ 5     ┆ 3         ┆ inf     ┆ 0.336299      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_12 ┆ 2          ┆ … ┆ 12    ┆ 1         ┆ inf     ┆ 0.365979      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 2          ┆ … ┆ 12    ┆ 1         ┆ inf     ┆ 0.250427      │\n",
      "│ 34088 ┆ 2015 ┆ ITEM_15 ┆ 231        ┆ … ┆ 5     ┆ 2         ┆ inf     ┆ 0.394132      │\n",
      "└───────┴──────┴─────────┴────────────┴───┴───────┴───────────┴─────────┴───────────────┘\n",
      "\n",
      "=== Stratified summary by section length ===\n",
      "shape: (4, 5)\n",
      "┌────────────┬─────────┬──────────┬───────────┬───────────┐\n",
      "│ len_bucket ┆ anchors ┆ coverage ┆ hit5_filt ┆ hit5_open │\n",
      "│ ---        ┆ ---     ┆ ---      ┆ ---       ┆ ---       │\n",
      "│ str        ┆ u32     ┆ f64      ┆ f64       ┆ f64       │\n",
      "╞════════════╪═════════╪══════════╪═══════════╪═══════════╡\n",
      "│ 10-19      ┆ 3       ┆ 1.0      ┆ 1.0       ┆ 0.0       │\n",
      "│ 20-39      ┆ 6       ┆ 1.0      ┆ 1.0       ┆ 0.0       │\n",
      "│ 40+        ┆ 15      ┆ 1.0      ┆ 0.6       ┆ 0.0       │\n",
      "│ <10        ┆ 36      ┆ 0.444444 ┆ 0.388889  ┆ 0.027778  │\n",
      "└────────────┴─────────┴──────────┴───────────┴───────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joems\\AppData\\Local\\Temp\\ipykernel_59080\\853864438.py:248: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"anchors\"),\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Gold Test P2 — Adaptive windowing, cardinality-aware metrics, small-sections included\n",
    "# Keeps S3 Vectors usage identical; only the gold and reporting logic change.\n",
    "# ============================================================================\n",
    "\n",
    "import boto3, numpy as np, polars as pl, math, statistics as stats\n",
    "from pathlib import Path\n",
    "from botocore.exceptions import ClientError\n",
    "from loaders.ml_config_loader import MLConfig\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration (P2-specific)\n",
    "# ---------------------------\n",
    "cfg = MLConfig()\n",
    "VECTOR_BUCKET = \"finrag-embeddings-s3vectors\"\n",
    "INDEX_NAME    = \"finrag-sentence-fact-embed-1024d\"\n",
    "DIM           = cfg.s3vectors_dimensions(\"cohere_1024d\")\n",
    "\n",
    "# Retrieval knobs (unchanged service behavior)\n",
    "TOPK_FILT     = 30\n",
    "TOPK_OPEN     = 30\n",
    "\n",
    "# Anchor/gold construction knobs (P2)\n",
    "W_BASE        = 5       # start here\n",
    "W_MAX         = 12      # do not exceed this\n",
    "G_TARGET      = 2       # try to have at least this many non-self gold neighbors\n",
    "MAX_ANCHORS   = 60      # total anchors to evaluate\n",
    "MAX_PER_SEC   = 3       # max anchors sampled per (cik,year,section)\n",
    "SEED          = 7       # determinism\n",
    "\n",
    "# Client + data\n",
    "s3v = boto3.client(\"s3vectors\",\n",
    "                   region_name=cfg.region,\n",
    "                   aws_access_key_id=cfg.aws_access_key,\n",
    "                   aws_secret_access_key=cfg.aws_secret_key)\n",
    "\n",
    "stage3_path = cfg.get_s3vectors_cache_path(\"cohere_1024d\")\n",
    "df = pl.read_parquet(stage3_path)\n",
    "\n",
    "# Basic section size table\n",
    "gcols = [\"cik_int\",\"report_year\",\"section_name\"]\n",
    "sec_sizes = (df.group_by(gcols)\n",
    "               .agg(pl.count().alias(\"section_len\"))\n",
    "               .sort(gcols))\n",
    "df = df.join(sec_sizes, on=gcols, how=\"inner\")\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def query_vectors(query_vec, flt=None, topk=20):\n",
    "    # Clamp per service contract\n",
    "    topk = max(1, min(30, int(topk)))\n",
    "    resp = s3v.query_vectors(\n",
    "        vectorBucketName=VECTOR_BUCKET,\n",
    "        indexName=INDEX_NAME,\n",
    "        queryVector={\"float32\": query_vec},\n",
    "        topK=topk,\n",
    "        filter=flt,\n",
    "        returnMetadata=True,\n",
    "        returnDistance=True\n",
    "    )\n",
    "    hits = resp.get(\"vectors\", [])\n",
    "    keys  = [int(h[\"key\"]) for h in hits]\n",
    "    dists = [h.get(\"distance\") for h in hits]\n",
    "    meta  = [h.get(\"metadata\", {}) for h in hits]\n",
    "    return keys, dists, meta\n",
    "\n",
    "def effective_gold(df_slice, anchor_key, anchor_pos, w_base, w_max, g_target):\n",
    "    \"\"\"Expand ±window from w_base until we have >= g_target non-self neighbors or hit w_max.\"\"\"\n",
    "    sec_len = int(df_slice[\"section_len\"][0])\n",
    "    # Early exit: single-sentence sections\n",
    "    if sec_len <= 1:\n",
    "        return set(), w_base, sec_len\n",
    "    # Expand window\n",
    "    for w in range(w_base, w_max+1):\n",
    "        sub = df_slice.filter(pl.col(\"sentence_pos\").is_between(anchor_pos - w, anchor_pos + w)) \\\n",
    "                      .select([\"sentenceID_numsurrogate\",\"sentence_pos\"])\n",
    "        cand = [int(k) for k in sub[\"sentenceID_numsurrogate\"].to_list() if int(k) != int(anchor_key)]\n",
    "        if len(cand) >= g_target:\n",
    "            return set(cand), w, sec_len\n",
    "    # Not enough candidates even at max window\n",
    "    sub = df_slice.filter(pl.col(\"sentence_pos\").is_between(anchor_pos - w_max, anchor_pos + w_max)) \\\n",
    "                  .select([\"sentenceID_numsurrogate\",\"sentence_pos\"])\n",
    "    cand = [int(k) for k in sub[\"sentenceID_numsurrogate\"].to_list() if int(k) != int(anchor_key)]\n",
    "    return set(cand), w_max, sec_len\n",
    "\n",
    "def mrr_at_k(ranks, k):\n",
    "    rr = []\n",
    "    for r in ranks:\n",
    "        if r is None or r > k:\n",
    "            rr.append(0.0)\n",
    "        else:\n",
    "            rr.append(1.0/float(r))\n",
    "    return sum(rr)/len(rr) if rr else 0.0\n",
    "\n",
    "# ---------------------------\n",
    "# Anchor sampling (section-balanced, no min-len cut)\n",
    "# ---------------------------\n",
    "# Deterministic order\n",
    "df_sorted = df.sort(by=[\"cik_int\",\"report_year\",\"section_name\",\"sentence_pos\"])\n",
    "\n",
    "anchors = []\n",
    "per_sec_count = {}\n",
    "\n",
    "for (cik, yr, sec), sub in df_sorted.group_by(gcols, maintain_order=True):\n",
    "    keypos = sub.select([\"sentenceID_numsurrogate\",\"sentence_pos\",\"section_len\"]).to_dicts()\n",
    "    # stride by section length to avoid adjacency; at least stride 4\n",
    "    stride = max(4, len(keypos)//5) if len(keypos) > 0 else 1\n",
    "    taken = 0\n",
    "    for idx in range(0, len(keypos), stride):\n",
    "        if per_sec_count.get((cik,yr,sec), 0) >= MAX_PER_SEC:\n",
    "            break\n",
    "        anchors.append((int(cik), int(yr), str(sec),\n",
    "                        int(keypos[idx][\"sentenceID_numsurrogate\"]),\n",
    "                        int(keypos[idx][\"sentence_pos\"])))\n",
    "        per_sec_count[(cik,yr,sec)] = per_sec_count.get((cik,yr,sec),0) + 1\n",
    "        if len(anchors) >= MAX_ANCHORS:\n",
    "            break\n",
    "    if len(anchors) >= MAX_ANCHORS:\n",
    "        break\n",
    "\n",
    "# ---------------------------\n",
    "# Evaluation\n",
    "# ---------------------------\n",
    "rows = []\n",
    "for (cik, yr, sec, key, pos) in anchors:\n",
    "    # Slice for this section once\n",
    "    sec_slice = df.filter((pl.col(\"cik_int\")==cik) & (pl.col(\"report_year\")==yr) & (pl.col(\"section_name\")==sec)) \\\n",
    "                  .select([\"sentenceID_numsurrogate\",\"sentence_pos\",\"embedding\",\"section_len\"])\n",
    "\n",
    "    # Anchor embedding\n",
    "    arow = sec_slice.filter(pl.col(\"sentenceID_numsurrogate\")==key).to_dicts()[0]\n",
    "    qvec = np.asarray(arow[\"embedding\"], dtype=np.float32).tolist()\n",
    "\n",
    "    # Adaptive gold\n",
    "    G, w_eff, sec_len = effective_gold(sec_slice, key, pos, W_BASE, W_MAX, G_TARGET)\n",
    "\n",
    "    # Filtered query\n",
    "    flt = {\"$and\":[\n",
    "        {\"cik_int\":{\"$eq\": int(cik)}},\n",
    "        {\"report_year\":{\"$eq\": int(yr)}},\n",
    "        {\"section_name\":{\"$eq\": str(sec)}}\n",
    "    ]}\n",
    "    keys_f, dists_f, _ = query_vectors(qvec, flt=flt, topk=TOPK_FILT)\n",
    "    keys_o, dists_o, _ = query_vectors(qvec, flt=None, topk=TOPK_OPEN)\n",
    "\n",
    "    # Self@1\n",
    "    self1_f = (len(keys_f)>0 and keys_f[0]==key)\n",
    "    self1_o = (len(keys_o)>0 and keys_o[0]==key)\n",
    "\n",
    "    # First non-self hit in gold\n",
    "    def first_hit_rank(keys, gold):\n",
    "        for i,k_ in enumerate(keys, start=1):\n",
    "            if k_==key: continue\n",
    "            if k_ in gold: return i\n",
    "        return None\n",
    "\n",
    "    r1_f = first_hit_rank(keys_f, G)\n",
    "    r1_o = first_hit_rank(keys_o, G)\n",
    "\n",
    "    # Distances without self\n",
    "    def dist_wo_self(keys, dists):\n",
    "        out = []\n",
    "        for k_, d in zip(keys, dists):\n",
    "            if k_==key: continue\n",
    "            if d is not None: out.append(float(d))\n",
    "        return out\n",
    "\n",
    "    Df = dist_wo_self(keys_f, dists_f)\n",
    "    Do = dist_wo_self(keys_o, dists_o)\n",
    "\n",
    "    rows.append({\n",
    "        \"cik\": cik, \"year\": yr, \"sec\": sec, \"anchor_pos\": pos,\n",
    "        \"section_len\": sec_len, \"w_eff\": w_eff, \"gold_size\": len(G),\n",
    "        \"covered\": int(len(G) > 0),\n",
    "        \"self@1_filt\": int(self1_f), \"self@1_open\": int(self1_o),\n",
    "        \"r1_filt\": (r1_f or math.inf), \"r1_open\": (r1_o or math.inf),\n",
    "        \"hit1_filt\": int(r1_f is not None and r1_f<=1),\n",
    "        \"hit3_filt\": int(r1_f is not None and r1_f<=3),\n",
    "        \"hit5_filt\": int(r1_f is not None and r1_f<=5),\n",
    "        \"hit1_open\": int(r1_o is not None and r1_o<=1),\n",
    "        \"hit3_open\": int(r1_o is not None and r1_o<=3),\n",
    "        \"hit5_open\": int(r1_o is not None and r1_o<=5),\n",
    "        \"dist_med_filt\": (stats.median(Df) if Df else float(\"nan\")),\n",
    "        \"dist_med_open\": (stats.median(Do) if Do else float(\"nan\")),\n",
    "    })\n",
    "\n",
    "res = pl.DataFrame(rows)\n",
    "\n",
    "# ---------------------------\n",
    "# Summaries (cardinality-aware)\n",
    "# ---------------------------\n",
    "def pct(x): return f\"{100.0*float(x):.1f}%\"\n",
    "\n",
    "N_all = len(res)\n",
    "N_cov = int(res[\"covered\"].sum())\n",
    "coverage = N_cov / max(1, N_all)\n",
    "\n",
    "print(f\"\\nAnchors evaluated: {N_all}\")\n",
    "print(f\"Coverage (anchors with ≥1 gold after adaptive window): {pct(coverage)}\")\n",
    "\n",
    "# Filtered (covered only)\n",
    "cov = res.filter(pl.col(\"covered\")==1)\n",
    "def mrr(series_ranks, k): \n",
    "    return mrr_at_k([int(r) if r!=math.inf else None for r in series_ranks], k)\n",
    "\n",
    "print(\"\\n=== Filtered regime (same CIK/year/section) — covered anchors only ===\")\n",
    "if len(cov) > 0:\n",
    "    print(f\"Self@1:  {pct(cov['self@1_filt'].mean())}\")\n",
    "    print(f\"Hit@1:   {pct(cov['hit1_filt'].mean())}\")\n",
    "    print(f\"Hit@3:   {pct(cov['hit3_filt'].mean())}\")\n",
    "    print(f\"Hit@5:   {pct(cov['hit5_filt'].mean())}\")\n",
    "    print(f\"MRR@{TOPK_FILT}: {mrr(cov['r1_filt'], TOPK_FILT):.3f}\")\n",
    "    print(f\"Median distance (non-self): {cov['dist_med_filt'].drop_nulls().median():.3f}\")\n",
    "else:\n",
    "    print(\"No covered anchors (unexpected with adaptive window).\")\n",
    "\n",
    "# Open (covered only)\n",
    "print(\"\\n=== Open regime (no filter) — covered anchors only ===\")\n",
    "if len(cov) > 0:\n",
    "    print(f\"Self@1:  {pct(cov['self@1_open'].mean())}\")\n",
    "    print(f\"Hit@1:   {pct(cov['hit1_open'].mean())}\")\n",
    "    print(f\"Hit@3:   {pct(cov['hit3_open'].mean())}\")\n",
    "    print(f\"Hit@5:   {pct(cov['hit5_open'].mean())}\")\n",
    "    print(f\"MRR@{TOPK_OPEN}: {mrr(cov['r1_open'], TOPK_OPEN):.3f}\")\n",
    "    print(f\"Median distance (non-self): {cov['dist_med_open'].drop_nulls().median():.3f}\")\n",
    "else:\n",
    "    print(\"No covered anchors.\")\n",
    "\n",
    "# Hardest cases (covered only, by largest rank)\n",
    "hard_f = cov.sort([\"r1_filt\"], descending=True).head(5)\n",
    "hard_o = cov.sort([\"r1_open\"], descending=True).head(5)\n",
    "print(\"\\n=== Hardest cases (filtered, covered) ===\")\n",
    "print(hard_f.select([\"cik\",\"year\",\"sec\",\"anchor_pos\",\"section_len\",\"w_eff\",\"gold_size\",\"r1_filt\",\"dist_med_filt\"]))\n",
    "print(\"\\n=== Hardest cases (open, covered) ===\")\n",
    "print(hard_o.select([\"cik\",\"year\",\"sec\",\"anchor_pos\",\"section_len\",\"w_eff\",\"gold_size\",\"r1_open\",\"dist_med_open\"]))\n",
    "\n",
    "# Stratified by section length (light view)\n",
    "def bucket_len(n):\n",
    "    if n < 10: return \"<10\"\n",
    "    if n < 20: return \"10-19\"\n",
    "    if n < 40: return \"20-39\"\n",
    "    return \"40+\"\n",
    "\n",
    "res_b = res.with_columns(pl.col(\"section_len\").map_elements(bucket_len).alias(\"len_bucket\"))\n",
    "grp = (res_b.group_by(\"len_bucket\")\n",
    "           .agg([\n",
    "               pl.count().alias(\"anchors\"),\n",
    "               pl.col(\"covered\").mean().alias(\"coverage\"),\n",
    "               pl.col(\"hit5_filt\").mean().alias(\"hit5_filt\"),\n",
    "               pl.col(\"hit5_open\").mean().alias(\"hit5_open\"),\n",
    "           ])\n",
    "           .sort(\"len_bucket\"))\n",
    "print(\"\\n=== Stratified summary by section length ===\")\n",
    "print(grp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d645c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac30992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39ada5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e292d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a6e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd394bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinRAG ML (Python 3.11)",
   "language": "python",
   "name": "finrag_ml_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
